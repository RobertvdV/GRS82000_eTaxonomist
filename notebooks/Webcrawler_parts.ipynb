{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432f0205-06eb-4a76-b89b-61d4fc87975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import re\n",
    "import collections\n",
    "import glob\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sys.path.insert(0, '../src/models/')\n",
    "sys.path.insert(0, '../src/features/')\n",
    "\n",
    "from predict_model import loadBERT\n",
    "from predict_model import SpanPredictor as classify\n",
    "from build_features import text_cleaner, DuckDuckGo_Java, Bing_HTML, colorize_prediction\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28430fea-dde3-44b8-9bd6-53f8cc9614fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Success\n"
     ]
    }
   ],
   "source": [
    "model = loadBERT(\"../models/\", 'saved_weights_inf_FIXED_boot_beta80.pt')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66db15da-6d86-40b8-bacd-37f8fbe9f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_dict = collections.defaultdict(list)\n",
    "root = '../data/description/'\n",
    "# Load the pickle list\n",
    "data_files = glob.glob(root+ 'description*PLANTS.pkl')\n",
    "for data_file in data_files:\n",
    "    dict_ = pickle.load(open(data_file, 'rb'))\n",
    "    for key, value in dict_.items():\n",
    "        plants_dict[key] += value\n",
    "    \n",
    "\n",
    "# Order the dictionary based on the list length\n",
    "plants_dict = collections.OrderedDict(sorted(plants_dict.items(), key= lambda x: len(x[1]), reverse=True))\n",
    "# Correct first key\n",
    "plants_dict['Poa'] = plants_dict.pop('oa')\n",
    "# Get keys\n",
    "plants = [key for key in plants_dict.keys()]\n",
    "\n",
    "# FOR THE BIRD TESTING\n",
    "#bird_descriptions_dict = pickle.load(open('../data/description/04_TRAIN_0-1881_BIRDS.pkl', 'rb'))\n",
    "#birds = [key for key in bird_descriptions_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78da0acf-84ce-4b6c-94af-fcdb5c70e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "spps = ['Wodyetia bifurcata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b90b8e4-725c-4faf-b7be-f7b6fa19307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Safari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec62cb-83e5-400e-af98-d12213db69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DuckDuckGo_Java('Robert van de VLasakker', driver=driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b963d2-74cf-43eb-a557-b2eee91131f7",
   "metadata": {},
   "source": [
    "### URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "697925cc-4aa6-4247-9a5c-4635a7fc8dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058de31568584d8894561727993978e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUGGING\n",
    "data_links = collections.defaultdict(list)\n",
    "# Init driver\n",
    "#driver = webdriver.Safari()\n",
    "\n",
    "queries = ['description', 'diagnosis', '', 'attributes', 'captions']\n",
    "\n",
    "for species in tqdm_notebook(spps):\n",
    "    # Empty list\n",
    "    search_links = []\n",
    "    \n",
    "    for query in queries:\n",
    "        # create query\n",
    "        species_q = species.replace(' ', '+')\n",
    "        species_q = f'\"{species_q}\"+{query}'\n",
    "        try:\n",
    "            search_links += DuckDuckGo_Java(species_q, \n",
    "                                            driver=driver)\n",
    "            search_links += Bing_HTML(species_q)\n",
    "         # Skip connection timeout\n",
    "        except:\n",
    "            continue\n",
    "    # Drop duplicates\n",
    "    search_links = list(set(search_links))\n",
    "    if not search_links:\n",
    "        print('empty')\n",
    "    # DEBUGGING\n",
    "    data_links[species] += search_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed528f-acb2-40c8-b6c9-e9dbeb0ffbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/description/01_URLS_0020000-0025000_PLANTS.pkl', 'wb') as f:\n",
    "#    pickle.dump(data_links, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50f29fdf-e15e-4b9b-a99e-07252c707387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2025c5-bffc-43aa-ae5d-4508709501ad",
   "metadata": {},
   "source": [
    "### TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4b3e6cd-f6a5-4a1d-8154-df5cbd5a9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URLS = pickle.load(open('../data/description/01_URLS_0015000-0020000_PLANTS.pkl', 'rb'))\n",
    "URLS = data_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec392d4-f4cf-46ac-9ac6-8581ffda353f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e129412469475bb07121ea5b3fa363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Species:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_list = collections.defaultdict(list)\n",
    "\n",
    "species = list(URLS.keys())\n",
    "\n",
    "for species in tqdm_notebook(species, desc='Species'):\n",
    "    for URL in URLS[species]:\n",
    "        # Skip google archives\n",
    "        if 'google' in URL:\n",
    "            continue\n",
    "        # PDF and TXT\n",
    "        if URL.endswith('txt') or URL.endswith('pdf'):\n",
    "            continue\n",
    "        # Skip Plants of the world (already done)\n",
    "        if 'powo' in URL:\n",
    "            continue\n",
    "        try:\n",
    "            page = requests.get(URL, timeout=5)\n",
    "            # Skip PDF files for now\n",
    "            if page.headers['Content-Type'].startswith('application/pdf'):\n",
    "                continue\n",
    "            # Soup the result\n",
    "            soup = BeautifulSoup(page.content, \"lxml\", from_encoding=\"iso-8859-1\")    \n",
    "            # Skip Embedded PDF's\n",
    "            if 'pdf' in soup.title.text.lower():\n",
    "                continue\n",
    "            # Check if species exists somewhere within title\n",
    "            if bool(set(species.split()).intersection(soup.title.text.split())):\n",
    "                # Get text\n",
    "                #dirty_text = soup.get_text(\". \", strip=True)\n",
    "                dirty_text = soup.get_text(\" \", strip=False).replace('\\n', '.')\n",
    "                # Clean and break into sents\n",
    "                sentences = text_cleaner(dirty_text)\n",
    "                # Append\n",
    "                sentence_list[species].append(sentences)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ffd266d-7001-4a48-b904-ea2a78349c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for y in sentence_list[species]:\n",
    "    x.extend(y)\n",
    "#sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7be1c87-10b6-4c67-9644-adc6c9ab7c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3b39ee-df5a-4a14-ae74-3ef5f4eda4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/description/02_SENTS_0015000-0020000_PLANTS.pkl', 'wb') as f:\n",
    "#    pickle.dump(sentence_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926009d6-5ae2-4276-8528-5c276618a01a",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec5dca12-68f4-43c0-9a73-906475eee059",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load the pickle list\n",
    "datalist = glob.glob('../data/description/02_SENTS_0015_PLANTS.pkl')\n",
    "# Init list\n",
    "sentence_list = {}\n",
    "# Loop over the pickles\n",
    "for data in datalist:\n",
    "    # Open the pickles\n",
    "    datadict = pickle.load(open(data, 'rb'))\n",
    "    # Update\n",
    "    sentence_list.update(datadict)\n",
    "'''\n",
    "\n",
    "sentence_list = pickle.load(open('../data/description/02_SENTS_0015000-0020000_PLANTS.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f2571b4-8b92-4e53-bfd5-29ed64ff1bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd01899577144b3b41873c2e59b0ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Species:   0%|          | 0/4248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "descriptions = collections.defaultdict(list)\n",
    "species_list = list(sentence_list.keys())\n",
    "\n",
    "for species in tqdm_notebook(species_list, desc='Species'):\n",
    "    for text in sentence_list[species]:\n",
    "        for sentence in text:\n",
    "            if classify(sentence, model=model):\n",
    "                descriptions[species].append(sentence)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be5682aa-2c08-471a-a856-8bba6f7f36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/description/03_DESC_0015000-0020000_PLANTS.pkl.pkl', 'wb') as f:\n",
    "    pickle.dump(descriptions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbcadff-8f30-4fb5-a236-2b25f0b4a018",
   "metadata": {},
   "source": [
    "# Add Know Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e714c488-7806-4730-800a-1add97e3de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle list\n",
    "datalist = glob.glob('../data/description/03_DESC*PLANTS.pkl')\n",
    "# Init list\n",
    "description_list = {}\n",
    "# Loop over the pickles\n",
    "for data in datalist:\n",
    "    # Open the pickles\n",
    "    datadict = pickle.load(open(data, 'rb'))\n",
    "    # Update\n",
    "    description_list.update(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8039e09a-25c6-4fd2-9a84-1af2ef611127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14557"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372c87f8-3cb5-419c-962b-1e03f31df6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle list\n",
    "datalist = glob.glob('../data/description/description*.pkl')\n",
    "# Init list\n",
    "known_list = {}\n",
    "# Loop over the pickles\n",
    "for data in datalist:\n",
    "    # Open the pickles\n",
    "    datadict = pickle.load(open(data, 'rb'))\n",
    "    # Update\n",
    "    known_list.update(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "108e84bb-deff-46a1-abc6-8c328e9a1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = collections.defaultdict(list)\n",
    "\n",
    "species = description_list.keys()\n",
    "\n",
    "for species in description_list.keys():\n",
    "    for sentence in description_list[species]:\n",
    "        if len(sentence.split()) < 3:\n",
    "            continue\n",
    "        traindata[species].append(sentence)\n",
    "    for (sentence, URL) in known_list[species]:\n",
    "        if len(sentence.split()) < 3:\n",
    "            continue\n",
    "        traindata[species].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb0cb26-f56e-46a0-b88d-c3c9c130620a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14557"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88648b58-1ab2-41ba-8189-5c03cbcae236",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/description/04_DESC_0000000-0014557_PLANTS.pkl', 'wb') as f:\n",
    "    pickle.dump(traindata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929e7da-22d2-4de0-89f5-d789e89f218a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
