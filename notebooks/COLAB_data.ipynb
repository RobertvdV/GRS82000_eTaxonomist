{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194297f3-c87a-4076-9a22-091af7133107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import re\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9771c097-3c78-432f-8763-5ea3b9ef0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_text_splitter(text):\n",
    "\n",
    "    import random\n",
    "\n",
    "    \"\"\"\n",
    "    Random breaks up a text into an X amount of sentences. \n",
    "    The output sentences consist of a minimum of 10 sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split text\n",
    "    words = text.split()\n",
    "    # Get the amount of words\n",
    "    word_amount = len(words)\n",
    "    if word_amount <= 10:\n",
    "        return [text]\n",
    "\n",
    "    # Create counter\n",
    "    remaining_word_amount = word_amount\n",
    "    # Init list\n",
    "    parts = []\n",
    "    # While words remaining\n",
    "    while remaining_word_amount > 0:\n",
    "        if len(words) < 10:\n",
    "            # Add last part if less then 10\n",
    "            parts[-1] = parts[-1] + ' '.join(words)\n",
    "            # exit\n",
    "            remaining_word_amount = 0\n",
    "        # Generate random int\n",
    "        randint = random.randint(10, word_amount)\n",
    "        # Append to list \n",
    "        parts.append(' '.join(words[:randint]))\n",
    "        # Delete previous selection\n",
    "        words = words[randint:]\n",
    "        # Update counter\n",
    "        remaining_word_amount -= randint\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483d1401-7930-4b36-9ee5-2f941960aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "# Load the pickle list\n",
    "datalist = glob.glob('../data/processed/train*.pkl')\n",
    "# Init list\n",
    "data_values = []\n",
    "# Loop over the pickles\n",
    "for data in datalist:\n",
    "    # Open the pickles\n",
    "    datadict = pickle.load(open(data, 'rb'))\n",
    "    # Undict and append\n",
    "    data_values += (list(chain.from_iterable(datadict.values())))\n",
    "\n",
    "# Drop double values \n",
    "data_values = list(set(data_values))\n",
    "\n",
    "nested_values = [[tuple([1, span]) if text[0] == 1 else tuple([0, span]) \n",
    "                  for span in random_text_splitter(text[1])] \n",
    "                 for text in data_values]\n",
    "\n",
    "samples += list(chain.from_iterable(nested_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0247cf75-9f8c-4d7f-b76a-a20be76635b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/COLAB.pkl', 'wb') as f:\n",
    "    pickle.dump(samples, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e1e8f1-6903-4e83-bc87-13c25b18b8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2258184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969e646-8612-4629-b85d-ce9b904d6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e0c49-6a96-49bb-816f-3e5ef31252b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
