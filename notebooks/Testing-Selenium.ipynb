{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72d652b-e13c-4094-b988-7cf0bd52ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143b149c-bd62-488f-9ccf-ea9c07da7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://birdsoftheworld.org/bow/specieslist'\n",
    "#URL = 'https://birdsoftheworld-org.ezproxy.library.wur.nl/bow/specieslist'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "BOWlist = soup.find_all('a')\n",
    "\n",
    "URL = 'https://birdsoftheworld.org/bow/specieslist'\n",
    "#URL = 'https://birdsoftheworld-org.ezproxy.library.wur.nl/bow/specieslist'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "'''\n",
    "# Create a list with links\n",
    "BOWpages = ['https://birdsoftheworld.org' + pages.get('href').replace('introduction', '') for pages in BOWlist \n",
    "                   if pages.get('href') != None\n",
    "                   if pages.get('href').startswith('/bow/species')]\n",
    "\n",
    "'''\n",
    "# Create a list with links\n",
    "BOWpages = ['https://birdsoftheworld-org.ezproxy.library.wur.nl' + pages.get('href').replace('introduction', '') for pages in BOWlist \n",
    "                   if pages.get('href') != None\n",
    "                   if pages.get('href').startswith('/bow/species')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ccfa6e-3028-45c4-a123-b4b4340f8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init driver\n",
    "browser = webdriver.Safari()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3bc7a2-b53c-44b4-8408-d2641a524c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login URL\n",
    "browser.get(\"https://edepot.wur.nl/541124\")\n",
    "# Load the website\n",
    "time.sleep(8)\n",
    "\n",
    "# Current page\n",
    "main_page = browser.current_window_handle\n",
    "\n",
    "# Hit Okay\n",
    "Ok = browser.find_element_by_id(\"loginlinkBtn\")\n",
    "Ok.send_keys(u'\\ue007')\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# changing the handles to access login page\n",
    "for handle in browser.window_handles:\n",
    "    if handle != main_page:\n",
    "        login_page = handle\n",
    "          \n",
    "# change the control to signin page        \n",
    "browser.switch_to.window(login_page)\n",
    "\n",
    "# Username\n",
    "username = browser.find_element_by_id(\"userNameInput\")\n",
    "username.clear()\n",
    "username.send_keys(\"robert.vandevlasakker@wur.nl\")\n",
    "\n",
    "# Password\n",
    "password = browser.find_element_by_name(\"Password\")\n",
    "password.clear()\n",
    "password.send_keys(\"XXXXXXX\")\n",
    "\n",
    "# Hit Okay\n",
    "Ok = browser.find_element_by_id(\"submitButton\")\n",
    "Ok.send_keys(u'\\ue007')\n",
    "\n",
    "time.sleep(8)\n",
    "\n",
    "'''\n",
    "# changing the handles to access login page\n",
    "for handle in browser.window_handles:\n",
    "    if handle != main_page or handle!= login_page:\n",
    "        BOW = handle\n",
    "'''\n",
    "\n",
    "# change the control to signin page        \n",
    "browser.switch_to.window(main_page)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c255d-6ea0-461f-b35d-a12c8d14c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Login URL\n",
    "browser.get(\"https://secure.birds.cornell.edu/cassso/login?service=https%3A%2F%2Fbirdsoftheworld.org%2Flogin%2Fcas\")\n",
    "\n",
    "# Username\n",
    "username = browser.find_element_by_id(\"input-user-name\")\n",
    "username.clear()\n",
    "username.send_keys(\"RobertvdV\")\n",
    "\n",
    "# Password\n",
    "password = browser.find_element_by_name(\"password\")\n",
    "password.clear()\n",
    "password.send_keys(\"XXXXXXX\")\n",
    "\n",
    "# Sign in\n",
    "SignIn = browser.find_element_by_id(\"form-submit\")\n",
    "SignIn.send_keys(u'\\ue007')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859231e5-8c7a-4046-8663-a7dbf0e4c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# SHORTER ACCOUNTS SKIP?\n",
    "\n",
    "# Init dict\n",
    "DataBOW = collections.defaultdict(list)\n",
    "\n",
    "# XML dump for testing\n",
    "XMLdump = collections.defaultdict(list)\n",
    "\n",
    "# Reference Removers\n",
    "SourceRemover = [\n",
    "    ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\)',\n",
    "    ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\, .+Close\\n\\t\\n\\)',\n",
    "    ' *\\[\\d+\\n\\t.+?Close\\n\\t\\n\\]',\n",
    "    ' *\\( *\\d\\d\\n\\t.+?Close\\n\\t\\n,',\n",
    "    ' *\\(cf\\..+?Close\\n\\t\\n, .+Close\\n\\t\\n\\)',\n",
    "    '\\d+.+?Close\\n\\t\\n'\n",
    "]\n",
    "\n",
    "\n",
    "#ReferenceRemover1 = ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\)'\n",
    "#ReferenceRemover2 = ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\, .+Close\\n\\t\\n\\)'\n",
    "# Loop over the test set\n",
    "for Bird in BOWpages[0:500]:\n",
    "    \n",
    "    \n",
    "    browser.get(Bird + 'appearance')\n",
    "    #browser.get('https://birdsoftheworld.org/bow/species/norcar/cur/appearance')\n",
    "    SleepTime = random.randint(2, 6)\n",
    "    time.sleep(SleepTime)\n",
    "    \n",
    "    HTML = browser.page_source\n",
    "    soup = BeautifulSoup(HTML, 'html.parser')\n",
    "\n",
    "    # Bird name \n",
    "    if len(soup.title.text.split(' - ')) == 4:\n",
    "\n",
    "        BirdName = soup.title\\\n",
    "                        .text\\\n",
    "                        .split(' - ')[1]\\\n",
    "                        .lstrip()\n",
    "    else:\n",
    "        BirdName = soup.title\\\n",
    "                    .text\\\n",
    "                    .split(' - ')[0]\\\n",
    "                    .lstrip()\n",
    "        \n",
    "    # Dump XML for testing\n",
    "    XMLdump[BirdName].append(soup)\n",
    "        \n",
    "    # Find all text data\n",
    "    Paragraphs = soup.find_all('p')\n",
    "\n",
    "    # Loop over the text\n",
    "    for Para in Paragraphs[1:]:\n",
    "        try:\n",
    "\n",
    "            # Check to which section the text belongs\n",
    "            SubSection = Para.find_previous_siblings()[0]\\\n",
    "                             .text[0:50]\\\n",
    "                             .rstrip()\\\n",
    "                             .lstrip()\n",
    "            #print(SubSection)\n",
    "\n",
    "            # Check to which section the text belongs\n",
    "            SubSubSection = Para.find_previous_siblings()[-1]\\\n",
    "                                 .text\\\n",
    "                                 .rstrip()\\\n",
    "                                 .lstrip()\n",
    "            \n",
    "            #print(SubSubSection)\n",
    "\n",
    "        # If a text does not have a header, skip    \n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        ### THESE LINES MAY BE REMOVED###\n",
    "        # Exceptions\n",
    "        #if 'Formative' in SubSection:\n",
    "        #    continue\n",
    "        #if 'Juvenile' in SubSection:\n",
    "        #    continue\n",
    "        #if 'Immature' in SubSection:\n",
    "        #    continue\n",
    "        ### THESE LINES MAY BE REMOVED###\n",
    "        \n",
    "        # CHeck if Subsection is about juveniles\n",
    "        if all(s not in SubSection for s in ['Immature', 'Juvenile', 'Formative', 'Chick', 'Natal']) == False:\n",
    "            continue\n",
    "        \n",
    "        # Check if the information given in a text contains info about juveniles\n",
    "        try:\n",
    "            if Para.find('b').text.startswith(('Immature', 'Juvenile', 'Formative', 'Chick')) or\\\n",
    "            Para['class'][0] == 'u-text-2':\n",
    "                    continue\n",
    "        \n",
    "        except:\n",
    "            # See which are needed and append with 1\n",
    "            if SubSection in ['Identification', 'Adult'] or\\\n",
    "               SubSubSection in ['Plumages', 'Bare Parts', 'Identification']:\n",
    "        \n",
    "                # Clean the text from references \n",
    "                TextCleaned = Para.text\n",
    "\n",
    "                # Remove sources\n",
    "                for Remover in SourceRemover:\n",
    "                    TextCleaned = re.sub(Remover, '', TextCleaned, flags=re.DOTALL)\n",
    "\n",
    "                # Drop useless short nonsense\n",
    "                if len(TextCleaned.split()) <2:\n",
    "                    continue\n",
    "                else:\n",
    "                    DataBOW[BirdName].append(tuple([1, TextCleaned]))\n",
    "\n",
    "            # Otherwise label 2        \n",
    "            else:\n",
    "\n",
    "                # Clean the text from references \n",
    "                TextCleaned = Para.text\n",
    "\n",
    "                # Remove sources\n",
    "                for Remover in SourceRemover:\n",
    "                    TextCleaned = re.sub(Remover, '', TextCleaned, flags=re.DOTALL)\n",
    "\n",
    "                # Drop useless short nonsense\n",
    "                if len(TextCleaned.split()) <2:\n",
    "                    continue\n",
    "                else:\n",
    "                    DataBOW[BirdName].append(tuple([0, TextCleaned]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ad63ba-a600-491c-afc2-e32700d2e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataBOW.pkl', 'wb') as f:\n",
    "    pickle.dump(DataBOW, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed4eae-2839-43dd-b6a4-2eabaf934df7",
   "metadata": {},
   "source": [
    "# With Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0506b101-d4cf-4ab7-afa6-76f71c9d614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# SHORTER ACCOUNTS SKIP?\n",
    "\n",
    "# Init dict\n",
    "DataBOW = collections.defaultdict(list)\n",
    "\n",
    "# XML dump for testing\n",
    "XMLdump = collections.defaultdict(list)\n",
    "\n",
    "# Reference Removers\n",
    "SourceRemover = [\n",
    "    ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\)',\n",
    "    ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\, .+Close\\n\\t\\n\\)',\n",
    "    ' *\\[\\d+\\n\\t.+?Close\\n\\t\\n\\]',\n",
    "    ' *\\( *\\d\\d\\n\\t.+?Close\\n\\t\\n,',\n",
    "    ' *\\(cf\\..+?Close\\n\\t\\n, .+Close\\n\\t\\n\\)',\n",
    "    '\\d+.+?Close\\n\\t\\n'\n",
    "]\n",
    "\n",
    "\n",
    "#ReferenceRemover1 = ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\)'\n",
    "#ReferenceRemover2 = ' *\\( *\\d+\\n\\t.+?Close\\n\\t\\n\\, .+Close\\n\\t\\n\\)'\n",
    "# Loop over the test set\n",
    "for Bird in BOWpages[0:500]:\n",
    "    \n",
    "    \n",
    "    browser.get(Bird + 'appearance')\n",
    "    #browser.get('https://birdsoftheworld.org/bow/species/norcar/cur/appearance')\n",
    "    SleepTime = random.randint(2, 6)\n",
    "    time.sleep(SleepTime)\n",
    "    \n",
    "    HTML = browser.page_source\n",
    "    soup = BeautifulSoup(HTML, 'html.parser')\n",
    "\n",
    "    # Bird name \n",
    "    if len(soup.title.text.split(' - ')) == 4:\n",
    "\n",
    "        BirdName = soup.title\\\n",
    "                        .text\\\n",
    "                        .split(' - ')[1]\\\n",
    "                        .lstrip()\n",
    "    else:\n",
    "        BirdName = soup.title\\\n",
    "                    .text\\\n",
    "                    .split(' - ')[0]\\\n",
    "                    .lstrip()\n",
    "        \n",
    "    # Dump XML for testing\n",
    "    XMLdump[BirdName].append(soup)\n",
    "        \n",
    "    # Find all text data\n",
    "    Paragraphs = soup.find_all('p')\n",
    "\n",
    "    # Loop over the text\n",
    "    for Para in Paragraphs[1:]:\n",
    "        try:\n",
    "\n",
    "            # Check to which section the text belongs\n",
    "            SubSection = Para.find_previous_siblings()[0]\\\n",
    "                             .text[0:50]\\\n",
    "                             .rstrip()\\\n",
    "                             .lstrip()\n",
    "            #print(SubSection)\n",
    "\n",
    "            # Check to which section the text belongs\n",
    "            SubSubSection = Para.find_previous_siblings()[-1]\\\n",
    "                                 .text\\\n",
    "                                 .rstrip()\\\n",
    "                                 .lstrip()\n",
    "            \n",
    "            #print(SubSubSection)\n",
    "\n",
    "        # If a text does not have a header, skip    \n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        ### THESE LINES MAY BE REMOVED###\n",
    "        # Exceptions\n",
    "        #if 'Formative' in SubSection:\n",
    "        #    continue\n",
    "        #if 'Juvenile' in SubSection:\n",
    "        #    continue\n",
    "        #if 'Immature' in SubSection:\n",
    "        #    continue\n",
    "        ### THESE LINES MAY BE REMOVED###\n",
    "        \n",
    "        # CHeck if Subsection is about juveniles\n",
    "        if all(s not in SubSection for s in ['Immature', 'Juvenile', 'Formative', 'Chick', 'Natal']) == False:\n",
    "            continue\n",
    "        \n",
    "        # Check if the information given in a text contains info about juveniles\n",
    "        try:\n",
    "            if Para.find('b').text.startswith(('Immature', 'Juvenile', 'Formative', 'Chick')) or\\\n",
    "            Para['class'][0] == 'u-text-2':\n",
    "                    continue\n",
    "        \n",
    "        except:\n",
    "            # See which are needed and append with 1\n",
    "            if SubSection in ['Identification', 'Adult', 'Measurements'] or\\\n",
    "               SubSubSection in ['Plumages', 'Bare Parts', 'Identification', 'Measurements']:\n",
    "        \n",
    "                # Clean the text from references \n",
    "                TextCleaned = Para.text\n",
    "\n",
    "                # Remove sources\n",
    "                for Remover in SourceRemover:\n",
    "                    TextCleaned = re.sub(Remover, '', TextCleaned, flags=re.DOTALL)\n",
    "\n",
    "                # Drop useless short nonsense\n",
    "                if len(TextCleaned.split()) <2:\n",
    "                    continue\n",
    "                else:\n",
    "                    DataBOW[BirdName].append(tuple([1, TextCleaned]))\n",
    "\n",
    "            # Otherwise label 2        \n",
    "            else:\n",
    "\n",
    "                # Clean the text from references \n",
    "                TextCleaned = Para.text\n",
    "\n",
    "                # Remove sources\n",
    "                for Remover in SourceRemover:\n",
    "                    TextCleaned = re.sub(Remover, '', TextCleaned, flags=re.DOTALL)\n",
    "\n",
    "                # Drop useless short nonsense\n",
    "                if len(TextCleaned.split()) <2:\n",
    "                    continue\n",
    "                else:\n",
    "                    DataBOW[BirdName].append(tuple([0, TextCleaned]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e06da9d7-ed1b-4914-a2b3-0b308e3216bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataBOW_withMeasurements.pkl', 'wb') as f:\n",
    "    pickle.dump(DataBOW, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12c43f-5843-4569-8065-4f5c0f08f8af",
   "metadata": {},
   "source": [
    "# All Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440b5886-a0c1-40a0-940a-9b8d8eaa44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dict\n",
    "DataBOW = collections.defaultdict(list)\n",
    "\n",
    "# XML dump for testing\n",
    "XMLdump = collections.defaultdict(list)\n",
    "\n",
    "# Loop over the test set\n",
    "for Bird in BOWpages[0:10]:\n",
    "    \n",
    "    browser.get(Bird + 'appearance')\n",
    "    #browser.get('https://birdsoftheworld.org/bow/species/norcar/cur/appearance')\n",
    "    SleepTime = random.randint(2, 6)\n",
    "    time.sleep(SleepTime)\n",
    "    \n",
    "    HTML = browser.page_source\n",
    "    soup = BeautifulSoup(HTML, 'html.parser')\n",
    "\n",
    "    # Bird name \n",
    "    BirdName = soup.title.text.split(' - ')[1].lstrip()\n",
    "    \n",
    "    # Dump XML for testing\n",
    "    XMLdump[BirdName].append(soup)\n",
    "        \n",
    "    # Find all text data\n",
    "    Paragraphs = soup.find_all('p')\n",
    "\n",
    "    # Loop over the text\n",
    "    for Para in Paragraphs[1:]:\n",
    "        if Para.startswith(\"Editor's Note: This is a shorter format account\"):\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d06225-feef-4293-819c-b54c5f7b72aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataBOW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ece5f960914a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDataBOW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'DataBOW' is not defined"
     ]
    }
   ],
   "source": [
    "DataBOW.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d316266-cb04-4a6b-bb4f-619f22aa2b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Highland Tinamou'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title\\\n",
    "                        .text\\\n",
    "                        .split(' - ')[1]\\\n",
    "                        .lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9488c49-6a39-4ed8-a28d-82dc97b7d4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
