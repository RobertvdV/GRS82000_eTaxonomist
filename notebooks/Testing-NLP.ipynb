{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d19423-061e-4cc9-b37d-2ff2ce09710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5ac48f-b2bc-4ee9-b49b-415310aef0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/List_of_mammals_of_Europe'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find all wikiparts\n",
    "Animals = soup.find_all('a')\n",
    "# Create links \n",
    "AnimalsWikiPages = ['https://en.wikipedia.org/' + pages.get('href') for pages in Animals \n",
    "                       if pages.get('href') != None \n",
    "                       if pages.get('href').startswith('/wiki/')]\n",
    "                       # Reduces the retrieved pages (does not work)\n",
    "                       #if pages.span != None \n",
    "                       #if pages.span.attrs['class'][0] == 'tocnumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2039ea5c-9aaf-45d3-855c-5821c88bbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "data = []\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "for WikiPage in AnimalsWikiPages[:]:\n",
    "    \n",
    "    # Open the page\n",
    "    page = requests.get(WikiPage, timeout=5)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    for Tags in soup.find_all('h2'):\n",
    "\n",
    "        # Skip useless/empty stuff\n",
    "        if Tags.span == None:\n",
    "            continue\n",
    "\n",
    "        # Set chapter variable    \n",
    "        Chapter = Tags.span.attrs['id']\n",
    "\n",
    "        # Check if the chapter is description (or similar)\n",
    "        if Chapter == 'Characteristics'or \\\n",
    "           Chapter == 'Description' or \\\n",
    "           Chapter == 'Appearance':\n",
    "\n",
    "            # Get the next sibling (text)\n",
    "            for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "                # Add description data to dict\n",
    "                if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    data += [(1, Sentence) for Sentence in SentenceList]\n",
    "\n",
    "                # Add non description data to dict\n",
    "                elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    data += [(2, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "362c398b-9358-48bc-87a5-40676264a56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18867"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6ff5b153-25ce-4c82-8829-84d1ef9f9071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3573"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TruthData = [i for i in data if i[0] == 1]\n",
    "len(TruthData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c52af21-0669-46c4-ba4a-d5f9e67a291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test sequence\n",
    "train = int(len(data) * 0.8)\n",
    "test = len(data) - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b7a28752-0d7f-4be2-85d3-32edd6048409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc90c63-95b6-4a81-aa04-d6c94c369d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "trainset = data[0:train]\n",
    "testset = data[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708d5b7b-bc04-4e2a-a60d-7d772aeae649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic English\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Tokenize the dataset\n",
    "def yield_tokens(data_iter):\n",
    "    # Drop the label (label, text)\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Build a vocabulary        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(trainset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6ce8fa-9f29-4127-a754-a9e35b14c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "# -1 could be removed if data is loaded differently\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b4b51979-1c1c-4e6f-9b6c-936eff41b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   2,    8,   77,    3,    1,    2,  261,   10,   43, 3125,    7])\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "proc = torch.tensor(text_pipeline('the a whale and, the bear are not equal.'), dtype=torch.int64)\n",
    "print(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa2995c1-cb7d-4c68-bcd0-b06e70622b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (CPU for macs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \n",
    "    # Init lists\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    \n",
    "    # Loop over the data\n",
    "    for (_label, _text) in batch:\n",
    "        # Append the labels to list\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        # Process the text (singed 64), and convert to tensor\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        # Append the text to list \n",
    "        text_list.append(processed_text)\n",
    "        # Append the offset (tensor size)   \n",
    "        offsets.append(processed_text.size(0))\n",
    "    \n",
    "    # Convert the label list to a tensor\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    # Cummulative sum the offsets (dim=0 == rowwise)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    # Concatenate the text list\n",
    "    text_list = torch.cat(text_list)\n",
    "    \n",
    "    # Return the values\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "533c99c8-bb8c-41f0-91da-a64be4fb783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "dataloader = DataLoader(train_iter, batch_size=16, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e0583f2f-dcda-4c29-a4a5-562259e7a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1]),\n",
       " tensor([   19,     9,   713,     4,   953,  2420,     5,  3705,   540,   476,\n",
       "          1826,     1,    14,   355,     1,  4193,  1826,  2383,     8,  1812,\n",
       "             5,   582,     1,  2253,  1080,    14,     2,  1379,     5,     8,\n",
       "           331,   178,    77,   304,     4,  1768,     1,     2,  5983,   312,\n",
       "            22,    35,  4111,    16,   133,    20,     8,  1433,     5,  2043,\n",
       "          6708,     1, 13992,     4,     8,   360,   463,  5772, 12640,  3936,\n",
       "          5675,     4,   944,  1486,    23,  2790,     2,   348,   501,  1417,\n",
       "          2343,     6,  4109,    42,  1193,  2118, 10718,     4, 14427,     1,\n",
       "            18,   564,     1,   291,    99,    22,    35,  2895,   177,  2838,\n",
       "             1,     3,    22,  3113,     4,  1066, 13754,     4, 16034,     2,\n",
       "           684,  1986,     9,   118,  2638,     4,  4113,     3,  3176,    40,\n",
       "           164,   292,     4,   222,     2,   232,   661,    92,     9,   775,\n",
       "          1446,    13,   766,    15,     2,   526,    71,   973,     5,   434,\n",
       "            24,   105,  1298,   447,    10,     2,  2202,     5,  8895,    51,\n",
       "           457,  1944,     3,     2,  1298,   949,     1,    14,     2,  9982,\n",
       "             5, 10146,  3241,   133,    23,   279,    43,  2618,     2,    24,\n",
       "            26,  1111,     5,  1041,     7,     4,    56,    24,    62,    13,\n",
       "             2,  8277,     1,     2,   429,   380,    37,   602,    20,     2,\n",
       "           223,     2,   526,     3,  3433,  1417,  8661,   203,  4910,     1,\n",
       "          1053,     3,  3382,  6894,     1,  1178,  1318,     1,  5865,    18,\n",
       "          1539,     3,   539,   477,    13,   879,     6,     2,  2335,  1117,\n",
       "             5,   402,    77,  2470,     7,  1435,     6,     2,   222,     1,\n",
       "           149,     1,     3,    56,  2128,  7175,     1,    21,    22,     8,\n",
       "         19203, 13488,     7,     4,    56,    63,     5,     2,  1482,     1,\n",
       "           107,    11,   337,  2552,   107,   137,     6,    17,  2115,   603,\n",
       "            12,    22,    35,  3161,    13,     8,   518,  2623,    18,  2819,\n",
       "             5,  2376,  3523,     1,     8,   585,    34,     4,     2,  1482,\n",
       "             4,   933,  3602, 20653,   485,     4,  2268,     6,  9018,    18,\n",
       "           564,     1,    17,  9302,    10,   129,     4,     2,  3939,     5,\n",
       "             2,   458,   296, 18033, 18637, 15490,   633,  4711,     9,    43,\n",
       "          1095,    83,     2,  5368,    20,  9097,     1,    40,    20,  2731,\n",
       "             4,     2,   208,     2,   232,   352,    92,   794,    65,     6,\n",
       "           392,   797,    11,    58,     7,    58,   364,    12,     3,    37,\n",
       "           170,    65,     6,   392,    68,     2,   100,     9,   355,     3,\n",
       "           164, 20141,    44,     2,   119,  2775,  1989,   239,   148,    69,\n",
       "           998,    23,  4009,     4, 10556,     1,  1582,     1,  1724,     1,\n",
       "             3,   599,   246,  1926,     1,   605,   126,    24,     5,   787,\n",
       "             1,   163,    56,    23,    10, 10199,     6,    41,    94,   430,\n",
       "             2, 11605, 10492,  3194,     1,   126,   176,    24,    33,  2547,\n",
       "            13,   518,   383,  3470,     5,     2,  6703,  6782,     1,  7651]),\n",
       " tensor([  0,  25,  77,  99, 114, 131, 165, 181, 215, 233, 279, 296, 313, 335,\n",
       "         346, 379]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3a49b6e0-7eb0-46b7-b743-c8528401b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1144cfc2-43c0-44d0-9f5c-493cc449e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ede95da0-ce09-4593-b1dd-0a0c0da61d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "12ca46ca-7f2a-43e6-bbb5-e1781dd0f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/  897 batches | accuracy    0.848\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.30s | valid accuracy    0.881 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/  897 batches | accuracy    0.901\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.24s | valid accuracy    0.914 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/  897 batches | accuracy    0.922\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.24s | valid accuracy    0.889 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/  897 batches | accuracy    0.935\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.22s | valid accuracy    0.914 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/  897 batches | accuracy    0.941\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.22s | valid accuracy    0.919 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/  897 batches | accuracy    0.940\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.21s | valid accuracy    0.914 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/  897 batches | accuracy    0.946\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.22s | valid accuracy    0.915 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/  897 batches | accuracy    0.943\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.23s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/  897 batches | accuracy    0.945\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.23s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/  897 batches | accuracy    0.943\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.22s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 16 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = trainset, testset\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c85ffde5-d8d3-477a-9e7b-621066b9f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.900\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b64ebfcb-a5a5-4bce-93bd-dec92c8d7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a description or similar.\n"
     ]
    }
   ],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         2: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"\"\"\n",
    "One of the largest of living carnivores, grizzly bears are 1 to 2.8 meters in length from head to rump and\\\n",
    "their tails are 65 to 210 mm long. They are 90 to 150 cm tall at the shoulder and can tower at an intimidating\\\n",
    "height of 8 feet when standing upright on their hind legs. They range in weight from 80 to more than 600 kg. \\\n",
    "On average, adult males are 8 to 10% larger than females. Ursus arctos is largest along the the coast of southern\\\n",
    "Alaska and on nearby islands where males average 389 kg and females average 207 kg, though some males have been weighed \\\n",
    "at as much as 780 kg. Distance between the canines is from 6 to 8 cm. Size rapidly declines to the north and east, with\\\n",
    "individuals in southwestern Yukon weighing only 140 kg on average. Fur is usually dark brown, but varies from cream to almost black.\\\n",
    "Individuals in the Rocky Mountains have long hairs along the shoulders and back which are frosted with white, giving a grizzled appearance,\\\n",
    "hence the common name grizzly bear in that region. Brown bears are extremely strong and have good endurance; they\\\n",
    "can kill a cow with one blow, outrun a horse, outswim an Olympian, and drag a dead elk uphill. (Wilson and Ruff, 1999)\"\"\"    \n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14c71d33-b09c-43f9-8a3b-3b6fc75a3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "ExtraTesting = []\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Eurasian_wigeon'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "for Tags in soup.find_all('h2'):\n",
    "\n",
    "    # Skip useless/empty stuff\n",
    "    if Tags.span == None:\n",
    "        continue\n",
    "\n",
    "    # Set chapter variable    \n",
    "    Chapter = Tags.span.attrs['id']\n",
    "\n",
    "    # Check if the chapter is description (or similar)\n",
    "    if Chapter == 'Characteristics'or \\\n",
    "       Chapter == 'Description' or \\\n",
    "       Chapter == 'Appearance':\n",
    "\n",
    "        # Get the next sibling (text)\n",
    "        for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "            # Add description data to dict\n",
    "            if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(1, Sentence) for Sentence in SentenceList]\n",
    "\n",
    "            # Add non description data to dict\n",
    "            elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(0, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2597ada4-0238-4f00-9a77-35fe42c0881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a description or similar.\n",
      "Real value was 1\n",
      "This dabbling duck is 42–52 cm (17–20 in) long with a 71–80 cm (28–31 in) wingspan, and a weight of 500–1,073 g (1.102–2.366 lb)\n",
      "\n",
      "\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "The breeding male has grey flanks and back, with a black rear end, a dark green speculum and a brilliant white patch on upper wings, obvious in flight or at rest\n",
      "\n",
      "\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "It has a pink breast, white belly, and a chestnut head with a creamy crown\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 1\n",
      "In non-breeding (eclipse) plumage, the drake looks more like the female\n",
      "\n",
      "\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "The female is light brown, with plumage much like a female American wigeon\n",
      "\n",
      "\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "It can be distinguished from most other ducks, apart from American wigeon, on shape\n",
      "\n",
      "\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "However, that species has a paler head and white axillaries on its underwing\n",
      "\n",
      "\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "The female can be a rufous morph with a redder head, and a gray morph with a more gray head.\n",
      "\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It breeds in the northernmost areas of Europe and the Palearctic\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It is the Old World counterpart of North America's American wigeon\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It is strongly migratory and winters further south than its breeding range\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It migrates to southern Asia and Africa\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "In Great Britain and Ireland, the Eurasian wigeon is common as a winter visitor, but scarce as a breeding bird in Scotland, the Lake District, the Pennines and occasionally further south, with only a handful of breeding pairs in Ireland\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It can be found as an uncommon winter visitor in the United States on the mid-Atlantic and Pacific coasts\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It is a rare visitor to the rest of the United States except for the Four Corners and the southern Appalachians.\n",
      "\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "The Eurasian wigeon is a bird of open wetlands, such as wet grassland or marshes with some taller vegetation, and usually feeds by dabbling for plant food or grazing, which it does very readily\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It nests on the ground, near water and under cover\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "It is highly gregarious outside of the breeding season and will form large flocks\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "They will join with flocks of the American wigeon in the United States, and they also hybridize with them\n",
      "\n",
      "\n",
      "This is a description or similar.\n",
      "Real value was 0\n",
      "This is a noisy species\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "The male has a clear whistle that sounds like: \"pjiew pjiew\", whereas the female has a low growl: \"rawr\".\n",
      "\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "The Eurasian wigeon is one of the species to which the Agreement on the Conservation of African-Eurasian Migratory Waterbirds (AEWA) applies\n",
      "\n",
      "\n",
      "This is something else.\n",
      "Real value was 0\n",
      "Its conservation status is least concern.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         2: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "for tests in ExtraTesting:\n",
    "    ex_text_str = tests[1]\n",
    "    \n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "    print(\"Real value was {0}\".format(tests[0]))\n",
    "    print(tests[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25eb47-da5e-4001-929b-962a7a885bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
