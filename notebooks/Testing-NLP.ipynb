{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d19423-061e-4cc9-b37d-2ff2ce09710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5ac48f-b2bc-4ee9-b49b-415310aef0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/List_of_mammals_of_Europe'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find all wikiparts\n",
    "Animals = soup.find_all('a')\n",
    "# Create links \n",
    "AnimalsWikiPages = ['https://en.wikipedia.org/' + pages.get('href') for pages in Animals \n",
    "                       if pages.get('href') != None \n",
    "                       if pages.get('href').startswith('/wiki/')]\n",
    "                       # Reduces the retrieved pages (does not work)\n",
    "                       #if pages.span != None \n",
    "                       #if pages.span.attrs['class'][0] == 'tocnumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2039ea5c-9aaf-45d3-855c-5821c88bbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "data = []\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "for WikiPage in AnimalsWikiPages[:]:\n",
    "    \n",
    "    # Open the page\n",
    "    page = requests.get(WikiPage, timeout=5)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    for Tags in soup.find_all('h2'):\n",
    "\n",
    "        # Skip useless/empty stuff\n",
    "        if Tags.span == None:\n",
    "            continue\n",
    "\n",
    "        # Set chapter variable    \n",
    "        Chapter = Tags.span.attrs['id']\n",
    "\n",
    "        # Check if the chapter is description (or similar)\n",
    "        if Chapter == 'Characteristics'or \\\n",
    "           Chapter == 'Description' or \\\n",
    "           Chapter == 'Appearance':\n",
    "\n",
    "            # Get the next sibling (text)\n",
    "            for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "                # Add description data to dict\n",
    "                if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    data += [(1, Sentence) for Sentence in SentenceList]\n",
    "\n",
    "                # Add non description data to dict\n",
    "                elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    data += [(2, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362c398b-9358-48bc-87a5-40676264a56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18867"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c52af21-0669-46c4-ba4a-d5f9e67a291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test sequence\n",
    "train = int(len(data) * 0.8)\n",
    "test = len(data) - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a28752-0d7f-4be2-85d3-32edd6048409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc90c63-95b6-4a81-aa04-d6c94c369d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "trainset = data[0:train]\n",
    "testset = data[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22793ba-17cf-4a31-8690-0ef86cd02dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708d5b7b-bc04-4e2a-a60d-7d772aeae649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic English\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Tokenize the dataset\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Build a vocabulary        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(trainset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6ce8fa-9f29-4127-a754-a9e35b14c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b51979-1c1c-4e6f-9b6c-936eff41b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 77, 3, 2, 261, 10, 43, 3125, 7]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('the whale and the bear are not equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2995c1-cb7d-4c68-bcd0-b06e70622b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (CPU for macs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533c99c8-bb8c-41f0-91da-a64be4fb783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a49b6e0-7eb0-46b7-b743-c8528401b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1144cfc2-43c0-44d0-9f5c-493cc449e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ede95da0-ce09-4593-b1dd-0a0c0da61d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ca46ca-7f2a-43e6-bbb5-e1781dd0f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 7169 batches | accuracy    0.792\n",
      "| epoch   1 |  1000/ 7169 batches | accuracy    0.842\n",
      "| epoch   1 |  1500/ 7169 batches | accuracy    0.853\n",
      "| epoch   1 |  2000/ 7169 batches | accuracy    0.868\n",
      "| epoch   1 |  2500/ 7169 batches | accuracy    0.865\n",
      "| epoch   1 |  3000/ 7169 batches | accuracy    0.906\n",
      "| epoch   1 |  3500/ 7169 batches | accuracy    0.879\n",
      "| epoch   1 |  4000/ 7169 batches | accuracy    0.895\n",
      "| epoch   1 |  4500/ 7169 batches | accuracy    0.871\n",
      "| epoch   1 |  5000/ 7169 batches | accuracy    0.890\n",
      "| epoch   1 |  5500/ 7169 batches | accuracy    0.885\n",
      "| epoch   1 |  6000/ 7169 batches | accuracy    0.889\n",
      "| epoch   1 |  6500/ 7169 batches | accuracy    0.907\n",
      "| epoch   1 |  7000/ 7169 batches | accuracy    0.890\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  4.95s | valid accuracy    0.882 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 7169 batches | accuracy    0.912\n",
      "| epoch   2 |  1000/ 7169 batches | accuracy    0.922\n",
      "| epoch   2 |  1500/ 7169 batches | accuracy    0.919\n",
      "| epoch   2 |  2000/ 7169 batches | accuracy    0.909\n",
      "| epoch   2 |  2500/ 7169 batches | accuracy    0.922\n",
      "| epoch   2 |  3000/ 7169 batches | accuracy    0.895\n",
      "| epoch   2 |  3500/ 7169 batches | accuracy    0.916\n",
      "| epoch   2 |  4000/ 7169 batches | accuracy    0.897\n",
      "| epoch   2 |  4500/ 7169 batches | accuracy    0.896\n",
      "| epoch   2 |  5000/ 7169 batches | accuracy    0.916\n",
      "| epoch   2 |  5500/ 7169 batches | accuracy    0.902\n",
      "| epoch   2 |  6000/ 7169 batches | accuracy    0.907\n",
      "| epoch   2 |  6500/ 7169 batches | accuracy    0.925\n",
      "| epoch   2 |  7000/ 7169 batches | accuracy    0.926\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  4.90s | valid accuracy    0.925 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/ 7169 batches | accuracy    0.931\n",
      "| epoch   3 |  1000/ 7169 batches | accuracy    0.920\n",
      "| epoch   3 |  1500/ 7169 batches | accuracy    0.922\n",
      "| epoch   3 |  2000/ 7169 batches | accuracy    0.934\n",
      "| epoch   3 |  2500/ 7169 batches | accuracy    0.918\n",
      "| epoch   3 |  3000/ 7169 batches | accuracy    0.928\n",
      "| epoch   3 |  3500/ 7169 batches | accuracy    0.934\n",
      "| epoch   3 |  4000/ 7169 batches | accuracy    0.933\n",
      "| epoch   3 |  4500/ 7169 batches | accuracy    0.940\n",
      "| epoch   3 |  5000/ 7169 batches | accuracy    0.918\n",
      "| epoch   3 |  5500/ 7169 batches | accuracy    0.919\n",
      "| epoch   3 |  6000/ 7169 batches | accuracy    0.929\n",
      "| epoch   3 |  6500/ 7169 batches | accuracy    0.923\n",
      "| epoch   3 |  7000/ 7169 batches | accuracy    0.938\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  4.90s | valid accuracy    0.918 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/ 7169 batches | accuracy    0.943\n",
      "| epoch   4 |  1000/ 7169 batches | accuracy    0.921\n",
      "| epoch   4 |  1500/ 7169 batches | accuracy    0.949\n",
      "| epoch   4 |  2000/ 7169 batches | accuracy    0.940\n",
      "| epoch   4 |  2500/ 7169 batches | accuracy    0.937\n",
      "| epoch   4 |  3000/ 7169 batches | accuracy    0.945\n",
      "| epoch   4 |  3500/ 7169 batches | accuracy    0.945\n",
      "| epoch   4 |  4000/ 7169 batches | accuracy    0.954\n",
      "| epoch   4 |  4500/ 7169 batches | accuracy    0.952\n",
      "| epoch   4 |  5000/ 7169 batches | accuracy    0.952\n",
      "| epoch   4 |  5500/ 7169 batches | accuracy    0.942\n",
      "| epoch   4 |  6000/ 7169 batches | accuracy    0.949\n",
      "| epoch   4 |  6500/ 7169 batches | accuracy    0.936\n",
      "| epoch   4 |  7000/ 7169 batches | accuracy    0.937\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  4.83s | valid accuracy    0.921 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/ 7169 batches | accuracy    0.954\n",
      "| epoch   5 |  1000/ 7169 batches | accuracy    0.961\n",
      "| epoch   5 |  1500/ 7169 batches | accuracy    0.936\n",
      "| epoch   5 |  2000/ 7169 batches | accuracy    0.947\n",
      "| epoch   5 |  2500/ 7169 batches | accuracy    0.944\n",
      "| epoch   5 |  3000/ 7169 batches | accuracy    0.937\n",
      "| epoch   5 |  3500/ 7169 batches | accuracy    0.948\n",
      "| epoch   5 |  4000/ 7169 batches | accuracy    0.950\n",
      "| epoch   5 |  4500/ 7169 batches | accuracy    0.947\n",
      "| epoch   5 |  5000/ 7169 batches | accuracy    0.935\n",
      "| epoch   5 |  5500/ 7169 batches | accuracy    0.958\n",
      "| epoch   5 |  6000/ 7169 batches | accuracy    0.942\n",
      "| epoch   5 |  6500/ 7169 batches | accuracy    0.946\n",
      "| epoch   5 |  7000/ 7169 batches | accuracy    0.937\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  4.94s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/ 7169 batches | accuracy    0.938\n",
      "| epoch   6 |  1000/ 7169 batches | accuracy    0.948\n",
      "| epoch   6 |  1500/ 7169 batches | accuracy    0.959\n",
      "| epoch   6 |  2000/ 7169 batches | accuracy    0.943\n",
      "| epoch   6 |  2500/ 7169 batches | accuracy    0.944\n",
      "| epoch   6 |  3000/ 7169 batches | accuracy    0.960\n",
      "| epoch   6 |  3500/ 7169 batches | accuracy    0.938\n",
      "| epoch   6 |  4000/ 7169 batches | accuracy    0.950\n",
      "| epoch   6 |  4500/ 7169 batches | accuracy    0.946\n",
      "| epoch   6 |  5000/ 7169 batches | accuracy    0.940\n",
      "| epoch   6 |  5500/ 7169 batches | accuracy    0.941\n",
      "| epoch   6 |  6000/ 7169 batches | accuracy    0.936\n",
      "| epoch   6 |  6500/ 7169 batches | accuracy    0.940\n",
      "| epoch   6 |  7000/ 7169 batches | accuracy    0.945\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  4.83s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/ 7169 batches | accuracy    0.943\n",
      "| epoch   7 |  1000/ 7169 batches | accuracy    0.948\n",
      "| epoch   7 |  1500/ 7169 batches | accuracy    0.955\n",
      "| epoch   7 |  2000/ 7169 batches | accuracy    0.950\n",
      "| epoch   7 |  2500/ 7169 batches | accuracy    0.950\n",
      "| epoch   7 |  3000/ 7169 batches | accuracy    0.948\n",
      "| epoch   7 |  3500/ 7169 batches | accuracy    0.934\n",
      "| epoch   7 |  4000/ 7169 batches | accuracy    0.942\n",
      "| epoch   7 |  4500/ 7169 batches | accuracy    0.937\n",
      "| epoch   7 |  5000/ 7169 batches | accuracy    0.942\n",
      "| epoch   7 |  5500/ 7169 batches | accuracy    0.954\n",
      "| epoch   7 |  6000/ 7169 batches | accuracy    0.941\n",
      "| epoch   7 |  6500/ 7169 batches | accuracy    0.943\n",
      "| epoch   7 |  7000/ 7169 batches | accuracy    0.945\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  4.86s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/ 7169 batches | accuracy    0.951\n",
      "| epoch   8 |  1000/ 7169 batches | accuracy    0.939\n",
      "| epoch   8 |  1500/ 7169 batches | accuracy    0.949\n",
      "| epoch   8 |  2000/ 7169 batches | accuracy    0.936\n",
      "| epoch   8 |  2500/ 7169 batches | accuracy    0.944\n",
      "| epoch   8 |  3000/ 7169 batches | accuracy    0.933\n",
      "| epoch   8 |  3500/ 7169 batches | accuracy    0.952\n",
      "| epoch   8 |  4000/ 7169 batches | accuracy    0.960\n",
      "| epoch   8 |  4500/ 7169 batches | accuracy    0.944\n",
      "| epoch   8 |  5000/ 7169 batches | accuracy    0.950\n",
      "| epoch   8 |  5500/ 7169 batches | accuracy    0.945\n",
      "| epoch   8 |  6000/ 7169 batches | accuracy    0.948\n",
      "| epoch   8 |  6500/ 7169 batches | accuracy    0.933\n",
      "| epoch   8 |  7000/ 7169 batches | accuracy    0.951\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  4.82s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/ 7169 batches | accuracy    0.945\n",
      "| epoch   9 |  1000/ 7169 batches | accuracy    0.954\n",
      "| epoch   9 |  1500/ 7169 batches | accuracy    0.953\n",
      "| epoch   9 |  2000/ 7169 batches | accuracy    0.946\n",
      "| epoch   9 |  2500/ 7169 batches | accuracy    0.945\n",
      "| epoch   9 |  3000/ 7169 batches | accuracy    0.943\n",
      "| epoch   9 |  3500/ 7169 batches | accuracy    0.952\n",
      "| epoch   9 |  4000/ 7169 batches | accuracy    0.949\n",
      "| epoch   9 |  4500/ 7169 batches | accuracy    0.952\n",
      "| epoch   9 |  5000/ 7169 batches | accuracy    0.943\n",
      "| epoch   9 |  5500/ 7169 batches | accuracy    0.946\n",
      "| epoch   9 |  6000/ 7169 batches | accuracy    0.937\n",
      "| epoch   9 |  6500/ 7169 batches | accuracy    0.932\n",
      "| epoch   9 |  7000/ 7169 batches | accuracy    0.941\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  4.88s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/ 7169 batches | accuracy    0.949\n",
      "| epoch  10 |  1000/ 7169 batches | accuracy    0.940\n",
      "| epoch  10 |  1500/ 7169 batches | accuracy    0.952\n",
      "| epoch  10 |  2000/ 7169 batches | accuracy    0.948\n",
      "| epoch  10 |  2500/ 7169 batches | accuracy    0.953\n",
      "| epoch  10 |  3000/ 7169 batches | accuracy    0.952\n",
      "| epoch  10 |  3500/ 7169 batches | accuracy    0.942\n",
      "| epoch  10 |  4000/ 7169 batches | accuracy    0.945\n",
      "| epoch  10 |  4500/ 7169 batches | accuracy    0.942\n",
      "| epoch  10 |  5000/ 7169 batches | accuracy    0.938\n",
      "| epoch  10 |  5500/ 7169 batches | accuracy    0.950\n",
      "| epoch  10 |  6000/ 7169 batches | accuracy    0.934\n",
      "| epoch  10 |  6500/ 7169 batches | accuracy    0.945\n",
      "| epoch  10 |  7000/ 7169 batches | accuracy    0.935\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  4.85s | valid accuracy    0.923 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 2 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = trainset, testset\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c85ffde5-d8d3-477a-9e7b-621066b9f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.899\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b64ebfcb-a5a5-4bce-93bd-dec92c8d7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a description or similar.\n"
     ]
    }
   ],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         2: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "ex_text_str = \"\"\"\n",
    "No pochard has a metallic coloured speculum, something that is characteristic of other ducks.\\n'\n",
    "\"\"\"    \n",
    "    \n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14c71d33-b09c-43f9-8a3b-3b6fc75a3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "ExtraTesting = []\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Common_goldeneye'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "for Tags in soup.find_all('h2'):\n",
    "\n",
    "    # Skip useless/empty stuff\n",
    "    if Tags.span == None:\n",
    "        continue\n",
    "\n",
    "    # Set chapter variable    \n",
    "    Chapter = Tags.span.attrs['id']\n",
    "\n",
    "    # Check if the chapter is description (or similar)\n",
    "    if Chapter == 'Characteristics'or \\\n",
    "       Chapter == 'Description' or \\\n",
    "       Chapter == 'Appearance':\n",
    "\n",
    "        # Get the next sibling (text)\n",
    "        for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "            # Add description data to dict\n",
    "            if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(1, Sentence) for Sentence in SentenceList]\n",
    "\n",
    "            # Add non description data to dict\n",
    "            elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(0, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12ed2461-605c-4819-af62-0d1e205815f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adult males ranges from 45–51\\xa0cm (18–20\\xa0in) and weigh approximately 1,000\\xa0g (2.2\\xa0lb), while females range from 40–50\\xa0cm (16–20\\xa0in) and weigh approximately 800\\xa0g (1.8\\xa0lb)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtraTesting[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2597ada4-0238-4f00-9a77-35fe42c0881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a description or similar.\n",
      "Real value was 1\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "This is a description or similar.\n",
      "Real value was 1\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is a description or similar.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n",
      "This is something else.\n",
      "Real value was 0\n"
     ]
    }
   ],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         2: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() + 1\n",
    "\n",
    "for tests in ExtraTesting[0:100]:\n",
    "    ex_text_str = tests[1]\n",
    "    \n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "    print(\"Real value was {0}\".format(tests[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25eb47-da5e-4001-929b-962a7a885bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
