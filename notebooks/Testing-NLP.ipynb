{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d19423-061e-4cc9-b37d-2ff2ce09710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch import nn\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbfe3cd-dc36-4c65-8074-c47cdc70d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pickle_in = open(\"data_withMeasurements.pkl\", \"rb\")\n",
    "dataWIKI = pickle.load(pickle_in)\n",
    "\n",
    "# Load data\n",
    "pickle_in = open(\"dataBOW_withMeasurements.pkl\", \"rb\")\n",
    "dataBOW = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1601b1ff-4029-4c72-8a2d-99da9c97de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pickle_in = open(\"dataBOW.pkl\", \"rb\")\n",
    "dataBOW_noM = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5ea41b-c226-4e99-931e-f8591af0eb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'Tinamous are pudgy, terrestrial birds with very short tails and rounded wings. The three species of Nothocercus are medium sized tinamous of humid montane forests. Highland Tinamou is a dark reddish brown tinamou; the upperparts are finely black vermiculated with black, and the underparts are cinnamon brown. The crown and sides of the head are black or blackish, while the throat is ochraceous to rufous. The sexes are similar in appearance.'),\n",
       " (0,\n",
       "  'Highland Tinamou is sympatric with few other species of tinamou. Tawny-breasted Tinamou (Nothocercus julius) overlaps with Highland Tinamou in the Andes from Venezuela to Peru, but is found at higher elevations, and has a white throat and dull chestnut to sooty brown (not gray or blackish) head. There is no geographic overlap with Hooded Tinamou (Nothocercus nigrocapillus), which replaces Highland Tinamou south of the Río Marañón in northern Peru; Hooded Tinamou also has a white throat. Gray Tinamou (Tinamus tao) is larger and gray, not brown. Highland Tinamou typically occurs higher in elevation than other species in its geographic range.'),\n",
       " (1,\n",
       "  'The following description is based on Blake (1977), and refers to nominate bonapartei; see also Geographic Variation:'),\n",
       " (1,\n",
       "  'Adult: Sexes alike. Crown and sides of head black or blackish, becoming dark brown on the nape and upperparts, which ere very finely vermiculated with black. Wing coverts slightly paler brown and more or less profusely spotted with buff and black. Remiges dusky, mottled and barred with cinnamon and black, especially on the outer webs. Throat ochraceous or rufous. Breast and abdomen reddish brown, paler on the belly and tibial feathers, which are obscurely barred. Flanks darker brown, the feathers with pale tips and black subterminal spots or bars.'),\n",
       " (1, 'Iris: dark brown'),\n",
       " (1, 'Bill: maxilla black; mandible black, whitish at base'),\n",
       " (1, 'Tarsi and toes: plumbeous'),\n",
       " (1, 'Bare parts color from Wetmore (1965).'),\n",
       " (1,\n",
       "  'Total length: 35.5-38 cm (Ridgely and Greenfield 2001b), 38 cm (Stiles and Skutch 1989), Hilty and Brown (1986), 38-41 cm (Hilty 2003)'),\n",
       " (1, 'Linear measurements (from Blake 1977):'),\n",
       " (1, 'frantzii, male:'),\n",
       " (1, 'wing length (flat): mean 212.5 mm (range 205-220 mm, n = 6)'),\n",
       " (1, 'bill length (culmen from base): mean 33 mm (range 31.2-35.4 mm, n = 8)'),\n",
       " (1, 'tarsus length: mean 69 mm (range 66.6-71.3 mm, n = 8)'),\n",
       " (1, 'frantzii, female:'),\n",
       " (1, 'wing length (flat): mean 226.8 mm (range 221-241 mm, n = 6)'),\n",
       " (1,\n",
       "  'bill length (culmen from base): mean 34.5 mm (range 32.7-36.8 mm, n = 10)'),\n",
       " (1, 'tarsus length: mean 72.5 mm (range 68.1-74.6 mm, n = 10)'),\n",
       " (1, 'intercedens, male (n = 8):'),\n",
       " (1, 'wing length (flat): mean 209.8 mm (range 200-218 mm)'),\n",
       " (1, 'bill length (exposed culmen): mean 29.5 mm (range 28-31 mm)'),\n",
       " (1, 'intercedens, female (n = 7):'),\n",
       " (1, 'wing length (flat): mean 213.4 mm (range 203-224 mm)'),\n",
       " (1, 'bill length (exposed culmen): mean 29.6 mm (range 25-33 mm)'),\n",
       " (1, 'bonapartei, male (n = 7):'),\n",
       " (1, 'wing length (flat): mean 215.2 mm (range 207-226 mm)'),\n",
       " (1, 'bill length (exposed culmen): mean 28.8 mm (range 26-31 mm)'),\n",
       " (1, 'bonapartei, female (n = 5):'),\n",
       " (1, 'wing length (flat): mean 222 mm (range 218-244 mm)'),\n",
       " (1, 'bill length (exposed culmen): mean 31.7 mm (range 30-33 mm)'),\n",
       " (1, 'discrepans, female (holotype; n = 1):'),\n",
       " (1, 'wing length (flat): 228 mm'),\n",
       " (1, 'bill length (exposed culmen) 32 mm'),\n",
       " (1, 'tarrsus length: ca 65 mm'),\n",
       " (1, 'plumbeiceps, male (n = 8):'),\n",
       " (1, 'wing length (flat): mean 204.5 (range 196-214 mm)'),\n",
       " (1, 'bill length (exposed culmen): mean 29 mm (range 26-32 mm)'),\n",
       " (1, 'plumbeiceps, female (n = 3):'),\n",
       " (1, 'wing length (flat): mean 218.3 mm (range 216-222 mm)'),\n",
       " (1, 'bill length (exposed culmen): mean 30.4 mm (range 26-38 mm)'),\n",
       " (1,\n",
       "  'Mass: Published data on mass of Highland Tinamou encompass a surprisingly wide range of values, for which there is not a ready explanation: male 500 g (n = 1), female 455 g (n = 1) (Panama, Hartman 1955); male, mean 844 ± 18.1 g (n = 4), female 1050 g (n = 1) (Panama, Hartman 1961); female, 728 g (n = 1, laying, with fully formed egg in oviduct, Colombia; Miller 1963)')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataBOW['Highland Tinamou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f928b19d-11c4-41f7-9958-9b57fc299e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  'Tinamous are pudgy, terrestrial birds with very short tails and rounded wings. The three species of Nothocercus are medium sized tinamous of humid montane forests. Highland Tinamou is a dark reddish brown tinamou; the upperparts are finely black vermiculated with black, and the underparts are cinnamon brown. The crown and sides of the head are black or blackish, while the throat is ochraceous to rufous. The sexes are similar in appearance.'),\n",
       " (0,\n",
       "  'Highland Tinamou is sympatric with few other species of tinamou. Tawny-breasted Tinamou (Nothocercus julius) overlaps with Highland Tinamou in the Andes from Venezuela to Peru, but is found at higher elevations, and has a white throat and dull chestnut to sooty brown (not gray or blackish) head. There is no geographic overlap with Hooded Tinamou (Nothocercus nigrocapillus), which replaces Highland Tinamou south of the Río Marañón in northern Peru; Hooded Tinamou also has a white throat. Gray Tinamou (Tinamus tao) is larger and gray, not brown. Highland Tinamou typically occurs higher in elevation than other species in its geographic range.'),\n",
       " (1,\n",
       "  'The following description is based on Blake (1977), and refers to nominate bonapartei; see also Geographic Variation:'),\n",
       " (1,\n",
       "  'Adult: Sexes alike. Crown and sides of head black or blackish, becoming dark brown on the nape and upperparts, which ere very finely vermiculated with black. Wing coverts slightly paler brown and more or less profusely spotted with buff and black. Remiges dusky, mottled and barred with cinnamon and black, especially on the outer webs. Throat ochraceous or rufous. Breast and abdomen reddish brown, paler on the belly and tibial feathers, which are obscurely barred. Flanks darker brown, the feathers with pale tips and black subterminal spots or bars.'),\n",
       " (1, 'Iris: dark brown'),\n",
       " (1, 'Bill: maxilla black; mandible black, whitish at base'),\n",
       " (1, 'Tarsi and toes: plumbeous'),\n",
       " (1, 'Bare parts color from Wetmore (1965).'),\n",
       " (0,\n",
       "  'Total length: 35.5-38 cm (Ridgely and Greenfield 2001b), 38 cm (Stiles and Skutch 1989), Hilty and Brown (1986), 38-41 cm (Hilty 2003)'),\n",
       " (0, 'Linear measurements (from Blake 1977):'),\n",
       " (0, 'frantzii, male:'),\n",
       " (0, 'wing length (flat): mean 212.5 mm (range 205-220 mm, n = 6)'),\n",
       " (0, 'bill length (culmen from base): mean 33 mm (range 31.2-35.4 mm, n = 8)'),\n",
       " (0, 'tarsus length: mean 69 mm (range 66.6-71.3 mm, n = 8)'),\n",
       " (0, 'frantzii, female:'),\n",
       " (0, 'wing length (flat): mean 226.8 mm (range 221-241 mm, n = 6)'),\n",
       " (0,\n",
       "  'bill length (culmen from base): mean 34.5 mm (range 32.7-36.8 mm, n = 10)'),\n",
       " (0, 'tarsus length: mean 72.5 mm (range 68.1-74.6 mm, n = 10)'),\n",
       " (0, 'intercedens, male (n = 8):'),\n",
       " (0, 'wing length (flat): mean 209.8 mm (range 200-218 mm)'),\n",
       " (0, 'bill length (exposed culmen): mean 29.5 mm (range 28-31 mm)'),\n",
       " (0, 'intercedens, female (n = 7):'),\n",
       " (0, 'wing length (flat): mean 213.4 mm (range 203-224 mm)'),\n",
       " (0, 'bill length (exposed culmen): mean 29.6 mm (range 25-33 mm)'),\n",
       " (0, 'bonapartei, male (n = 7):'),\n",
       " (0, 'wing length (flat): mean 215.2 mm (range 207-226 mm)'),\n",
       " (0, 'bill length (exposed culmen): mean 28.8 mm (range 26-31 mm)'),\n",
       " (0, 'bonapartei, female (n = 5):'),\n",
       " (0, 'wing length (flat): mean 222 mm (range 218-244 mm)'),\n",
       " (0, 'bill length (exposed culmen): mean 31.7 mm (range 30-33 mm)'),\n",
       " (0, 'discrepans, female (holotype; n = 1):'),\n",
       " (0, 'wing length (flat): 228 mm'),\n",
       " (0, 'bill length (exposed culmen) 32 mm'),\n",
       " (0, 'tarrsus length: ca 65 mm'),\n",
       " (0, 'plumbeiceps, male (n = 8):'),\n",
       " (0, 'wing length (flat): mean 204.5 (range 196-214 mm)'),\n",
       " (0, 'bill length (exposed culmen): mean 29 mm (range 26-32 mm)'),\n",
       " (0, 'plumbeiceps, female (n = 3):'),\n",
       " (0, 'wing length (flat): mean 218.3 mm (range 216-222 mm)'),\n",
       " (0, 'bill length (exposed culmen): mean 30.4 mm (range 26-38 mm)'),\n",
       " (0,\n",
       "  'Mass: Published data on mass of Highland Tinamou encompass a surprisingly wide range of values, for which there is not a ready explanation: male 500 g (n = 1), female 455 g (n = 1) (Panama, Hartman 1955); male, mean 844 ± 18.1 g (n = 4), female 1050 g (n = 1) (Panama, Hartman 1961); female, 728 g (n = 1, laying, with fully formed egg in oviduct, Colombia; Miller 1963)')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataBOW_noM['Highland Tinamou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3b4bc10-ba1e-4cff-be77-442d952f576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data together\n",
    "#data = dataWIKI | dataBOW\n",
    "#data = dataWIKI\n",
    "data = dataBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0135fbc-34ec-4b11-8de3-8e34c8ad5b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6890 values.\n",
      "2511 labels with 1 (true).\n",
      "4379 labels with 0 (false).\n"
     ]
    }
   ],
   "source": [
    "TotalValues = list(chain.from_iterable(data.values()))\n",
    "\n",
    "ones = Counter(ones[0] for ones in TotalValues if ones[0] == 1)\n",
    "zeros = Counter(ones[0] for ones in TotalValues if ones[0] == 0)\n",
    "\n",
    "print('{0} values.'. format(len(TotalValues)))\n",
    "print('{0} labels with 1 (true).'.format(ones[1]))\n",
    "print('{0} labels with 0 (false).'.format(zeros[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "362c398b-9358-48bc-87a5-40676264a56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Species\\nlen(data)\\n# Total values\\nTotal = sum(len(v) for v in list(data.values()))\\nprint(Total)\\n# Total Truths\\nTotalValues = [v for v in list(data.values())]\\nTruths = [[ones[0] for ones in Values if ones[0] == 1] for Values in TotalValues]\\nAmountofTruths = sum(len(x) for x in Truths)\\n# Total False\\nAmountofFalse = Total - AmountofTruths\\nprint(AmountofTruths)\\nprint(AmountofFalse)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Species\n",
    "len(data)\n",
    "# Total values\n",
    "Total = sum(len(v) for v in list(data.values()))\n",
    "print(Total)\n",
    "# Total Truths\n",
    "TotalValues = [v for v in list(data.values())]\n",
    "Truths = [[ones[0] for ones in Values if ones[0] == 1] for Values in TotalValues]\n",
    "AmountofTruths = sum(len(x) for x in Truths)\n",
    "# Total False\n",
    "AmountofFalse = Total - AmountofTruths\n",
    "print(AmountofTruths)\n",
    "print(AmountofFalse)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c52af21-0669-46c4-ba4a-d5f9e67a291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values from the dict\n",
    "data = list(chain.from_iterable(data.values()))\n",
    "# Train test sequence\n",
    "train = int(len(data) * 0.8)\n",
    "test = len(data) - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afc90c63-95b6-4a81-aa04-d6c94c369d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "trainset = data[0:train]\n",
    "testset = data[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62ada087-f784-4140-85e8-4ef7b8cbb817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5512"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "708d5b7b-bc04-4e2a-a60d-7d772aeae649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic English\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Tokenize the dataset\n",
    "def yield_tokens(data_iter):\n",
    "    # Drop the label (label, text)\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Build a vocabulary        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(trainset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a6ce8fa-9f29-4127-a754-a9e35b14c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "# -1 could be removed if data is loaded differently\n",
    "label_pipeline = lambda x: int(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4b51979-1c1c-4e6f-9b6c-936eff41b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  10,   13,  345,   40,    1,   10,  705,   25,   55, 4512,    2])\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "proc = torch.tensor(text_pipeline('the a bird birds, the bear are not equal.'), dtype=torch.int64)\n",
    "print(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa2995c1-cb7d-4c68-bcd0-b06e70622b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (CPU for macs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \n",
    "    '''\n",
    "    Convert sentences or paragrahs to integers by using\n",
    "    the PyTorch Vocab(). The data is converted and \n",
    "    returned as a tensor. The offset of the words is \n",
    "    compared to the start of the sentence/paragraph.\n",
    "    '''\n",
    "\n",
    "    # Init lists\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    \n",
    "    # Loop over the data\n",
    "    for (_label, _text) in batch:\n",
    "        # Append the labels to list\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        # Process the text (singed 64), and convert to tensor\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        # Append the text to list \n",
    "        text_list.append(processed_text)\n",
    "        # Append the offset (tensor size)   \n",
    "        offsets.append(processed_text.size(0))\n",
    "    \n",
    "    # Convert the label list to a tensor\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    # Cummulative sum the offsets (dim=0 == rowwise)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    # Concatenate the text list\n",
    "    text_list = torch.cat(text_list)\n",
    "    \n",
    "    # Return the values\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "533c99c8-bb8c-41f0-91da-a64be4fb783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "dataloader = DataLoader(train_iter, batch_size=16, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0583f2f-dcda-4c29-a4a5-562259e7a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]),\n",
       " tensor([   72,   183,   401,     2,    72,   183,   401,     2,    20,   163,\n",
       "            42,    23,   426,   151,    67,    20,     5,   426,    91,    67,\n",
       "            20,     3,    23,     1,     5,     2,   154,    62,    37,    95,\n",
       "            27,   328,   656,   280,   796,   661,     8,   788,   763,   721,\n",
       "           214,    10,   784,   178,   756,     2,   189,   705,     9,   780,\n",
       "           100,    27,   192,   502,   710,     2,   444,     7,   717,  1148,\n",
       "             1,   390,     1,  1123,     1,   695,     1,  1783,     1,  3423,\n",
       "             3,   507,     1,  2224,    18,  1529,     3,   825,   415,    83,\n",
       "             4,   734,     2,    70,   187,    39,   305,   218,  4150,     2,\n",
       "           199,  1350,    51,   114,     1,    23,   557,    39,   127,  6013,\n",
       "            74,     1,   195,   602,    39,   557,     4,    20,     2,   453,\n",
       "          1102,  2220,     1,  1058,     4,   621,   256,     7,     5,     2,\n",
       "          2022,  1084,     3, 10194,     3, 16742,    40,    39,   515,    42,\n",
       "          1350,  1084,    14,    55,    17,    97,     2,   242,  2169,     7,\n",
       "            58,    39,     1,    39,  1292,    11,    81,     1,  2226,     1,\n",
       "           149,     1,   153,     1,    44,     1,     3,    57,     6,  6315,\n",
       "           168,   179,     2,     1, 20809,     1,   186,     1,   577,     3,\n",
       "           697,     1, 14705,     1,  5955,     5,     2,  1257,    39,  1033,\n",
       "             8, 20169,     3,  9405,     6,     5,   456,    13,   991,   963,\n",
       "            93,    39,    19,    85,    29,  1012,     4,  3788,     1,   602,\n",
       "            10,    39,   214,    78,    29,     6,   700,    39,     1,   900,\n",
       "             5,     1,     4,    54,    17,   130,     1,    15,    27,    39,\n",
       "            33,   106,  1066,     8,  4969,     6,   191,   425,     1,   290,\n",
       "             5,     2,   824,     7,    93,    30,    17,    27,   431,     4,\n",
       "          7393,   306,    52,    35,  1539,  1324,  1245,    39,     1,  1012,\n",
       "             9,  5575,     7,   158,   451,  5066,    24,    93,   614,   205,\n",
       "          2866,     2,   309,  1023,     2,   771,   147,  1632,    18,    13,\n",
       "           249,   241,     9,    13, 10228,     1,   107,  6656,     1,  3007,\n",
       "             1,     3,    73,  1683,  4797,     2,   119,   355,    16,    14,\n",
       "           188,   355,    16,     1,   494,     9,  1727,   149,     2,   549,\n",
       "             6,   123,  2189,     5,  1470,    46,   307,     4,   241,   296,\n",
       "             1,  4797,     1,   795,   317,     1,     3,  2582,   221,     2,\n",
       "           241,   221,    52,    43,   249,     1,   923,   157,     1,   128,\n",
       "           157,     1,    14,   188,   355,    16,  2180,    87,    12,   987,\n",
       "             1,     3,  3007,    87,    12,   782,     6,   673,     5,     2,\n",
       "            20,     2,    10,    44,    12,    16,     1,     9,    13,  1592,\n",
       "           231,    11,    10,   136,     1,    68,    12,   163,     4,   138,\n",
       "             4,  2428,    54,     3,   161,    14,   782,     4,  1072,    40,\n",
       "             2,    10,    57,    12,   103,    22,    14,    21,     2,   244,\n",
       "             1,    10,   149,    52,   736,   122,    56,   343,    53,     8,\n",
       "            26,   343,    22,    10,   349,    12,  2125,   376,    22,     3,\n",
       "           481,     9,    21,     1,    10,   101,     3,   268,    25,    53,\n",
       "            22,     1,     3,   758,    50,    25, 15108,   206,     2,    10,\n",
       "           120,     3,   153,   736,   122,    26,   343,    22,     3,   355,\n",
       "            53,    10,    63,     3,   119,    25,   206,     1,     3,  7549,\n",
       "            11,    10,   446,    50,     1,     3,    10,    81,    12,   103,\n",
       "             2,    10,   269,    25,  3236,    53,    22,     9,   827,    11,\n",
       "            10,    50,   459,    50,    25,  1616,    53,     9,    16,  1135,\n",
       "             2,    32,    91,     6,   463,   311,     5,  1334,     2,   474,\n",
       "            28,     6,    45, 11844,    28,     5,    58,    91,     6,   498,\n",
       "             5,    71,  7935,    28,     6,    45, 11647,    28,     5,  2576,\n",
       "            44,     1,  1261,     1,    63,     1,     3,   719,   342,    50,\n",
       "           811,    15,  1829,   789,     9,  2876,     1,    26,   128,     8,\n",
       "           103,     1,   427,    30,     2,  2576,    32,    12,   249,   263,\n",
       "             1,     3,   163,     3,    92,   611,  5325,    42,    10,    23,\n",
       "            32,     2,  2098,    18, 20230,  9551,     2,   299,   343,    22,\n",
       "             6,   560,   473,  5929,     2,  8872,     1,  6066,  1407,     5,\n",
       "           573,     3,   623,    26,   188,    22,     2,    17,   319,     1,\n",
       "            26,  1186,     4,   197,     1,    26,   128,     6,   186,     5,\n",
       "             2,    20,     2,    44,     3,    57,   128,     9,    72,    16,\n",
       "           876,     3,    13,    26,     1,    73,   606,     1,  2088,     2,\n",
       "            69,     7,   349,    26,   128,    53,     3,   643,     4,   221,\n",
       "             1,    46,    30,     9,  1683,   678,   444,   185,   510,     2,\n",
       "            81,    24,     4,   427,    29,    14,    70,    84,    29,     1,\n",
       "           169,   288,   509,     6,    73,   731,   400,     5,     7,   332,\n",
       "           170,   303,     1,    26,    22,     9,   124,   410,     2,   342,\n",
       "            30,    24,     4,   427,    14,    70,    84,    20,   169,  3624,\n",
       "           259,     3,    46,   719,   445,    50,    73,   303,     1,    22,\n",
       "             9,    56,   285,  2921,  3028,     2,    63,    22,    14,   343,\n",
       "            22,     3,  3193,    14,   409,  2100,     1,    10,    30,     9,\n",
       "           117,    26,  1288,     3,   924,     9,   235,   221, 10635,   692,\n",
       "             1,   131,  3204,     1,   605,   678,    17,  1127,     2,   378,\n",
       "             3,  1101,  1819,   764,   288,     1,  2041,    19,   343,    22,\n",
       "             8,   615,     8,   960,     1,     3,    87,  1794,     1,    10,\n",
       "            30,     9,   131,    22,  1609,     3,   132,   124,   444,     2,\n",
       "           119,   288,     1,   107,    24,     4,   427,    29,     3,    70,\n",
       "            84,    29,     6,    72,    30,   303,     5,    14,   367,   133,\n",
       "            43,    34,   582,   520,    14,   409,     2,   446,    50,    24,\n",
       "             4,    70,    84,    23,   169,   317,     1,   441,   177,     1,\n",
       "           163,     3,    34,   965,     2]),\n",
       " tensor([  0,   4,   8,  26,  56,  83, 177, 265, 350, 481, 496, 509, 557, 570,\n",
       "         577, 591]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a49b6e0-7eb0-46b7-b743-c8528401b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1144cfc2-43c0-44d0-9f5c-493cc449e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ede95da0-ce09-4593-b1dd-0a0c0da61d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12ca46ca-7f2a-43e6-bbb5-e1781dd0f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/  655 batches | accuracy    0.873\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.19s | valid accuracy    0.924 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/  655 batches | accuracy    0.933\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.25s | valid accuracy    0.913 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/  655 batches | accuracy    0.953\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.16s | valid accuracy    0.942 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/  655 batches | accuracy    0.956\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.17s | valid accuracy    0.942 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/  655 batches | accuracy    0.957\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.16s | valid accuracy    0.949 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/  655 batches | accuracy    0.959\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.15s | valid accuracy    0.942 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/  655 batches | accuracy    0.958\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.14s | valid accuracy    0.946 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/  655 batches | accuracy    0.959\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.15s | valid accuracy    0.942 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/  655 batches | accuracy    0.961\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.15s | valid accuracy    0.942 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/  655 batches | accuracy    0.960\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.15s | valid accuracy    0.942 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 8 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = trainset, testset\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c85ffde5-d8d3-477a-9e7b-621066b9f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.986\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b64ebfcb-a5a5-4bce-93bd-dec92c8d7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a description or similar.\n",
      "This is something else.\n",
      "This is a description or similar.\n",
      "This is a description or similar.\n",
      "This is a description or similar.\n",
      "This is a description or similar.\n"
     ]
    }
   ],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         0: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() \n",
    "\n",
    "# Measurements\n",
    "ex_text_str = 'They are 90 to 150 cm tall at the shoulder and can tower at an intimidating height of 8 feet when standing upright on their hind legs.'\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Random\n",
    "ex_text_str = 'Hi I am GIS student, this is a random sentence!'\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Bird stuff\n",
    "ex_text_str = 'The bill is long and orange.'\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Something about bears\n",
    "ex_text_str = '''Brown bears are often not fully brown. \n",
    "                They have long, thick fur, with a moderately long mane at the back of the neck which varies somewhat across the types. \n",
    "                In India, brown bears can be reddish with silver-tipped hairs, while in China brown bears are bicolored, \n",
    "                with a yellowish-brown or whitish collar across the neck, chest and shoulders.'''\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Somehting about Robins\n",
    "ex_text_str = '''This is a nonsense sentence that is about large. but the model is trained on large sentences now, so lets make a bit .\n",
    "                 This is more nonsense about nothing I am not talking about anything   '''\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Random Difficult sentence\n",
    "ex_text_str = '''While I am very tan from the sun, I can be pale within a few days.\n",
    "                I have blonde hair'''\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c71d33-b09c-43f9-8a3b-3b6fc75a3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "ExtraTesting = []\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Eurasian_wigeon'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "for Tags in soup.find_all('h2'):\n",
    "\n",
    "    # Skip useless/empty stuff\n",
    "    if Tags.span == None:\n",
    "        continue\n",
    "\n",
    "    # Set chapter variable    \n",
    "    Chapter = Tags.span.attrs['id']\n",
    "\n",
    "    # Check if the chapter is description (or similar)\n",
    "    if Chapter == 'Characteristics'or \\\n",
    "       Chapter == 'Description' or \\\n",
    "       Chapter == 'Appearance':\n",
    "\n",
    "        # Get the next sibling (text)\n",
    "        for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "            # Add description data to dict\n",
    "            if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(1, Sentence) for Sentence in SentenceList]\n",
    "\n",
    "            # Add non description data to dict\n",
    "            elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(0, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597ada4-0238-4f00-9a77-35fe42c0881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         0: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() \n",
    "\n",
    "for tests in ExtraTesting:\n",
    "    ex_text_str = tests[1]\n",
    "    \n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "    print(\"Real value was {0}\".format(tests[0]))\n",
    "    print(tests[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25eb47-da5e-4001-929b-962a7a885bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
