{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import collections\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dict\n",
    "Data = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for database\n",
    "#URL = 'https://en.wikipedia.org/wiki/List_of_birds_of_the_Netherlands'\n",
    "#URL = 'https://en.wikipedia.org/wiki/List_of_mammals_of_the_Netherlands'\n",
    "URL = 'https://en.wikipedia.org/wiki/List_of_mammals_of_Europe'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Find all wikiparts\n",
    "Animals = soup.find_all('a')\n",
    "# Create links \n",
    "AnimalsWikiPages = ['https://en.wikipedia.org/' + pages.get('href') for pages in Animals \n",
    "                       if pages.get('href') != None \n",
    "                       if pages.get('href').startswith('/wiki/')]\n",
    "                       # Reduces the retrieved pages (does not work)\n",
    "                       #if pages.span != None \n",
    "                       #if pages.span.attrs['class'][0] == 'tocnumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "DescriptionData = {}\n",
    "NonDescriptionData = {}\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "for WikiPage in AnimalsWikiPages[0:50]:\n",
    "    \n",
    "    # Open the page\n",
    "    page = requests.get(WikiPage, timeout=5)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    for Tags in soup.find_all('h2'):\n",
    "\n",
    "        # Skip useless/empty stuff\n",
    "        if Tags.span == None:\n",
    "            continue\n",
    "\n",
    "        # Set chapter variable    \n",
    "        Chapter = Tags.span.attrs['id']\n",
    "\n",
    "        # Check if the chapter is description (or similar)\n",
    "        if Chapter == 'Characteristics'or \\\n",
    "           Chapter == 'Description' or \\\n",
    "           Chapter == 'Appearance':\n",
    "\n",
    "\n",
    "            # Get species name\n",
    "            Species = soup.title\\\n",
    "                            .string\\\n",
    "                            .split(' - ')[0]\\\n",
    "                            .rstrip(' ')\n",
    "\n",
    "\n",
    "            # Get the next sibling (text)\n",
    "            for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "                # Add description data to dict\n",
    "                if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    #Data[Species] += [(1, Sentence) for Sentence in SentenceList]\n",
    "                    #### TESTING\n",
    "                    for index, Sentences in enumerate(SentenceList):\n",
    "                        if all(s.lower() not in Sentences for s in ['cm', 'm', 'kg', 'lbs', 'dimensions']):\n",
    "                            Data[Species].append(tuple([0, Sentences]))\n",
    "                        else:\n",
    "                            Data[Species].append(tuple([1, Sentences]))\n",
    "\n",
    "                # Add non description data to dict\n",
    "                elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    Data[Species] += [(0, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animals A-Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://a-z-animals.com/animals/'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Finds all links\n",
    "Animals = soup.find_all('a')\n",
    "\n",
    "# Create a list with links\n",
    "AnimalsA_Zpages = [pages.get('href') for pages in Animals \n",
    "                   if pages.get('href') != None\n",
    "                   if pages.get('href').startswith('https://a-z-animals.com')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "for AnimalPage in AnimalsA_Zpages[:]:\n",
    "    \n",
    "    # Open the page\n",
    "    page = requests.get(AnimalPage, timeout=5)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    for Tags in soup.find_all('h2'):\n",
    "\n",
    "        # Get the chapters\n",
    "        try:\n",
    "            Chapter = Tags['id']\n",
    "        # skip other stuff\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Finds descriptions or similar\n",
    "        if Chapter.endswith('appearance'):\n",
    "            \n",
    "            '''\n",
    "            # Get species name\n",
    "            Species = soup.title\\\n",
    "                            .string\\\n",
    "                            .split(' Animal')[0]\\\n",
    "                            .lower()\\\n",
    "                            .capitalize()\n",
    "            '''\n",
    "            \n",
    "            # Get species name\n",
    "            Species = soup.find('h1').text\\\n",
    "                                        .lower()\\\n",
    "                                        .capitalize()\n",
    "\n",
    "\n",
    "            # Get the next sibling (text)\n",
    "            for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "                # Add description data to dict\n",
    "                if Chapter in Text.find_previous_siblings('h2')[0]['id']:\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    #Data[Species] += [(1, Sentence) for Sentence in SentenceList]\n",
    "                    #### TESTING\n",
    "                    for index, Sentences in enumerate(SentenceList):\n",
    "                        if all(s.lower() not in Sentences for s in ['cm', 'm', 'kg', 'lbs', 'dimensions']):\n",
    "                            Data[Species].append(tuple([0, Sentences]))\n",
    "                        else:\n",
    "                            Data[Species].append(tuple([1, Sentences]))\n",
    "  \n",
    "\n",
    "                # Add non description data to dict\n",
    "                elif Chapter not in Text.find_previous_siblings('h2')[0]['id']:\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Split into Sentences\n",
    "                    SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    Data[Species] += [(0, Sentence) for Sentence in SentenceList]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump(Data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "DescriptionData = {}\n",
    "NonDescriptionData = {}\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "for WikiPage in AnimalsWikiPages[0:50]:\n",
    "    \n",
    "    # Open the page\n",
    "    page = requests.get(WikiPage, timeout=5)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    for Tags in soup.find_all('h2'):\n",
    "\n",
    "        # Skip useless/empty stuff\n",
    "        if Tags.span == None:\n",
    "            continue\n",
    "\n",
    "        # Set chapter variable    \n",
    "        Chapter = Tags.span.attrs['id']\n",
    "\n",
    "        # Check if the chapter is description (or similar)\n",
    "        if Chapter == 'Characteristics'or \\\n",
    "           Chapter == 'Description' or \\\n",
    "           Chapter == 'Appearance':\n",
    "\n",
    "\n",
    "            # Get species name\n",
    "            Species = soup.title\\\n",
    "                            .string\\\n",
    "                            .split(' - ')[0]\\\n",
    "                            .rstrip(' ')\n",
    "\n",
    "\n",
    "            # Get the next sibling (text)\n",
    "            for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "                # Add description data to dict\n",
    "                if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Add to dict\n",
    "                    Data[Species].append(tuple([1, Paragraph]))\n",
    "                    \n",
    "                    # Split into Sentences\n",
    "                    #SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    #Data[Species] += [(1, Sentence) for Sentence in SentenceList]\n",
    "\n",
    "                # Add non description data to dict\n",
    "                elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Add to dict\n",
    "                    Data[Species].append(tuple([0, Paragraph]))\n",
    "                    \n",
    "                    # Split into Sentences\n",
    "                    #SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    #Data[Species] += [(0, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "for AnimalPage in AnimalsA_Zpages[:]:\n",
    "    \n",
    "    # Open the page\n",
    "    page = requests.get(AnimalPage, timeout=5)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    for Tags in soup.find_all('h2'):\n",
    "\n",
    "        # Get the chapters\n",
    "        try:\n",
    "            Chapter = Tags['id']\n",
    "        # skip other stuff\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Finds descriptions or similar\n",
    "        if Chapter.endswith('appearance'):\n",
    "            \n",
    "            '''\n",
    "            # Get species name\n",
    "            Species = soup.title\\\n",
    "                            .string\\\n",
    "                            .split(' Animal')[0]\\\n",
    "                            .lower()\\\n",
    "                            .capitalize()\n",
    "            '''\n",
    "            \n",
    "            # Get species name\n",
    "            Species = soup.find('h1').text\\\n",
    "                                        .lower()\\\n",
    "                                        .capitalize()\n",
    "\n",
    "\n",
    "            # Get the next sibling (text)\n",
    "            for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "                # Add description data to dict\n",
    "                if Chapter in Text.find_previous_siblings('h2')[0]['id']:\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Add to dict\n",
    "                    Data[Species].append(tuple([1, Paragraph]))\n",
    "                    \n",
    "                    # Split into Sentences\n",
    "                    #SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    #Data[Species] += [(1, Sentence) for Sentence in SentenceList]\n",
    "          \n",
    "                # Add non description data to dict\n",
    "                elif Chapter not in Text.find_previous_siblings('h2')[0]['id']:\n",
    "                    # Remove source\n",
    "                    Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                    # Add to dict\n",
    "                    Data[Species].append(tuple([0, Paragraph]))\n",
    "                    \n",
    "                    # Split into Sentences\n",
    "                    #SentenceList = Paragraph.split('. ')\n",
    "                    # Add to the dict\n",
    "                    #Data[Species] += [(0, Sentence) for Sentence in SentenceList]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_withMeasurements.pkl', 'wb') as f:\n",
    "    pickle.dump(Data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
