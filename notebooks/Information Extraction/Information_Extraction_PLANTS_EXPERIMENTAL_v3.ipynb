{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c838a5-be6b-4ef9-9611-ba3840147e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import collections\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50981800-673a-408a-9bff-4a5c95e292a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary = pickle.load(open('../../data/glossaries/FNA_glossary.pkl', 'rb'))\n",
    "glossary['leaf'] += ['leave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcbd31b-187b-41ad-9589-91c2fa500b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glossary_FNA['Flower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6534cd43-64ab-45fb-8a95-4135f7879b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_list = [\n",
    "    'fertile', 'sterile',\n",
    "    'male', 'female', 'bisexual', 'hermaphroditic', \n",
    "    'basal', 'developed', \n",
    "    'primary', 'secondary', 'main',\n",
    "    'upper', 'lower', 'greater', 'dorsal', 'alternate', 'lesser', 'apex', 'outer',\n",
    "    'central', 'outermost', 'outer', 'inner', 'uppermost', 'median', 'dorsal', 'central', 'lateral',\n",
    "    'young', 'mature', 'individual', \n",
    "    'opposite', \n",
    "]\n",
    "\n",
    "rubbish_list = [\n",
    "    '.', ',', '-', '..', '...', '', \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba98d50-e81f-4457-a286-5950ecc0f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pickle.load(open('../../data/PlantNet/descriptions_raw.pkl', 'rb'))\n",
    "data = pickle.load(open('../../data/description/04_TRAIN_0000000-0014557_PLANTS.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e860339e-8d1b-4a93-b5af-60f489798c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861c7c47-631f-440f-bbda-5d7f4cd92bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_list = [\n",
    "    'mm', 'cm', 'm', 'km',\n",
    "    'milimeter', 'centimeter', 'meter', 'kilometer',\n",
    "    'milimetre', 'centimetre', 'metre', 'kilometre',\n",
    "    'inch', 'foot', 'yard', 'mile',\n",
    "    'wide', 'long', 'broad', 'tall',\n",
    "    'length', 'form',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8fdb8c5-9b77-4fe0-a562-cc77d9ff47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Test Tree':[\n",
    "        'light, slightly dark, upper axial leaves with 7 veins.',\n",
    "        'Bark up to 20 to 30 cm.',\n",
    "        'Stems often 5-veined.',\n",
    "        'Branches light-dark reddish brown and greenish purple or black.'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34734c16-c991-41ca-a17a-bd88b6faaf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preparation(species, text):\n",
    "    cleaners = [(r'(?<!\\d)\\.(?!\\d)', ' '),\n",
    "                (r'\\s×\\s', ' times '),\n",
    "                #(r'\\xa0', ' '),\n",
    "                (r'\\s+c\\s+', ' '),\n",
    "                (r'â\\x80\\x93', ' to '),\n",
    "                (r'\\xa0', ' '),\n",
    "                (r'\\x97', ''),\n",
    "                (r'\\s{2,}', ' '),\n",
    "                (r'\\.', ' ')]\n",
    "    \n",
    "    species_parts = species.split()\n",
    "    candidates = [' '.join(species_parts[:idx+1]) for idx, _ in enumerate(species_parts)]\n",
    "    candidates += [\n",
    "        f'{species_parts[0][0]}. {species_parts[1]}'\n",
    "    ]\n",
    "    candidates.reverse()\n",
    "    for candidate in candidates:\n",
    "        try:\n",
    "            text = re.sub(candidate, 'the species', text)\n",
    "        except:\n",
    "            continue # Skip species with brackets for now\n",
    "    for (cleaner, replacement) in cleaners:\n",
    "        text = re.sub(cleaner, replacement, text)    \n",
    "    text = f'{text.strip()}.'\n",
    "    return text.capitalize()\n",
    "\n",
    "def is_float(val):\n",
    "    try:\n",
    "        num = float(val)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_existance(t, doc):\n",
    "    item = None\n",
    "    for mainpart in glossary.keys():\n",
    "        if t.lemma_ in compound_list:\n",
    "            item = None\n",
    "        elif t.dep_ == 'compound':\n",
    "            item = None\n",
    "        elif t.pos_ != 'NOUN':\n",
    "            item = None\n",
    "        elif not list(t.children):\n",
    "            item = None\n",
    "        elif t.lemma_.lower().strip() in glossary[mainpart]:\n",
    "            item = mainpart            \n",
    "    return item\n",
    "\n",
    "\n",
    "def extract_compounds(t, doc):\n",
    "    for child in t.children:\n",
    "        if (\n",
    "            child.dep_ == 'compound'\n",
    "            or child.lemma_ in compound_list\n",
    "        ):\n",
    "            yield child\n",
    "            #yield from (extract_compounds(child, doc))\n",
    "\n",
    "def extract_amods(t, doc):\n",
    "    for child in t.children:\n",
    "        if (\n",
    "            child.dep_ == 'amod'\n",
    "            and child.lemma_ not in measurements_list\n",
    "            and child.lemma_ not in compound_list\n",
    "            or child.dep_ == 'conj'\n",
    "            #and child.pos_ == ' ADJ'\n",
    "        ):\n",
    "            yield child\n",
    "            yield from (extract_amods(child, doc))\n",
    "            #yield from (extract_numbers(child, doc))\n",
    "\n",
    "def extract_advmods(t, doc):\n",
    "    for child in t.children:\n",
    "        if (\n",
    "            child.dep_ == 'advmod'\n",
    "            and child.lemma_ not in measurements_list\n",
    "            and child.lemma_ not in compound_list\n",
    "        ):\n",
    "            yield child\n",
    "            #yield from (extract_advmods(child, doc))            \n",
    "\n",
    "def extract_numbers(t, doc):\n",
    "    for child in t.children:\n",
    "        if (\n",
    "            child.dep_ == 'nummod'\n",
    "            or child.dep_ == 'quantmod'\n",
    "            and child.pos_ == 'NUM'\n",
    "        ):\n",
    "            yield child\n",
    "            yield from (extract_numbers(child, doc))\n",
    "\n",
    "def extract_apmods(t, doc):\n",
    "    for child in t.children:\n",
    "        if (\n",
    "            child.dep_ == 'appos'\n",
    "            and child.lemma_ not in measurements_list\n",
    "            and child.lemma_ not in compound_list\n",
    "            or child.dep_ == 'conj'\n",
    "            #and child.pos_ == ' ADJ'\n",
    "        ):\n",
    "            yield child\n",
    "            yield from (extract_numbers(child, doc))\n",
    "            \n",
    "def clean_triples(triples):\n",
    "    \n",
    "    cleaned = []\n",
    "    for (sub, rel, obj) in triples:\n",
    "             \n",
    "        sub = sub.strip().lower().strip('-')\n",
    "        rel = rel.strip().lower().strip('-')\n",
    "        obj = obj.strip().lower().strip('-')\n",
    "        cleaned.append((sub, rel, obj))\n",
    "    \n",
    "    return cleaned\n",
    "            \n",
    "            \n",
    "def extract_triples(doc):\n",
    "    \n",
    "    triples = []\n",
    "    \n",
    "    for t in doc:\n",
    "        part = check_existance(t, doc)\n",
    "        if part:\n",
    "            \n",
    "            triples.append(('species', 'has_part', part))\n",
    "            parts = []\n",
    "            # Append to list\n",
    "            parts.append((part, 'has_main_part', t.lemma_))\n",
    "            # Yield Compounds\n",
    "            for compound in extract_compounds(t, doc):\n",
    "                # Get last item\n",
    "                last = parts[-1][2]\n",
    "                # Construct new\n",
    "                new = f'{compound} {last}'\n",
    "                # Append\n",
    "                parts.append((last, 'has_sub_part', new))    \n",
    "            triples.extend(parts)\n",
    "                \n",
    "            # Modifiers\n",
    "            for amod in extract_amods(t, doc):\n",
    "                triples.append((parts[-1][-1], 'has_property', amod.lemma_))\n",
    "                for advmod in extract_advmods(amod, doc):\n",
    "                    triples.append((amod.lemma_, 'has_modifier', advmod.lemma_))\n",
    "            \n",
    "            # Direct Numbers        \n",
    "            numbers = list(extract_numbers(t, doc))\n",
    "            #print(list(numbers))\n",
    "            if numbers:\n",
    "                print(numbers)\n",
    "                new_node = f'{t.lemma_}_quantity'\n",
    "                triples.append((parts[-1][-1], 'has_property', new_node))\n",
    "                for number in numbers:\n",
    "                    triples.append((new_node, 'has_property', number.lemma_))\n",
    "                    \n",
    "            # Appositional modifier\n",
    "            for apmod in extract_apmods(t, doc):\n",
    "                triples.append((parts[-1][-1], 'has_property', apmod.lemma_))\n",
    "            #print(list(extract_apmods(t, doc)))\n",
    "\n",
    "    return clean_triples(triples)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8aec99-50bc-460f-a990-9bddb316b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e1a07-9206-4d78-8601-f450e124f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_data = []\n",
    "species = species_list[0]\n",
    "for sent in data[species][0:10]:\n",
    "    \n",
    "    text = text_preparation(species, sent)\n",
    "    \n",
    "    doc = nlp(sent)\n",
    "    kn_data += extract_triples(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51fdfe1-1ce1-4818-a884-f5a3f8dce680",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da69fe18-690d-48cb-be92-32ca9f74d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('../../data/description/04_TRAIN_0000000-0014557_PLANTS.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85d2eec5-e68c-401b-9e37-cf24d4d9ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = list(data.keys())\n",
    "species = species_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ffe7ec64-1c9b-4a19-982d-b82226fe0b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ffe6504157724edeb3227766a50f364b-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Fertile</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">spikelets</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">pedicelled,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">2</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">cluster.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ffe6504157724edeb3227766a50f364b-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ffe6504157724edeb3227766a50f364b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ffe6504157724edeb3227766a50f364b-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ffe6504157724edeb3227766a50f364b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ffe6504157724edeb3227766a50f364b-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ffe6504157724edeb3227766a50f364b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ffe6504157724edeb3227766a50f364b-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ffe6504157724edeb3227766a50f364b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ffe6504157724edeb3227766a50f364b-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ffe6504157724edeb3227766a50f364b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ffe6504157724edeb3227766a50f364b-0-5\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ffe6504157724edeb3227766a50f364b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,179.0 L1108.0,167.0 1092.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(data[species][3])\n",
    "displacy.render(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5fab287-5b56-4fc6-aedb-a31ec3326538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_sentence(t):\n",
    "    sentence_dict = {}\n",
    "    for child in t.children:\n",
    "        items = dict_sentence(child)\n",
    "        sentence_dict[child] = items \n",
    "    return sentence_dict\n",
    "\n",
    "def undict_to_tuples(d, acc = ()):\n",
    "    if d == {}:\n",
    "        yield acc\n",
    "    else:\n",
    "        for k,v in d.items():\n",
    "            yield from undict_to_tuples(v, acc + (k,))\n",
    "    \n",
    "def extract_compounds(t, doc):\n",
    "    head = None\n",
    "    if t.dep_ == 'compound':\n",
    "        t = next(t.ancestors)\n",
    "    indices = [child.i for child in t.children\n",
    "               if child.dep_ == 'compound'\n",
    "               or child.lemma_ in compound_list]\n",
    "    indices.append(t.i)\n",
    "    indices.sort(reverse=True)\n",
    "    compounds  = []\n",
    "    for idx in indices:\n",
    "        compounds.append(doc[idx : t.i + 1])\n",
    "    return compounds    \n",
    "            \n",
    "            \n",
    "def check_existance(t):\n",
    "    item = None\n",
    "    for mainpart in glossary.keys():\n",
    "        if t.lemma_ in compound_list:\n",
    "            item = None\n",
    "        elif t.pos_ != 'NOUN':\n",
    "            item = None\n",
    "        elif t.lemma_.lower().strip() in glossary[mainpart]:\n",
    "            item = mainpart            \n",
    "    return item\n",
    "\n",
    "def extract_information(t, double):\n",
    "    triples = []\n",
    "    for info in double:\n",
    "        if info.dep_ == 'amod':\n",
    "            triples.append((t.lemma_, 'has_property', info.lemma_))\n",
    "        elif info.pos_ == 'NUM':\n",
    "            triples.append((t.lemma_, 'has_number', info.lemma_))\n",
    "        elif t.dep_ == 'amod':\n",
    "            triples.append((t.lemma_, 'has_modifier', info.lemma_))\n",
    "        else:\n",
    "            triples.append((t.lemma_, 'other', info.lemma_))\n",
    "        t = info\n",
    "    return triples\n",
    "\n",
    "def extract_triples(doc):\n",
    "    \n",
    "    triples = []\n",
    "    for t in doc:\n",
    "        part = check_existance(t)\n",
    "        #print(part, t)\n",
    "        if part:\n",
    "            triples.append(('species', 'has_main_part', part))\n",
    "            last = part\n",
    "            for compound in extract_compounds(t, doc):\n",
    "                triples.append((last, 'has_sub_part', compound))\n",
    "                last = compound\n",
    "            sentence_dict = dict_sentence(t)\n",
    "            for tuples in undict_to_tuples(sentence_dict):\n",
    "                pass\n",
    "                #print(extract_information(t, tuples))\n",
    "    print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af1980ac-d743-4657-9bad-d2d17c0955a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('species', 'has_main_part', 'spikelet'), ('spikelet', 'has_sub_part', spikelets), (spikelets, 'has_sub_part', Fertile spikelets)]\n"
     ]
    }
   ],
   "source": [
    "extract_triples(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd952b-efb6-48ec-9691-b6fd96592b20",
   "metadata": {},
   "source": [
    "# VIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda96c7-7e1c-4a08-bd5f-07e994625bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from netgraph import Graph\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29154af6-f4ec-4408-8904-207e7a34ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348fc33-e829-403b-b811-e7f6fb7ba9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source   = []\n",
    "relation = []\n",
    "target   = []\n",
    "\n",
    "\n",
    "for (sub, rel, obj) in kn_data:\n",
    "    source.append(sub)\n",
    "    relation.append(rel)\n",
    "    target.append(obj)\n",
    "\n",
    "kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4975c-30de-4a84-9a5a-47645f170177",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f304656-f6e8-4fd5-8c56-447cde861402",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [(source, target) for source, target in zip(kg_df['source'].values, kg_df['target'].values)]\n",
    "G=nx.from_pandas_edgelist(kg_df, \"source\", \"target\", \n",
    "                          edge_attr=True, create_using=nx.Graph())\n",
    "\n",
    "\n",
    "node_labels = {node : node for idx, node in enumerate(G)}\n",
    "edge_labels = dict(zip(list(zip(kg_df.source, kg_df.target)),\n",
    "                  kg_df['edge'].tolist()))\n",
    "\n",
    "node_size = {}\n",
    "node_color = {}\n",
    "\n",
    "size = 1.5\n",
    "\n",
    "for node in node_labels:\n",
    "    if node == 'species':\n",
    "        node_size[node] = 3.5/size\n",
    "        node_color[node] = 'darkgreen'\n",
    "    else:\n",
    "        node_size[node] = 1./size\n",
    "        node_color[node] = 'white'\n",
    "        \n",
    "pos = nx.spring_layout(G, k = 0.08, iterations=5000, seed=3, scale=0.5, center=(0,0), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927df6cf-661d-45e6-8f50-d817a4664c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "Graph(nodes, \n",
    "      #node_layout='spring', edge_layout='curved', \n",
    "      node_layout=pos, edge_layout='straight', \n",
    "      arrows=True, node_zorder=3, #edge_zorder=1,\n",
    "      node_labels=node_labels, \n",
    "      node_label_offset=0.02, \n",
    "      #edge_labels=edge_labels,\n",
    "      node_label_fontdict=dict(size=18, rotation=0, ha='center', clip_on=False), node_edge_width=0.2,\n",
    "      node_size=node_size,  node_color=node_color, #edge_labels=edge_labels,\n",
    "      edge_width=0.2, edge_label_fontdict=dict(size=10,),\n",
    "      #node_layout_kwargs=dict(node_size=1, total_iterations=20),\n",
    "      ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9acee-344a-4650-831b-7686fb6e74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retokenize_doubles(candidates, doc):\n",
    "    \n",
    "    retok_list = []\n",
    "    # Create list to change stuff in place\n",
    "    candidate_list = [list(item) for item in candidates]\n",
    "    # Get Subject\n",
    "    subject = candidate_list[0][1]\n",
    "    \n",
    "    \n",
    "    print(candidate_list)\n",
    "    \n",
    "    ## Compounds\n",
    "    # Find possible compounds\n",
    "    compound_candidates = [item for item in candidate_list[1:] if item[0] == subject or item[0].dep_ == 'compound']\n",
    "    \n",
    "    #print(compound_candidates)\n",
    "    \n",
    "    # Extract compounds:\n",
    "    compounds = [amod for (_, amod) in compound_candidates \n",
    "                 if amod.lemma_ in compound_list or amod.dep_ == 'compound']\n",
    "    \n",
    "    #print(compounds)\n",
    "    #for compound in compounds:\n",
    "        #print(compound)\n",
    "        #compounds += [additional[1] for additional in candidate_list[1:] if additional[0] ==  compound]\n",
    "    \n",
    "    if compounds:\n",
    "        compound_idx = min([compound.i for compound in compounds if compound.i < subject.i])\n",
    "        compound = doc[compound_idx : subject.i + 1]\n",
    "        # Replace in place (not faster but more convinient)\n",
    "        for idx, (noun, info) in enumerate(candidate_list[1:]):\n",
    "            if noun == subject:\n",
    "                candidate_list[idx + 1] = [compound, info]\n",
    "        # Remove compound amods:\n",
    "        compounds_removed = [[information[0], information[1]] for information in candidate_list[1:]\n",
    "                             if information[1].text not in information[0].text]\n",
    "        candidate_list = candidate_list[0:1] + compounds_removed\n",
    "        for idx, token in enumerate(reversed(compounds)):\n",
    "            compound = doc[token.i : subject.i + 1]\n",
    "            #print(compound, idx)\n",
    "            if idx == 0:\n",
    "                candidate_list.insert(idx + 1, [subject, compound])\n",
    "            else:\n",
    "                candidate_list.insert(idx + 1, [previous_compound, compound])\n",
    "            previous_compound = compound\n",
    "        \n",
    "    \n",
    "    #print(compounds)\n",
    "    return candidate_list\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
