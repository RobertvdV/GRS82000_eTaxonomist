{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc52df0f-7635-426b-a5c8-6e7028a47ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "from spacy import displacy\n",
    "import collections\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, logging\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as colors\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8618f695-8368-4439-9b1c-43d5d4523a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../src/models/')\n",
    "sys.path.insert(0, '../../src/features/')\n",
    "\n",
    "import predict_model\n",
    "from predict_model import loadBERT\n",
    "from predict_model import SpanPredictor as classify\n",
    "from build_features import text_cleaner\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6888aba9-61f6-4792-8f75-db5a8268a5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Success\n"
     ]
    }
   ],
   "source": [
    "model = loadBERT(\"../../models/\", 'saved_weights_inf_FIXED_boot_beta80.pt')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2401ac84-8266-4422-813a-7666b6533d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "URL = 'https://en.wikipedia.org/wiki/Glossary_of_plant_morphology'\n",
    "# Get the page\n",
    "page = requests.get(URL, timeout=5)\n",
    "soup = BeautifulSoup(page.content, \"lxml\", from_encoding=\"iso-8859-1\")   \n",
    "\n",
    "glossary = collections.defaultdict(list)\n",
    "# Find all H4 \n",
    "for chapter in soup.find_all('h4')[0:]:\n",
    "    # Clean\n",
    "    chapter_text = chapter.text.rstrip('[edit]')\n",
    "    # Find all siblings\n",
    "    for sibling in chapter.find_next_siblings():\n",
    "        # Find the parent\n",
    "        for parent in sibling.find_previous_sibling('h4'):\n",
    "            # Only append if correspond to current chapter\n",
    "            if parent.text == chapter_text:\n",
    "                if 'â' in sibling.text:\n",
    "                    for tag in sibling.find_all('li'):\n",
    "                        candidates = tag.text.split('â')[0]\n",
    "                        candidates = candidates.split('/')\n",
    "                        for candidate in candidates:\n",
    "                            glossary[chapter_text.lower()].append(candidate.strip().lower())  \n",
    "                            \n",
    "glossary['leaves'] += [\n",
    "    'glume', 'surface', 'margin',\n",
    "    'leaves', 'auricles', 'spatheole',\n",
    "    'ovate', 'lanceolate',\n",
    "]\n",
    "\n",
    "glossary['basic flower parts'] += [\n",
    "    'floret', 'awn',\n",
    "    \n",
    "]\n",
    "glossary['inflorescences'] += [\n",
    "    'spikelets', 'lemma', 'racemes',\n",
    "    'axis',\n",
    "]\n",
    "glossary['leaves'] += [\n",
    "    'rhachilla'\n",
    "]\n",
    "\n",
    "glossary['other parts'] += [\n",
    "    'apex', 'culm', 'tube',\n",
    "    'palea', 'crown', 'canopy',\n",
    "    'base', 'callus', 'hair',\n",
    "    'anther',\n",
    "\n",
    "]\n",
    "\n",
    "glossary['plant property'] += [\n",
    "    'tree', 'shrub',\n",
    "    'life-span', 'life', 'span',\n",
    "]\n",
    "\n",
    "#with open('../../data/glossaries/plants.pkl', 'wb') as f:\n",
    "#    pickle.dump(glossary, f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86921782-9945-4318-b358-27f440aed0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds = [\n",
    "    'fertile', 'sterile',\n",
    "    'male', 'female', 'bisexual',\n",
    "    'basal', 'developed', \n",
    "    'primary', 'secondary', 'main',\n",
    "    'upper', 'lower', 'greater', 'dorsal', 'alternate', 'lesser', 'apex', 'outer',\n",
    "    'central', 'outermost', 'outer', 'inner', 'uppermost', 'median', 'dorsal', 'central', 'lateral',\n",
    "]\n",
    "\n",
    "#with open('../../data/glossaries/plants_compounds.pkl', 'wb') as f:\n",
    "#    pickle.dump(compounds, f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a00ae8f-43f9-4c5e-b37f-089a5294655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pickle.load(open('../../data/description/04_TRAIN_0000000-0014557_PLANTS.pkl', 'rb'))\n",
    "data = pickle.load(open('../../data/processed/PlantNET_plants_SUBSET.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89a57260-8ece-4782-978b-66f10f2c9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_reconstructor(token, doc):\n",
    "    if token.i == 0:\n",
    "        trait = token\n",
    "    elif doc[token.i - 1].pos_ == 'DET':\n",
    "        trait = token\n",
    "    elif doc[token.i - 3].dep_ == 'compound':\n",
    "        trait = doc[token.i - 3: token.i + 1]\n",
    "    elif doc[token.i - 3].text.lower() in compounds or doc[token.i - 3].lemma_.lower() in compounds:\n",
    "        trait = doc[token.i - 3: token.i + 1]\n",
    "    elif doc[token.i - 2].dep_ == 'compound':\n",
    "        trait = doc[token.i - 2: token.i + 1]\n",
    "    elif doc[token.i - 2].text.lower() in compounds or doc[token.i - 3].lemma_.lower() in compounds:\n",
    "        trait = doc[token.i - 2: token.i + 1]\n",
    "    elif doc[token.i - 1].dep_ == 'compound':\n",
    "        trait = doc[token.i - 1: token.i + 1]\n",
    "    elif doc[token.i - 1].text.lower() in compounds or doc[token.i - 3].lemma_.lower() in compounds:\n",
    "        trait = doc[token.i - 1: token.i + 1]\n",
    "    else:\n",
    "        trait = token   \n",
    "    return trait.lemma_\n",
    "\n",
    "def check_existance(t, doc):\n",
    "    \n",
    "    # Check prep\n",
    "    single = next((key for key, value in glossary.items() if t.lemma_.lower() in value), None)\n",
    "    multi = next((key for key, value in glossary.items() if t.text.lower() in value), None)\n",
    "    if single:\n",
    "        return single\n",
    "    elif multi:\n",
    "        return multi\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_advmod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'advmod':\n",
    "            return child\n",
    "        \n",
    "def extract_nummod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'nummod':\n",
    "            return child\n",
    "\n",
    "def extract_conjunction(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    if t.dep_ == 'conj' and t.pos_ == 'ADJ':\n",
    "        return t \n",
    "\n",
    "def extract_amod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'amod':\n",
    "            return child\n",
    "        \n",
    "def extract_measurements(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    obj = None\n",
    "    measurements = ['wide', 'long', 'high',]\n",
    "    if t.text in measurements or t.lemma_ in measurements:\n",
    "        obj = doc[t.left_edge.i : t.right_edge.i + 1]\n",
    "    return obj\n",
    "\n",
    "def extract_prepositions(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'prep':\n",
    "            return doc[child.left_edge.i : child.right_edge.i + 1]\n",
    "\n",
    "def define_position(x, y, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    if len(x.text.split()) > 1:\n",
    "        return f'{y.text} {x.text}'\n",
    "    else:\n",
    "        try:\n",
    "            if x.i > y.i:\n",
    "                return doc[y.i : x.i + 1]\n",
    "            else:\n",
    "                return doc[x.i : y.i + 1]\n",
    "        except:\n",
    "            return f'{y.text} {x.text}'\n",
    "\n",
    "\n",
    "def extract_verb_advm(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'advmod':\n",
    "            return child\n",
    "\n",
    "def extract_verb_nmod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'nummod':\n",
    "            return doc[child.left_edge.i : child.right_edge.i + 1] \n",
    "        \n",
    "def extract_verb_prep(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'prep':\n",
    "            return child    \n",
    "\n",
    "def extract_verb_pobj(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'pobj' or child.dep_ == 'pcomp' or child.dep_ == 'prep':\n",
    "            return child\n",
    "        \n",
    "def extract_verb_nmod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'acl':\n",
    "            return doc[child.left_edge.i : child.right_edge.i + 1]         \n",
    "        \n",
    "def extract_verb_dobj(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'dobj':\n",
    "            return child\n",
    "        \n",
    "def extract_verb_orpd(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'oprd':\n",
    "            return child    \n",
    "        \n",
    "def extract_verb_agnt(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'agent':\n",
    "            return child \n",
    "        \n",
    "def extract_verb_acomp(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'acomp':\n",
    "            obj = doc[child.left_edge.i : child.right_edge.i + 1].text.lower()\n",
    "            return obj \n",
    "        \n",
    "def extract_verb_attr(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'attr':\n",
    "            obj = doc[child.left_edge.i : child.right_edge.i + 1].text.lower()\n",
    "            return obj    \n",
    "        \n",
    "def extract_nounandverb_nummods(t, doc):\n",
    "    obj = None\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'nummod':\n",
    "            obj = doc[child.left_edge.i : child.right_edge.i + 1]\n",
    "            return obj   \n",
    "\n",
    "def extract_dnummod(t, doc):\n",
    "    obj = extract_nounandverb_nummods(t, doc)\n",
    "    if obj:\n",
    "        return obj.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_noun_adjectives(t, doc):\n",
    "    adjs = []\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'appos' or child.dep_ == 'compound':\n",
    "            continue\n",
    "        if child.pos_ =='ADJ' or child.tag_ == 'VBN' and child.dep_ in ['conj', 'amod']:\n",
    "            if child.lemma_.lower() in compounds or child.text.lower() in compounds:\n",
    "                continue\n",
    "            measurement = extract_measurements(child, doc)\n",
    "            if measurement:\n",
    "                obj = measurement\n",
    "                adjs.append(obj)\n",
    "            amod = extract_amod(child, doc)\n",
    "            if amod:\n",
    "                obj = define_position(amod, child, doc)\n",
    "                adjs.append(obj)\n",
    "            advmod = extract_advmod(child, doc)\n",
    "            if advmod:\n",
    "                obj = define_position(advmod, child, doc)\n",
    "                adjs.append(obj)\n",
    "            prep = extract_prepositions(child, doc)\n",
    "            if prep:\n",
    "                obj = define_position(prep, child, doc)\n",
    "                adjs.append(obj)\n",
    "            nummod = extract_nummod(child, doc)\n",
    "            if nummod:\n",
    "                obj = define_position(nummod, child, doc)\n",
    "                adjs.append(obj)                \n",
    "            if not any((measurement, amod, advmod, prep, nummod)): \n",
    "                obj = child\n",
    "                adjs.append(obj)\n",
    "            for grandchild in child.subtree:\n",
    "                conj = extract_conjunction(grandchild, doc)\n",
    "                if conj:\n",
    "                    advmod = extract_advmod(conj, doc)\n",
    "                    if advmod:\n",
    "                        obj = define_position(advmod, conj, doc)\n",
    "                        adjs.append(obj)\n",
    "                    prep = extract_prepositions(conj, doc)\n",
    "                    if prep:\n",
    "                        obj = define_position(prep, conj, doc)\n",
    "                        adjs.append(obj)\n",
    "                    nummod = extract_nummod(conj, doc)\n",
    "                    if nummod:\n",
    "                        obj = define_position(nummod, conj, doc)\n",
    "                        adjs.append(obj)\n",
    "                    if not any((advmod, prep, nummod)):\n",
    "                        obj = conj\n",
    "                        adjs.append(obj)\n",
    "                        \n",
    "    return clean_adjectives(adjs)\n",
    "\n",
    "def extract_noun_appos(t, doc):\n",
    "    appos = []\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'appos':\n",
    "            obj = doc[child.left_edge.i : child.right_edge.i + 1].text.lower()\n",
    "            for obj_split in obj.split(','):\n",
    "                appos.append(obj_split.strip())\n",
    "    return appos\n",
    "\n",
    "def extract_noun_prep(t, doc):\n",
    "    preps = []\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'prep':\n",
    "            obj = doc[child.left_edge.i : child.right_edge.i + 1].text.lower()\n",
    "            for obj_split in obj.split(','):\n",
    "                preps.append(obj_split.strip())\n",
    "    return preps\n",
    "\n",
    "def check_species(t, species, doc):\n",
    "    if t.text in species.split():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def extract_noun_verbs_ROOT(t, doc):\n",
    "    relations = []\n",
    "    objects = []\n",
    "    if t.dep_ not in ['ROOT', 'nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "        return '', ''\n",
    "    parent = next((parent for parent in t.ancestors), None)\n",
    "    if parent and parent.pos_ == 'VERB' or parent and parent.pos_ == 'AUX':\n",
    "        try:\n",
    "                        \n",
    "            prep = extract_verb_prep(parent, doc)\n",
    "            if prep: \n",
    "                relations.append(f'{parent.text} {prep}'), objects.append(extract_verb_pobj(prep, doc).lemma_)\n",
    "            dobj = extract_verb_dobj(parent, doc)\n",
    "            if dobj: \n",
    "                relations.append(parent.text), objects.append(extract_verb_pobj(dobj, doc).lemma_)\n",
    "            oprd = extract_verb_orpd(parent, doc)\n",
    "            if oprd: \n",
    "                relations.append(parent.text), objects.append(oprd.text)\n",
    "            agnt = extract_verb_agnt(parent, doc)\n",
    "            if agnt: \n",
    "                relations.append(f'{parent.text} {agnt}'), objects.append(extract_verb_pobj(agnt, doc).lemma_)\n",
    "            nmod = extract_verb_nmod(parent, doc)\n",
    "            if nmod: \n",
    "                print(nmod)\n",
    "            advm = extract_verb_advm(parent, doc)\n",
    "            if advm: \n",
    "                relations.append(parent.text), objects.append(advm.text)\n",
    "            acomp = extract_verb_acomp(parent, doc)\n",
    "            if acomp: \n",
    "                relations.append(parent.text), objects.append(acomp) # Already text\n",
    "            attr = extract_verb_attr(parent, doc)\n",
    "            if attr:\n",
    "                relations.append(parent.text), objects.append(attr) # Already text\n",
    "            if not any((prep, dobj, oprd, agnt, nmod, advm, acomp, attr)): \n",
    "                relations.append('are'), objects.append(parent.text)\n",
    "        except:\n",
    "            print(333)\n",
    "            pass\n",
    "       \n",
    "    return clean_verbs(relations, objects)\n",
    "\n",
    "def extract_noun_verbs_NON_ROOT(t, doc):\n",
    "    relations = []\n",
    "    objects = []\n",
    "    if t.dep_ not in ['ROOT', 'nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "        return '', ''\n",
    "    # Double check\n",
    "    parent = next((parent for parent in t.ancestors), None)\n",
    "    if not parent:\n",
    "        try:\n",
    "            for child in t.children:\n",
    "                if child.pos_ == 'VERB' and child.dep_ != 'amod':\n",
    "                    print(child)\n",
    "                    \n",
    "                    prep = extract_verb_prep(child, doc)\n",
    "                    if prep: \n",
    "                        noun = extract_verb_pobj(prep, doc)\n",
    "                        relations.append(f'{child.text} {prep}')\n",
    "                        objects.append(doc[noun.left_edge.i : noun.right_edge.i + 1].text)\n",
    "                    dobj = extract_verb_dobj(child, doc)\n",
    "                    if dobj:\n",
    "                        relations.append(child.text)\n",
    "                        objects.append(dobj.lemma_) \n",
    "                    oprd = extract_verb_orpd(child, doc)\n",
    "                    if oprd:\n",
    "                        oprd_prep = extract_verb_prep(oprd, doc)\n",
    "                        if oprd_prep:\n",
    "                            relations.append(f'{child.text} {oprd.text}')\n",
    "                            objects.append(doc[oprd_prep.left_edge.i : oprd_prep.right_edge.i + 1].text) \n",
    "                        else:\n",
    "                            relations.append(child.text), objects.append(oprd.text)\n",
    "                    agnt = extract_verb_agnt(child, doc)\n",
    "                    if agnt:\n",
    "                        noun = extract_verb_pobj(agnt, doc)\n",
    "                        relations.append(f'{child.text} {agnt.text}')\n",
    "                        objects.append(doc[noun.left_edge.i : noun.right_edge.i + 1].text)\n",
    "                    nmod = extract_verb_nmod(child, doc)\n",
    "                    if nmod:\n",
    "                        relations.append('is')\n",
    "                        objects.append(f'{nmod.text} {child}') \n",
    "        except:\n",
    "            pass\n",
    "                        \n",
    "    return clean_verbs(relations, objects)\n",
    "\n",
    "\n",
    "def clean_verbs(relations, objects):\n",
    "    \n",
    "    rel = []\n",
    "    obj = []\n",
    "    for relation, object_ in zip(relations, objects):\n",
    "        #rel.append(relation)\n",
    "        #obj.append(object_.split(',')[0])\n",
    "        \n",
    "        for obj_split in re.split(',|and', object_):\n",
    "            #print(relation, obj_split)\n",
    "            rel.append(relation.lower().strip())\n",
    "            obj.append(obj_split.lower().strip())            \n",
    "            \n",
    "    return rel, obj\n",
    "\n",
    "def clean_adjectives(adjs):\n",
    "    \n",
    "    adjectives = []\n",
    "    for adj in adjs:\n",
    "        try:\n",
    "            if adj.pos_ == 'VERB':\n",
    "                adj_text = adj.text.lower()\n",
    "            elif adj.root.pos_ == 'VERB':\n",
    "                adj_text = adj.text.lower()\n",
    "            else:\n",
    "                adj_text = adj.lemma_.lower()\n",
    "        except:\n",
    "                if type(adj) == str:\n",
    "                    adj_text = adj.lower()\n",
    "                else:\n",
    "                    adj_text = adj.text.lower()\n",
    "        for adj_split in adj_text.split(','):\n",
    "            adjectives.append(adj_split.strip())\n",
    "    \n",
    "    return adjectives\n",
    "        \n",
    "def adjective_reverser(doc):\n",
    "    root = next(t for t in doc if t.dep_ == 'ROOT')\n",
    "    if root.pos_ == 'ADJ':\n",
    "        \n",
    "        span_1 = doc[root.i - 1].text.lower()\n",
    "        span_2 = root.text.capitalize()\n",
    "        span_3 = doc[root.i + 1 : ].text\n",
    "        \n",
    "        text = f'{span_2} {span_1} {span_3}'\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        print('asd')\n",
    "    \n",
    "    return doc        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "920294d4-b81a-4c0b-a0a0-b4b11508b2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7181cf732c0f41d088d5c1a3ac287603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Simple perforation rim, vessel-vessel pits.\n",
      "[]\n",
      "\n",
      "\n",
      "1 Axial parenchyma   Axial parenchyma paratracheal and confluent to banded.\n",
      "[]\n",
      "\n",
      "\n",
      "2 Habit:   Shrub to 4 m tall, occasionally a small tree to 7 m   Distribution:  Introduced.\n",
      "[('species', 'has main part', 'plant property'), ('plant property', 'has sub part', 'shrub'), ('shrub', 'is', 'a small tree to 7 m'), ('shrub', 'is', 'to 4 m tall'), ('species', 'has main part', 'plant property'), ('plant property', 'has sub part', 'tree'), ('tree', 'is', 'small'), ('tree', 'is', 'to 7 m')]\n",
      "\n",
      "\n",
      "3 Rays 1-2 cells wide.\n",
      "[('species', 'has main part', 'basic flower parts'), ('basic flower parts', 'has sub part', 'cell'), ('cell', 'is', '1-2')]\n",
      "\n",
      "\n",
      "4 Longitudinal surface.\n",
      "[('species', 'has main part', 'leaves'), ('leaves', 'has sub part', 'surface'), ('surface', 'is', 'longitudinal')]\n",
      "\n",
      "\n",
      "5 Rays  Rays 1-2 cells wide with uniseriate rays present.\n",
      "[('species', 'has main part', 'basic flower parts'), ('basic flower parts', 'has sub part', 'cell'), ('cell', 'is', '1-2')]\n",
      "\n",
      "\n",
      "6 Branches glabrous or nearly, purplish to grey, with very small glands, stipules spinescent, usually short, up to 1.8 cm long, rarely longer, never inflated, leaves twice pinnate, with a small gland on petiole and sometimes one on the rachis near top of pinnae, pinnae 2-8 pairs, leaflets 10-12 pairs, minute, 2-7 mm long, 0.75-1.75 mm wide.\n",
      "[('species', 'has main part', 'stems'), ('stems', 'has sub part', 'branch'), ('branch', 'is', 'glabrous'), ('branch', 'is', 'purplish to grey'), ('branch', 'is', 'leaves'), ('branch', 'is', 'twice pinnate'), ('branch', 'is', 'with a small gland on petiole and sometimes one on the rachis near top of pinnae'), ('branch', 'is', 'pinnae 2-8 pairs'), ('branch', 'is', 'leaflets 10-12 pairs'), ('branch', 'is', 'minute'), ('branch', 'is', '2-7 mm long'), ('branch', 'is', '0.75-1.75 mm wide'), ('species', 'has main part', 'leaves'), ('leaves', 'has sub part', 'stipule'), ('stipule', 'is', 'spinescent'), ('stipule', 'is', 'usually short'), ('stipule', 'is', 'up to 1.8 cm long'), ('stipule', 'is', 'rarely longer'), ('stipule', 'is', 'rarely longer'), ('stipule', 'is', 'inflated'), ('species', 'has main part', 'leaves'), ('leaves', 'has sub part', 'leave'), ('species', 'has main part', 'leaves'), ('leaves', 'has sub part', 'petiole'), ('species', 'has main part', 'leaves'), ('leaves', 'has sub part', 'rachi'), ('species', 'has main part', 'leaves'), ('leaves', 'has sub part', 'leaflet'), ('leaflet', 'is', '10-12 pairs')]\n",
      "\n",
      "\n",
      "7 A  farnesiana is a spinescent shrub, or rarely a small tree, 2-7 m tall with several slender stems and long thin branches growing from ground level.\n",
      "[('species', 'has main part', 'plant property'), ('plant property', 'has sub part', 'shrub'), ('shrub', 'is', 'spinescent'), ('shrub', 'is', 'with several slender stems and long thin branches growing from ground level'), ('species', 'has main part', 'plant property'), ('plant property', 'has sub part', 'tree'), ('tree', 'is', 'small'), ('tree', 'is', 'tall'), ('species', 'has main part', 'stems'), ('stems', 'has sub part', 'stem'), ('stem', 'is', 'several'), ('stem', 'is', 'slender'), ('species', 'has main part', 'stems'), ('stems', 'has sub part', 'branch'), ('branch', 'is', 'long'), ('branch', 'is', 'thin')]\n",
      "\n",
      "\n",
      "8 University of Hawaii Botany Department describe A  farnesiana as thorny, deciduous, growing to 4 m in height.\n",
      "[]\n",
      "\n",
      "\n",
      "9 The slightly rough stems are a rich chocolate brown or grey, possessing long, sharp, multiple thorns.\n",
      "[('species', 'has main part', 'stems'), ('stems', 'has sub part', 'stem'), ('stem', 'is', 'slightly rough'), ('stem', 'are', 'a rich chocolate brown or grey'), ('species', 'has main part', 'stems'), ('stems', 'has sub part', 'thorn'), ('thorn', 'is', 'long'), ('thorn', 'is', 'sharp'), ('thorn', 'is', 'multiple')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descriptions = collections.defaultdict(list)\n",
    "\n",
    "# For plotting purposes\n",
    "parts = []\n",
    "traits = []\n",
    "for species in tqdm_notebook(list(data.keys())[2:3]):\n",
    "    for idx, text in enumerate(data[species][0:10]):\n",
    "\n",
    "        # Clean the text\n",
    "        text = re.sub(r'(?<!\\d)\\.(?!\\d)', ' ', text)\n",
    "        text = re.sub(r'\\s×\\s', ' times ', text)\n",
    "        text = re.sub(r'\\xa0', ' ', text)\n",
    "        text = f'{text.strip()}.'\n",
    "        # Reset variables\n",
    "        part=trait=rel=obj=adjectives = None \n",
    "        # NLP\n",
    "        doc = nlp(text)\n",
    "        # Init\n",
    "        descriptions[species, idx] = []\n",
    "        triples = []\n",
    "        # Loop over tokens\n",
    "        for t in doc:\n",
    "            if t.dep_ == 'compound':\n",
    "                continue\n",
    "            ### SUBJECTS ###    \n",
    "            if t.pos_ == 'NOUN' or t.pos_ == 'PROPN':\n",
    "                # Check existance of parts\n",
    "                part = check_existance(t, doc)\n",
    "                if part:\n",
    "                    # Reconstruct Compounds & Append\n",
    "                    trait = compound_reconstructor(t, doc)\n",
    "                    triples.append(('species', 'has main part', part))\n",
    "                    triples.append((part, f'has sub part', trait))\n",
    "                    # NOUN ADJECTIVES\n",
    "                    adjectives = extract_noun_adjectives(t, doc)\n",
    "                    for adjective in adjectives:\n",
    "                        triples.append((trait, 'is', adjective))\n",
    "                    # NOUN ROOT VERBS\n",
    "                    verbs_rel, verbs_obj = extract_noun_verbs_ROOT(t, doc)\n",
    "                    for rel, obj in zip(verbs_rel, verbs_obj):\n",
    "                        triples.append((trait, rel, obj))\n",
    "                    # NOUN NON ROOT VERBS\n",
    "                    verbs_rel, verbs_obj = extract_noun_verbs_NON_ROOT(t, doc)\n",
    "                    for rel, obj in zip(verbs_rel, verbs_obj):\n",
    "                        triples.append((trait, rel, obj))\n",
    "                    # NOUN APPOSITIONAL MODIFIER\n",
    "                    adjectives = extract_noun_appos(t, doc)\n",
    "                    for adjective in adjectives:\n",
    "                        triples.append((trait, 'is', adjective))\n",
    "                    # NOUN NUMMODS\n",
    "                    nummod = extract_dnummod(t, doc)\n",
    "                    triples.append((trait, 'is', nummod))\n",
    "                    # NOUN PREPOSITIONAL MODIFIER\n",
    "                    adjectives = extract_noun_prep(t, doc)\n",
    "                    for adjective in adjectives:\n",
    "                        triples.append((trait, 'is', adjective))                \n",
    "\n",
    "        # APPEND\n",
    "        descriptions[species, idx] = [triple for triple in triples if all(triple)]     \n",
    "        \n",
    "                    \n",
    "        print(idx, doc)\n",
    "        print(descriptions[species, idx])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "197a4970-8d2e-4f0b-bc60-66da5439cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"16f0062bfc0c4c07b84d572b5dbb301f-0\" class=\"displacy\" width=\"2500\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">plant</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">leaves</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">dark</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">green,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">its</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">flowers</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">pinkish-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">white</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">color.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-5\" stroke-width=\"2px\" d=\"M595,352.0 C595,89.5 1095.0,89.5 1095.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,354.0 L1103.0,342.0 1087.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-8\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1625.0,2.0 1625.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1625.0,354.0 L1633.0,342.0 1617.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,354.0 L1793.0,342.0 1777.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-11\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2170,354.0 L2162,342.0 2178,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-12\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,89.5 2320.0,89.5 2320.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f0062bfc0c4c07b84d572b5dbb301f-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2320.0,354.0 L2328.0,342.0 2312.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7d2cd70-5c9f-4235-a7f9-eeadb2facdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_verbs_ROOT(t, doc):\n",
    "    relations = []\n",
    "    objects = []\n",
    "    if t.dep_ not in ['ROOT', 'nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "        return '', ''\n",
    "    parent = next((parent for parent in t.ancestors), None)\n",
    "    if parent and parent.pos_ == 'VERB' or parent and parent.pos_ == 'AUX':\n",
    "        try:\n",
    "                        \n",
    "            prep = extract_verb_prep(parent, doc)\n",
    "            if prep: \n",
    "                relations.append(f'{parent.text} {prep}'), objects.append(extract_verb_pobj(prep, doc).lemma_)\n",
    "            dobj = extract_verb_dobj(parent, doc)\n",
    "            if dobj: \n",
    "                relations.append(parent.text), objects.append(extract_verb_pobj(dobj, doc).lemma_)\n",
    "            oprd = extract_verb_orpd(parent, doc)\n",
    "            if oprd: \n",
    "                relations.append(parent.text), objects.append(oprd.text)\n",
    "            agnt = extract_verb_agnt(parent, doc)\n",
    "            if agnt: \n",
    "                relations.append(f'{parent.text} {agnt}'), objects.append(extract_verb_pobj(agnt, doc).lemma_)\n",
    "            nmod = extract_verb_nmod(parent, doc)\n",
    "            if nmod: \n",
    "                print(nmod)\n",
    "            advm = extract_verb_advm(parent, doc)\n",
    "            if advm: \n",
    "                relations.append(parent.text), objects.append(advm.text)\n",
    "            acomp = extract_verb_acomp(parent, doc)\n",
    "            if acomp: \n",
    "                relations.append(parent.text), objects.append(acomp) # Already text\n",
    "            if not any((prep, dobj, oprd, agnt, nmod, advm, acomp)): \n",
    "                relations.append('are'), objects.append(parent.text)\n",
    "        except:\n",
    "            print(333)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13df69a8-0a8d-4e71-a55d-d4cf893a2c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_noun_verbs_ROOT(doc[1],doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6880f99-d1c1-43d2-865b-3bcba1927508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
