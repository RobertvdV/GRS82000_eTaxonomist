{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee01308e-ccfe-4e97-acc4-796037133388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import display, HTML\n",
    "from transformers import DistilBertModel, DistilBertTokenizer, logging\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../src/models/')\n",
    "sys.path.insert(0, '../../src/features/')\n",
    "\n",
    "from build_features import similarity_matrix as vector_values\n",
    "from predict_model import load_CUB_Bert, load_simBERT\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14cda9b-c2c2-4bc3-b271-5c6fefe71fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfc21eb-f23d-4514-9124-dea6172e0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Success\n"
     ]
    }
   ],
   "source": [
    "model = load_CUB_Bert(\"../../models/\", 'saved_weights_CUB_CHUNKS_1881.pt')\n",
    "#SIMmodel = load_simBERT()\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2b95c6-5584-46e4-bf2b-db2cc5f74c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence\n",
    "\n",
    "# Modify the prediction output and define a custom forward\n",
    "def predict(inputs, attentions):\n",
    "    return model(input_ids=inputs, attention_mask=attentions)[0]\n",
    "\n",
    "def custom_forward(inputs, attentions):\n",
    "    preds = predict(inputs, attentions)\n",
    "    return torch.exp(preds)\n",
    "\n",
    "# Tokenize functions\n",
    "def construct_input_ref_pair(text, ref_token_id, sep_token_id, cls_token_id):\n",
    "\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(text_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "# Summarize and vis functions\n",
    "def summarize_attributions_ig(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "def summarize_attributions_occ(attributions):\n",
    "    return attributions.sum(axis=0)\n",
    "\n",
    "def token_to_words(attribution, tokens):\n",
    "    \n",
    "    words = []\n",
    "    attributes = []\n",
    "\n",
    "    for attribute, word in zip(attribution, tokens):\n",
    "\n",
    "        attribute = attribute.cpu().detach().numpy()\n",
    "        if word == '[CLS]' or word == '[SEP]':\n",
    "            words.append(word)\n",
    "            attributes.append([attribute])\n",
    "        elif not word.startswith('##'):\n",
    "            words.append(word)\n",
    "            attributes.append([attribute])\n",
    "        elif word.startswith('##'):\n",
    "            words[-1] += word.strip('##')\n",
    "            attributes[-1] = np.append(attributes[-1], attribute)\n",
    "\n",
    "    attribution = [np.sum(mean) for mean in attributes]\n",
    "    return attribution, words\n",
    "\n",
    "def colorize(attribution, tokens):\n",
    "    \n",
    "    template = \"\"\"  \n",
    "    <mark class=\"entity\" style=\" background: {}; padding: 0.4em 0.0em; margin: 0.0em; line-height: 2; \n",
    "    border-radius: 0.0em; \">{}<span style=\" font-size: 0.8em;  font-weight: bold;  line-height: 1; \n",
    "    border-radius: 0.0em; text-align-last:center; vertical-align: middle; margin-left: 0rem; \"></span></mark>\n",
    "    \"\"\"\n",
    "\n",
    "    colored_string = ''\n",
    "    normalized_and_mapped = matplotlib.cm.ScalarMappable(cmap=matplotlib.cm.Greens).to_rgba(attribution)\n",
    "    for idx, (word, color) in enumerate(zip(tokens, normalized_and_mapped)):\n",
    "        \n",
    "        word = word + ' '\n",
    "        color = matplotlib.colors.rgb2hex(color[:3])\n",
    "        if word.strip() == '[CLS]' or word.strip() == '[SEP]': \n",
    "            color = '#ffffff'\n",
    "        #print(color)\n",
    "        colored_string += template.format(color, word)\n",
    "\n",
    "    return colored_string\n",
    "\n",
    "def explain(word):\n",
    "    \n",
    "    #data = []\n",
    "       \n",
    "    # tokenize\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(word, ref_token_id, sep_token_id, cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "    indices = input_ids[0].type(torch.LongTensor)\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "    \n",
    "    #### Occlusion maps (3, 2)\n",
    "    attribution_occ2 = occ.attribute(inputs=(input_ids, attention_mask),\n",
    "                                sliding_window_shapes=(tuple([3,]), tuple([3,])), \n",
    "                                strides=(2, 2), \n",
    "                                baselines=(ref_input_ids, attention_mask),)\n",
    "    attribution_occ2_sum = summarize_attributions_occ(attribution_occ2[0])\n",
    "    attributions_occ2_words, words = token_to_words(attribution_occ2_sum, all_tokens)\n",
    "    data = [(word, attr) for word, attr in zip(words, attributions_occ2_words)]\n",
    "    ####\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2c73368-3a8f-4c05-8137-937d8aa4e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Occlusion\n",
    "occ     = Occlusion(custom_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc507c02-e8d2-4f0b-8f91-97015580b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Example\n",
    "string = 'Orange legs with long nails.'\n",
    "data = explain(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12229727-503a-4e55-84f0-60f8243449b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]', 1.7881393e-07),\n",
       " ('orange', 1.7881393e-07),\n",
       " ('legs', 4.4703484e-08),\n",
       " ('with', -5.9604645e-08),\n",
       " ('long', -1.1920929e-07),\n",
       " ('nails', -2.0861626e-07),\n",
       " ('.', -2.3841858e-07),\n",
       " ('[SEP]', -2.0861626e-07)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5cb5c-322e-4e2b-8fcf-c1ecee99ec12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
