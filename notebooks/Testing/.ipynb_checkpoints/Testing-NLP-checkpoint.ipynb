{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d19423-061e-4cc9-b37d-2ff2ce09710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch import nn\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbfe3cd-dc36-4c65-8074-c47cdc70d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "pickle_in = open(\"data_withMeasurements.pkl\", \"rb\")\n",
    "dataWIKI = pickle.load(pickle_in)\n",
    "\n",
    "# Load data\n",
    "pickle_in = open(\"dataBOW_withMeasurements.pkl\", \"rb\")\n",
    "dataBOW = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3b4bc10-ba1e-4cff-be77-442d952f576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data together\n",
    "#data = dataWIKI | dataBOW\n",
    "#data = dataWIKI\n",
    "data = dataBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0135fbc-34ec-4b11-8de3-8e34c8ad5b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6890 values.\n",
      "2511 labels with 1 (true).\n",
      "4379 labels with 0 (false).\n"
     ]
    }
   ],
   "source": [
    "TotalValues = list(chain.from_iterable(data.values()))\n",
    "\n",
    "ones = Counter(ones[0] for ones in TotalValues if ones[0] == 1)\n",
    "zeros = Counter(ones[0] for ones in TotalValues if ones[0] == 0)\n",
    "\n",
    "print('{0} values.'. format(len(TotalValues)))\n",
    "print('{0} labels with 1 (true).'.format(ones[1]))\n",
    "print('{0} labels with 0 (false).'.format(zeros[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "362c398b-9358-48bc-87a5-40676264a56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Species\\nlen(data)\\n# Total values\\nTotal = sum(len(v) for v in list(data.values()))\\nprint(Total)\\n# Total Truths\\nTotalValues = [v for v in list(data.values())]\\nTruths = [[ones[0] for ones in Values if ones[0] == 1] for Values in TotalValues]\\nAmountofTruths = sum(len(x) for x in Truths)\\n# Total False\\nAmountofFalse = Total - AmountofTruths\\nprint(AmountofTruths)\\nprint(AmountofFalse)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Species\n",
    "len(data)\n",
    "# Total values\n",
    "Total = sum(len(v) for v in list(data.values()))\n",
    "print(Total)\n",
    "# Total Truths\n",
    "TotalValues = [v for v in list(data.values())]\n",
    "Truths = [[ones[0] for ones in Values if ones[0] == 1] for Values in TotalValues]\n",
    "AmountofTruths = sum(len(x) for x in Truths)\n",
    "# Total False\n",
    "AmountofFalse = Total - AmountofTruths\n",
    "print(AmountofTruths)\n",
    "print(AmountofFalse)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c52af21-0669-46c4-ba4a-d5f9e67a291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values from the dict\n",
    "data = list(chain.from_iterable(data.values()))\n",
    "# Train test sequence\n",
    "train = int(len(data) * 0.8)\n",
    "test = len(data) - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afc90c63-95b6-4a81-aa04-d6c94c369d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "trainset = data[0:train]\n",
    "testset = data[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62ada087-f784-4140-85e8-4ef7b8cbb817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5512"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "708d5b7b-bc04-4e2a-a60d-7d772aeae649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic English\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Tokenize the dataset\n",
    "def yield_tokens(data_iter):\n",
    "    # Drop the label (label, text)\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Build a vocabulary        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(trainset), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a6ce8fa-9f29-4127-a754-a9e35b14c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "# -1 could be removed if data is loaded differently\n",
    "label_pipeline = lambda x: int(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4b51979-1c1c-4e6f-9b6c-936eff41b454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  10,   13,  345,   40,    1,   10,  705,   25,   55, 4512,    2])\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "proc = torch.tensor(text_pipeline('the a bird birds, the bear are not equal.'), dtype=torch.int64)\n",
    "print(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa2995c1-cb7d-4c68-bcd0-b06e70622b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (CPU for macs)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \n",
    "    '''\n",
    "    Convert sentences or paragrahs to integers by using\n",
    "    the PyTorch Vocab(). The data is converted and \n",
    "    returned as a tensor. The offset of the words is \n",
    "    compared to the start of the sentence/paragraph.\n",
    "    '''\n",
    "\n",
    "    # Init lists\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    \n",
    "    # Loop over the data\n",
    "    for (_label, _text) in batch:\n",
    "        # Append the labels to list\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        # Process the text (singed 64), and convert to tensor\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        # Append the text to list \n",
    "        text_list.append(processed_text)\n",
    "        # Append the offset (tensor size)   \n",
    "        offsets.append(processed_text.size(0))\n",
    "    \n",
    "    # Convert the label list to a tensor\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    # Cummulative sum the offsets (dim=0 == rowwise)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    # Concatenate the text list\n",
    "    text_list = torch.cat(text_list)\n",
    "    \n",
    "    # Return the values\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "533c99c8-bb8c-41f0-91da-a64be4fb783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "dataloader = DataLoader(train_iter, batch_size=16, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0583f2f-dcda-4c29-a4a5-562259e7a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]),\n",
       " tensor([551,  91,  71,  ...,  27, 113,   2]),\n",
       " tensor([   0,   12,   18,  114,  287,  384,  973, 1007, 1610, 1711, 1976, 2036,\n",
       "         2039, 2059, 2086, 2111]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a49b6e0-7eb0-46b7-b743-c8528401b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1144cfc2-43c0-44d0-9f5c-493cc449e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = trainset\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ede95da0-ce09-4593-b1dd-0a0c0da61d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12ca46ca-7f2a-43e6-bbb5-e1781dd0f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/  655 batches | accuracy    0.871\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.22s | valid accuracy    0.917 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/  655 batches | accuracy    0.935\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.14s | valid accuracy    0.888 \n",
      "-----------------------------------------------------------\n",
      "| epoch   3 |   500/  655 batches | accuracy    0.951\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.14s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n",
      "| epoch   4 |   500/  655 batches | accuracy    0.953\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.13s | valid accuracy    0.942 \n",
      "-----------------------------------------------------------\n",
      "| epoch   5 |   500/  655 batches | accuracy    0.956\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.15s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n",
      "| epoch   6 |   500/  655 batches | accuracy    0.957\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.14s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n",
      "| epoch   7 |   500/  655 batches | accuracy    0.959\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.16s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n",
      "| epoch   8 |   500/  655 batches | accuracy    0.959\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.13s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n",
      "| epoch   9 |   500/  655 batches | accuracy    0.960\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.13s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n",
      "| epoch  10 |   500/  655 batches | accuracy    0.959\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.16s | valid accuracy    0.935 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 8 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = trainset, testset\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c85ffde5-d8d3-477a-9e7b-621066b9f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.987\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b64ebfcb-a5a5-4bce-93bd-dec92c8d7ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a description or similar.\n",
      "This is something else.\n",
      "This is a description or similar.\n",
      "This is a description or similar.\n",
      "This is a description or similar.\n",
      "This is a description or similar.\n"
     ]
    }
   ],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         0: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() \n",
    "\n",
    "# Measurements\n",
    "ex_text_str = 'They are 90 to 150 cm tall at the shoulder and can tower at an intimidating height of 8 feet when standing upright on their hind legs.'\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Random\n",
    "ex_text_str = 'Hi I am GIS student, this is a random sentence!'\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Bird stuff\n",
    "ex_text_str = 'The bill is long and orange.'\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Something about bears\n",
    "ex_text_str = '''Brown bears are often not fully brown. \n",
    "                They have long, thick fur, with a moderately long mane at the back of the neck which varies somewhat across the types. \n",
    "                In India, brown bears can be reddish with silver-tipped hairs, while in China brown bears are bicolored, \n",
    "                with a yellowish-brown or whitish collar across the neck, chest and shoulders.'''\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Somehting about Robins\n",
    "ex_text_str = '''The upperparts are brownish, or olive-tinged in British birds, and the belly whitish, while the legs and feet are brown. \n",
    "                The bill and eyes are black.'''\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "\n",
    "# Random Difficult sentence\n",
    "ex_text_str = '''While I am very tan from the sun, I can be pale within a few days.\n",
    "                I have blonde hair'''\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c71d33-b09c-43f9-8a3b-3b6fc75a3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dicts\n",
    "ExtraTesting = []\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "URL = 'https://en.wikipedia.org/wiki/Eurasian_wigeon'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "for Tags in soup.find_all('h2'):\n",
    "\n",
    "    # Skip useless/empty stuff\n",
    "    if Tags.span == None:\n",
    "        continue\n",
    "\n",
    "    # Set chapter variable    \n",
    "    Chapter = Tags.span.attrs['id']\n",
    "\n",
    "    # Check if the chapter is description (or similar)\n",
    "    if Chapter == 'Characteristics'or \\\n",
    "       Chapter == 'Description' or \\\n",
    "       Chapter == 'Appearance':\n",
    "\n",
    "        # Get the next sibling (text)\n",
    "        for Text in Tags.find_next_siblings('p'):\n",
    "\n",
    "            # Add description data to dict\n",
    "            if Chapter in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(1, Sentence) for Sentence in SentenceList]\n",
    "\n",
    "            # Add non description data to dict\n",
    "            elif Chapter not in Text.find_previous_siblings('h2')[0].text.strip():\n",
    "                # Remove source\n",
    "                Paragraph = re.sub(ReferenceRemover, '', Text.text)\n",
    "                # Split into Sentences\n",
    "                SentenceList = Paragraph.split('. ')\n",
    "                # Add to the dict\n",
    "                ExtraTesting += [(0, Sentence) for Sentence in SentenceList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597ada4-0238-4f00-9a77-35fe42c0881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {1: \"a description or similar.\",\n",
    "         0: \"something else.\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item() \n",
    "\n",
    "for tests in ExtraTesting:\n",
    "    ex_text_str = tests[1]\n",
    "    \n",
    "    model = model.to(\"cpu\")\n",
    "\n",
    "    print(\"This is %s\" %label[predict(ex_text_str, text_pipeline)])\n",
    "    print(\"Real value was {0}\".format(tests[0]))\n",
    "    print(tests[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25eb47-da5e-4001-929b-962a7a885bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
