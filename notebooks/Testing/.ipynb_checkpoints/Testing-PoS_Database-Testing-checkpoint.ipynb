{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4972715-9f9c-4211-a549-78a985fe3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "import collections\n",
    "import re\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from netgraph import Graph\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b9bf2e-d590-430b-88db-621b3fcc5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color checker\n",
    "colors = list(mcolors.CSS4_COLORS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2c3d0-34e3-4e66-9063-ebb378e25566",
   "metadata": {},
   "source": [
    "## Create a glossary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77ff15e-7660-473a-9baf-87dd589d9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "URL = 'https://en.wikipedia.org/wiki/Glossary_of_plant_morphology'\n",
    "# Get the page\n",
    "page = requests.get(URL, timeout=5)\n",
    "soup = BeautifulSoup(page.content, \"lxml\", from_encoding=\"iso-8859-1\")   \n",
    "\n",
    "glossary = collections.defaultdict(list)\n",
    "# Find all H4 \n",
    "for chapter in soup.find_all('h4')[0:]:\n",
    "    # Clean\n",
    "    chapter_text = chapter.text.rstrip('[edit]')\n",
    "    # Find all siblings\n",
    "    for sibling in chapter.find_next_siblings():\n",
    "        # Find the parent\n",
    "        for parent in sibling.find_previous_sibling('h4'):\n",
    "            # Only append if correspond to current chapter\n",
    "            if parent.text == chapter_text:\n",
    "                if 'â' in sibling.text:\n",
    "                    for tag in sibling.find_all('li'):\n",
    "                        candidates = tag.text.split('â')[0]\n",
    "                        candidates = candidates.split('/')\n",
    "                        for candidate in candidates:\n",
    "                            glossary[chapter_text.lower()].append(candidate.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79d43f1-466a-423e-af57-e92e3ba3df99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['morphology', 'roots', 'stems', 'buds', 'leaves', 'basic flower parts', 'inflorescences', 'insertion of floral parts', 'union of flower parts', 'flower sexuality and presence of floral parts', 'flower symmetry', 'terms for fruits', 'fruit types', 'pteridophytes', 'bryophytes'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42656c0-55ac-4b52-b703-985565efeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glossary['fruit types'] += [\n",
    "#    'fruit',\n",
    "#]\n",
    "\n",
    "glossary['leaves'] += [\n",
    "    'glume',\n",
    "    'surface',\n",
    "    'margin'\n",
    "]\n",
    "\n",
    "glossary['basic flower parts'] +=[\n",
    "    'floret',\n",
    "    'awn',\n",
    "    \n",
    "]\n",
    "glossary['inflorescences'] += [\n",
    "    'spikelets',\n",
    "    'lemma',\n",
    "    'racemes',\n",
    "    'axis',\n",
    "]\n",
    "glossary['leaves'] += [\n",
    "    'rhachilla'\n",
    "]\n",
    "\n",
    "glossary['other'] += [\n",
    "    'apex',\n",
    "    'culm',\n",
    "    'tube',\n",
    "    'palea',\n",
    "    'crown',\n",
    "    'canopy',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9ceb5-bb96-427e-9a6d-5fcade9ef7bc",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba1afef-91f9-4b05-9af5-2467860f2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pickle.load(open('../../data/description/04_TRAIN_0000000-0014557_PLANTS.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e130d125-8caf-447b-ba7b-bc215a6061da",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_id = collections.defaultdict(list)\n",
    "descriptions = collections.defaultdict(list)\n",
    "\n",
    "compounds = [\n",
    "    'fertile', 'sterile',\n",
    "    'male', 'female', 'bisexual',\n",
    "    'basal', 'developed', \n",
    "    'primary', 'secondary', 'main',\n",
    "    'upper', 'lower', 'greater', 'dorsal', 'alternate', 'lesser', 'apex', 'outer',\n",
    "    'central', 'outermost', 'outer', 'inner', 'uppermost', 'median', 'dorsal', 'central', 'lateral',\n",
    "]\n",
    "\n",
    "def compound_reconstructor(token, doc):\n",
    "    if token.i == 0:\n",
    "        trait = token\n",
    "    elif doc[token.i - 3].dep_ == 'compound':\n",
    "        trait = doc[token.i - 3: token.i + 1]\n",
    "    elif doc[token.i - 3].text.lower() in compounds or doc[token.i - 3].lemma_.lower() in compounds:\n",
    "        trait = doc[token.i - 3: token.i + 1]\n",
    "    elif doc[token.i - 2].dep_ == 'compound':\n",
    "        trait = doc[token.i - 2: token.i + 1]\n",
    "    elif doc[token.i - 2].text.lower() in compounds or doc[token.i - 3].lemma_.lower() in compounds:\n",
    "        trait = doc[token.i - 2: token.i + 1]\n",
    "    elif doc[token.i - 1].dep_ == 'compound':\n",
    "        trait = doc[token.i - 1: token.i + 1]\n",
    "    elif doc[token.i - 1].text.lower() in compounds or doc[token.i - 3].lemma_.lower() in compounds:\n",
    "        trait = doc[token.i - 1: token.i + 1]\n",
    "    else:\n",
    "        trait = token   \n",
    "    return trait.lemma_\n",
    "\n",
    "def check_existance(t, doc):\n",
    "    single = next((key for key, value in glossary.items() if t.lemma_.lower() in value), None)\n",
    "    multi = next((key for key, value in glossary.items() if t.text.lower() in value), None)\n",
    "    if single:\n",
    "        return single\n",
    "    elif multi:\n",
    "        return multi\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_advmod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'advmod':\n",
    "            return child\n",
    "        \n",
    "def extract_nummod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'nummod':\n",
    "            return child\n",
    "\n",
    "def extract_conjunction(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    if t.dep_ == 'conj' and t.pos_ == 'ADJ':\n",
    "        return t \n",
    "\n",
    "def extract_amod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'amod':\n",
    "            return child\n",
    "        \n",
    "def extract_measurements(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    obj = None\n",
    "    measurements = ['wide', 'long']\n",
    "    if t.text in measurements or t.lemma_ in measurements:\n",
    "        obj = doc[t.left_edge.i : t.right_edge.i + 1]\n",
    "    return obj\n",
    "\n",
    "def extract_prepositions(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'prep':\n",
    "            return doc[child.left_edge.i : child.right_edge.i + 1]\n",
    "\n",
    "def define_position(x, y, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    if len(x.text.split()) > 1:\n",
    "        return f'{y.text} {x.text}'\n",
    "    else:\n",
    "        try:\n",
    "            if x.i > y.i:\n",
    "                return doc[y.i : x.i + 1]\n",
    "            else:\n",
    "                return doc[x.i : y.i + 1]\n",
    "        except:\n",
    "            return f'{y.text} {x.text}'\n",
    "\n",
    "def extract_noun_verbs(t, doc):\n",
    "    relations = []\n",
    "    objects = []\n",
    "    if t.dep_ not in ['ROOT', 'nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "        return '', ''\n",
    "    parent = next((parent for parent in t.ancestors), None)\n",
    "    if parent and parent.pos_ == 'VERB':\n",
    "        prep = extract_verb_prep(parent, doc)\n",
    "        dobj = extract_verb_dobj(parent, doc)\n",
    "        oprd = extract_verb_orpd(parent, doc)\n",
    "        agnt = extract_verb_agnt(parent, doc)\n",
    "        nmod = extract_verb_nmod(parent, doc)\n",
    "        advm = extract_verb_advm(parent, doc)\n",
    "        print(advm)\n",
    "\n",
    "\n",
    "def extract_verb_advm(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'advmod':\n",
    "            return child\n",
    "\n",
    "def extract_verb_nmod(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'nummod':\n",
    "            return doc[child.left_edge.i : child.right_edge.i + 1] \n",
    "        \n",
    "def extract_verb_prep(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'prep':\n",
    "            return child    \n",
    "\n",
    "def extract_verb_pobj(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'pobj' or child.dep_ == 'pcomp' or child.dep_ == 'prep':\n",
    "            return child\n",
    "        \n",
    "def extract_verb_dobj(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'dobj':\n",
    "            return child\n",
    "        \n",
    "def extract_verb_orpd(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'oprd':\n",
    "            return child    \n",
    "        \n",
    "def extract_verb_agnt(t, doc):\n",
    "    \"\"\"HELPER\"\"\"\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'agent':\n",
    "            return child \n",
    "        \n",
    "def extract_nounandverb_nummods(t, doc):\n",
    "    obj = None\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'nummod':\n",
    "            obj = doc[child.left_edge.i : child.right_edge.i + 1]\n",
    "            return obj   \n",
    "\n",
    "def extract_dnummod(t, doc):\n",
    "    obj = extract_nounandverb_nummods(t, doc)\n",
    "    if obj:\n",
    "        return obj.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_noun_adjectives(t, doc):\n",
    "    adjs = []\n",
    "    adjectives = []\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'appos':\n",
    "            continue\n",
    "        if child.pos_ =='ADJ' or child.tag_ == 'VBN' and child.dep_ in ['conj', 'amod']:\n",
    "            \n",
    "            \n",
    "            advmod = extract_advmod(child, doc)\n",
    "            measurement = extract_measurements(child, doc)\n",
    "            prep = extract_prepositions(child, doc)\n",
    "            nummod = extract_nummod(child, doc)\n",
    "            amod = extract_amod(child, doc)\n",
    "           \n",
    "            \n",
    "            if child.lemma_.lower() in compounds:\n",
    "                continue\n",
    "            if child.text.lower() in compounds:\n",
    "                continue\n",
    "            elif amod:\n",
    "                obj = define_position(amod, child, doc)\n",
    "                adjs.append(obj)\n",
    "            elif advmod:\n",
    "                #obj = doc[advmod.i : child.i + 1]\n",
    "                obj = define_position(advmod, child, doc)\n",
    "                adjs.append(obj)\n",
    "            elif measurement:\n",
    "                obj = measurement\n",
    "                adjs.append(obj)\n",
    "            elif prep:\n",
    "                obj = define_position(prep, child, doc)\n",
    "                adjs.append(obj)\n",
    "            elif nummod:\n",
    "                obj = define_position(nummod, child, doc)\n",
    "                adjs.append(obj)                \n",
    "            else:\n",
    "                obj = child\n",
    "                adjs.append(obj)\n",
    "            for grandchild in child.subtree:\n",
    "                conj = extract_conjunction(grandchild, doc)\n",
    "                if conj:\n",
    "                    advmod = extract_advmod(conj, doc)\n",
    "                    prep = extract_prepositions(conj, doc)\n",
    "                    nummod = extract_nummod(conj, doc)\n",
    "                    if advmod:\n",
    "                        obj = define_position(advmod, conj, doc)\n",
    "                        adjs.append(obj)\n",
    "                    elif prep:\n",
    "                        obj = define_position(prep, conj, doc)\n",
    "                        adjs.append(obj)\n",
    "                    elif nummod:\n",
    "                        obj = define_position(nummod, conj, doc)\n",
    "                        adjs.append(obj)\n",
    "                    else:\n",
    "                        obj = conj\n",
    "                        adjs.append(obj)            \n",
    "    for adj in adjs:\n",
    "        try:\n",
    "            if adj.pos_ == 'VERB':\n",
    "                adj_text = adj.text.lower()\n",
    "            elif adj.root.pos_ == 'VERB':\n",
    "                adj_text = adj.text.lower()\n",
    "            else:\n",
    "                adj_text = adj.lemma_.lower()\n",
    "        except:\n",
    "                if type(adj) == str:\n",
    "                    adj_text = adj.lower()\n",
    "                else:\n",
    "                    adj_text = adj.text.lower()\n",
    "        for adj_split in adj_text.split(','):\n",
    "            adjectives.append(adj_split.strip())\n",
    "    return adjectives\n",
    "\n",
    "def extract_noun_appos(t, doc):\n",
    "    appos = []\n",
    "    for child in t.children:\n",
    "        if child.dep_ == 'appos':\n",
    "            obj = doc[child.left_edge.i : child.right_edge.i + 1].text.lower()\n",
    "            for obj_split in obj.split(','):\n",
    "                appos.append(obj_split.strip())\n",
    "    return appos\n",
    "\n",
    "def check_species(t, species, doc):\n",
    "    if t.text in species.split():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def extract_auxillary(t, doc):\n",
    "     parent = next((parent for parent in t.ancestors if parent.pos_ == 'AUX'), None)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e86b1640-58b5-423a-820b-ac2b5576a1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36c97d48eeb4d65b1d1763fee6dc09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gp/hp50s5114x52591qbdhn43xm0000gn/T/ipykernel_40725/1946546912.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0mtriples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;31m# NOUN VERBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mverbs_rel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbs_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_noun_verbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mrel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbs_rel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbs_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                         \u001b[0mtriples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "descriptions = collections.defaultdict(list)\n",
    "\n",
    "# For plotting purposes\n",
    "parts = []\n",
    "traits = []\n",
    "for species in tqdm_notebook(list(DATA.keys())[1:2]):\n",
    "    for idx, text in enumerate(DATA[species][1:2]):\n",
    "\n",
    "\n",
    "#for species in tqdm_notebook(COMMON_species[0:]):\n",
    "#for species in tqdm_notebook(list(descriptions_text.keys())):\n",
    "#    for idx, text in enumerate(TEST[species][0:]):\n",
    "        # Clean the text\n",
    "        text = re.sub(r'(?<!\\d)\\.(?!\\d)', ' ', text)\n",
    "        text = re.sub(r'\\s×\\s', ' times ', text)\n",
    "        text = f'{text.strip()}.'\n",
    "        # Reset variables\n",
    "        part=trait=rel=obj=adjectives = None \n",
    "        # NLP\n",
    "        doc = nlp(text)\n",
    "        # Init\n",
    "        descriptions[species, idx] = []\n",
    "        triples = []\n",
    "        # Loop over tokens\n",
    "        for t in doc:\n",
    "            if t.dep_ == 'compound':\n",
    "                continue\n",
    "            ### SUBJECTS ###    \n",
    "            if t.pos_ == 'NOUN' or t.pos_ == 'PROPN':\n",
    "                # Check existance of parts\n",
    "                part = check_existance(t, doc)\n",
    "                if part:\n",
    "                    # Reconstruct Compounds & Append\n",
    "                    trait = compound_reconstructor(t, doc)\n",
    "                    triples.append((species, 'has main part', part))\n",
    "                    triples.append((part, 'has sub part', trait))\n",
    "\n",
    "                    \n",
    "                    # Plotting\n",
    "                    #parts.append(part)\n",
    "                    #traits.append(trait)\n",
    "                    # NOUN ADJECTIVES\n",
    "                    adjectives = extract_noun_adjectives(t, doc)\n",
    "                    for adjective in adjectives:\n",
    "                        triples.append((trait, 'is', adjective))\n",
    "                    # NOUN VERBS\n",
    "                    verbs_rel, verbs_obj = extract_noun_verbs(t, doc)\n",
    "                    for rel, obj in zip(verbs_rel, verbs_obj):\n",
    "                        triples.append((trait, rel, obj))\n",
    "                    # NOUN APPOSITIONAL MODIFIER\n",
    "                    adjectives = extract_noun_appos(t, doc)\n",
    "                    for adjective in adjectives:\n",
    "                        triples.append((trait, 'is', adjective))\n",
    "                    # NOUN NUMMODS\n",
    "                    nummod = extract_dnummod(t, doc)\n",
    "                    triples.append((trait, 'is', nummod))\n",
    "                \n",
    "            #if check_species(t, species, doc):\n",
    "\n",
    "        # APPEND\n",
    "        descriptions[species, idx] = [triple for triple in triples if all(triple)]     \n",
    "        \n",
    "                    \n",
    "        #print(idx, doc)\n",
    "        print(descriptions[species, idx])\n",
    "        #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e2b4e37-841d-4dee-8a2f-8f8c24976e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_verbs_ROOT(t, doc):\n",
    "    relations = []\n",
    "    objects = []\n",
    "    if t.dep_ not in ['ROOT', 'nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "        return '', ''\n",
    "    parent = next((parent for parent in t.ancestors), None)\n",
    "    print(parent)\n",
    "    if parent and parent.pos_ == 'VERB':\n",
    "        prep = extract_verb_prep(parent, doc)\n",
    "        if prep: relations.append(f'{parent.text} {prep}'), objects.append(extract_verb_pobj(prep, doc).lemma_)\n",
    "        dobj = extract_verb_dobj(parent, doc)\n",
    "        if dobj: relations.append(parent.text), objects.append(extract_verb_pobj(prep, doc).lemma_)\n",
    "        oprd = extract_verb_orpd(parent, doc)\n",
    "        \n",
    "        agnt = extract_verb_agnt(parent, doc)\n",
    "        nmod = extract_verb_nmod(parent, doc)\n",
    "        advm = extract_verb_advm(parent, doc)\n",
    "        if advm: relations.append(parent), objects.append(advm)\n",
    "        if not any((prep, dobj, oprd, agnt, nmod, advm)): relations.append('are'), objects.append(parent)\n",
    "            \n",
    "    return relations, objects\n",
    "\n",
    "def extract_noun_verbs_NON_ROOT(t, doc):\n",
    "    relations = []\n",
    "    objects = []\n",
    "    if t.dep_ not in ['ROOT', 'nsubj', 'nsubjpass', 'csubj', 'csubjpass']:\n",
    "        return '', ''\n",
    "    # Double check\n",
    "    parent = next((parent for parent in t.ancestors), None)\n",
    "    if not parent:\n",
    "        for child in t.children:\n",
    "            if child.pos_ == 'VERB' and child.dep_ != 'amod':\n",
    "                prep = extract_verb_prep(child, doc)\n",
    "                if prep: \n",
    "                    noun = extract_verb_pobj(prep, doc)\n",
    "                    relations.append(f'{child.text} {prep}')\n",
    "                    objects.append(doc[noun.left_edge.i : noun.right_edge.i + 1].text)\n",
    "                dobj = extract_verb_dobj(child, doc)\n",
    "                if dobj:\n",
    "                    relations.append(child.text)\n",
    "                    objects.append(doc[dobj.left_edge.i : dobj.right_edge.i + 1].text) \n",
    "                oprd = extract_verb_orpd(child, doc)\n",
    "                if oprd:\n",
    "                    oprd_prep = extract_verb_preps(oprd, doc)\n",
    "                    relations.append(f'{child.text} {oprd.text}')\n",
    "                    objects.append(doc[oprd_prep.left_edge.i : oprd_prep.right_edge.i + 1].text)  \n",
    "                agnt = extract_verb_agnt(child, doc)\n",
    "                if agnt:\n",
    "                    print(33333)\n",
    "                nmod = extract_verb_nmod(child, doc)\n",
    "                if nmod:\n",
    "                    relations.append('is')\n",
    "                    objects.append(f'{nmod.text} {child}') \n",
    "                        \n",
    "    return relations, objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83b31d6b-5444-440d-8ef4-fe7c22e8078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_child_subtree(t, doc):\n",
    "    for child in t.children:\n",
    "        subtree_idx = [t.i for t in child.subtree]\n",
    "        print(subtree_idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "691a1a62-072c-4a6a-b068-3a193a14d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "extract_child_subtree(doc[7], doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9efd115-5695-4459-bfdd-86fa2e804ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comprising"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[10].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68d430d0-f9f8-459b-9cf1-20a6f5b88c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "11\n",
      "13\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t in doc[10].children:\n",
    "    \n",
    "    print(t.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af8c73ae-e937-49db-8af7-0705aa3ced2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_noun_verbs_ROOT(doc[0], doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c437438e-5b0d-4645-93ad-d2bc6e934bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['comprising'],\n",
       " ['2 subequal glumes without lemmas, linear, 2 mm long, shorter than fertile, separately deciduous'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_noun_verbs_NON_ROOT(doc[2], doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09ace1b6-1c2a-4f50-83df-30a1065bb1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"52700af4f5da43eaa03996a737975067-0\" class=\"displacy\" width=\"3550\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Companion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">sterile</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">spikelets</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">well-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">developed,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">comprising</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">2</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">subequal</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">glumes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">without</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">lemmas,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">linear,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">2</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">mm</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">long,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">shorter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">than</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">fertile,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">separately</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">deciduous.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-0\" stroke-width=\"2px\" d=\"M70,527.0 C70,352.0 380.0,352.0 380.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,529.0 L62,517.0 78,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-1\" stroke-width=\"2px\" d=\"M245,527.0 C245,439.5 375.0,439.5 375.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,529.0 L237,517.0 253,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-2\" stroke-width=\"2px\" d=\"M595,527.0 C595,439.5 725.0,439.5 725.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,529.0 L587,517.0 603,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-3\" stroke-width=\"2px\" d=\"M420,527.0 C420,352.0 730.0,352.0 730.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730.0,529.0 L738.0,517.0 722.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-4\" stroke-width=\"2px\" d=\"M420,527.0 C420,264.5 910.0,264.5 910.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,529.0 L918.0,517.0 902.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-5\" stroke-width=\"2px\" d=\"M1120,527.0 C1120,352.0 1430.0,352.0 1430.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,529.0 L1112,517.0 1128,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-6\" stroke-width=\"2px\" d=\"M1295,527.0 C1295,439.5 1425.0,439.5 1425.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,529.0 L1287,517.0 1303,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-7\" stroke-width=\"2px\" d=\"M945,527.0 C945,264.5 1435.0,264.5 1435.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,529.0 L1443.0,517.0 1427.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-8\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,439.5 1600.0,439.5 1600.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1600.0,529.0 L1608.0,517.0 1592.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-9\" stroke-width=\"2px\" d=\"M1645,527.0 C1645,439.5 1775.0,439.5 1775.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1775.0,529.0 L1783.0,517.0 1767.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-10\" stroke-width=\"2px\" d=\"M1995,527.0 C1995,89.5 3370.0,89.5 3370.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,529.0 L1987,517.0 2003,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-11\" stroke-width=\"2px\" d=\"M2170,527.0 C2170,439.5 2300.0,439.5 2300.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2170,529.0 L2162,517.0 2178,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-12\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,439.5 2475.0,439.5 2475.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,529.0 L2337,517.0 2353,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-13\" stroke-width=\"2px\" d=\"M1995,527.0 C1995,264.5 2485.0,264.5 2485.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2485.0,529.0 L2493.0,517.0 2477.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-14\" stroke-width=\"2px\" d=\"M2695,527.0 C2695,177.0 3365.0,177.0 3365.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,529.0 L2687,517.0 2703,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-15\" stroke-width=\"2px\" d=\"M2695,527.0 C2695,439.5 2825.0,439.5 2825.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2825.0,529.0 L2833.0,517.0 2817.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-16\" stroke-width=\"2px\" d=\"M2870,527.0 C2870,439.5 3000.0,439.5 3000.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3000.0,529.0 L3008.0,517.0 2992.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-17\" stroke-width=\"2px\" d=\"M3220,527.0 C3220,439.5 3350.0,439.5 3350.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3220,529.0 L3212,517.0 3228,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-52700af4f5da43eaa03996a737975067-0-18\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,2.0 3375.0,2.0 3375.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-52700af4f5da43eaa03996a737975067-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3375.0,529.0 L3383.0,517.0 3367.0,517.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7df41-bf96-46ec-a2ba-3dc81a459dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
