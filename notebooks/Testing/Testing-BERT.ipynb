{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b019440f-db73-42cc-a9c1-2afaea19c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from transformers import DistilBertModel, DistilBertConfig\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad6804b-0d4b-4dc9-b74f-15fc1a42866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"../data/processed/dataBOW.pkl\", \"rb\")\n",
    "data1 = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde36a57-a11a-4a99-8a20-fe880cb5c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"../data/processed/dataAZ_withMeasurements.pkl\", \"rb\")\n",
    "data2 = pickle.load(pickle_in)\n",
    "data = {**data1, **data2}          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ba09b4-c1e1-4507-8395-8ab1e76972a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1c5a59-0323-4fae-9277-503fd1cfa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undict data\n",
    "data = list(chain.from_iterable(data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba359bf4-82dc-4b14-87b2-9428f4c15b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14426"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b5d946-5cab-423b-97ea-df9cee73c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame using data\n",
    "df = pd.DataFrame(data, columns =['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efad22a-8c30-4b78-9b32-3f4f25837dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
    "                                                                    random_state=2021, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2021, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9344a06f-101a-40cd-adf7-7449eeb50be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b73a44-8ab8-4927-9f27-bcc50317f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1afeb3da-d7c2-4f5a-9549-2bd5030b1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 512,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 512,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 512,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f38bb7-4fc5-4f58-9fb4-4f839c4f9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436882b8-cdb8-4597-a6cd-5ca197dc4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 4\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff67859a-5eb0-4e9f-b388-f2c454e5ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9aed518-ab92-4f05-b16e-ef1dca05aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        \n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        #pass the inputs to the model BERT  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        \n",
    "        #pass the inputs to the model DistilBERT  \n",
    "        #cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        #cls_hs = cls_hs[0]\n",
    "        \n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f74c791-c47a-4e60-ad23-b8c10b1156b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dabbcb67-1fdd-43e6-a8b3-400e1af9cc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6841, -0.7022],\n",
       "        [-0.7082, -0.6784],\n",
       "        [-0.7223, -0.6649],\n",
       "        [-0.6908, -0.6955]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing, Deactivate dropout layer\n",
    "model.eval()\n",
    "# Push a dataset trough the mode\n",
    "BatchTest = next(iter(train_dataloader))\n",
    "\n",
    "# push the batch to gpu\n",
    "batch = [r.to(device) for r in BatchTest]\n",
    "sent_id, mask, labels = batch\n",
    "\n",
    "# Push the data trough the model\n",
    "preds = model(sent_id, mask)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23f73f27-4780-49c1-bf73-25ca44a872bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "612f111e-39b6-48b7-863f-ed2a2cf21501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)          # learning rate was -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e498c8b-6c0e-4dac-b025-668515f0d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.5671319  4.22401171]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17a83f7f-c77a-4b3d-8a3d-4f5c2b80c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6ec668c-6d1b-4fd9-942f-0af87d462716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 4 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "        # append the model predictions\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "634d749f-0548-412c-b046-936387edd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 4 == 0 and not step == 0:\n",
    "      \n",
    "            # Calculate elapsed time in minutes.\n",
    "            #elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52fc8dff-981e-4b48-b56c-2562d1efe4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 2\n",
      "  Batch     4  of  2,885.\n",
      "  Batch     8  of  2,885.\n",
      "  Batch    12  of  2,885.\n",
      "  Batch    16  of  2,885.\n",
      "  Batch    20  of  2,885.\n",
      "  Batch    24  of  2,885.\n",
      "  Batch    28  of  2,885.\n",
      "  Batch    32  of  2,885.\n",
      "  Batch    36  of  2,885.\n",
      "  Batch    40  of  2,885.\n",
      "  Batch    44  of  2,885.\n",
      "  Batch    48  of  2,885.\n",
      "  Batch    52  of  2,885.\n",
      "  Batch    56  of  2,885.\n",
      "  Batch    60  of  2,885.\n",
      "  Batch    64  of  2,885.\n",
      "  Batch    68  of  2,885.\n",
      "  Batch    72  of  2,885.\n",
      "  Batch    76  of  2,885.\n",
      "  Batch    80  of  2,885.\n",
      "  Batch    84  of  2,885.\n",
      "  Batch    88  of  2,885.\n",
      "  Batch    92  of  2,885.\n",
      "  Batch    96  of  2,885.\n",
      "  Batch   100  of  2,885.\n",
      "  Batch   104  of  2,885.\n",
      "  Batch   108  of  2,885.\n",
      "  Batch   112  of  2,885.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gp/hp50s5114x52591qbdhn43xm0000gn/T/ipykernel_51589/891059182.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gp/hp50s5114x52591qbdhn43xm0000gn/T/ipykernel_51589/317807313.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gp/hp50s5114x52591qbdhn43xm0000gn/T/ipykernel_51589/3396320251.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#pass the inputs to the model BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#pass the inputs to the model DistilBERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         )\n\u001b[0;32m--> 991\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    992\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1999\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/DL/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.6f}')\n",
    "    print(f'Validation Loss: {valid_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca429f-54be-40b7-a982-b6120c7a8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce1a1d-142b-40f7-9bc1-5d0ca6cbcaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea01358-dc6a-4c59-9124-efd08bf4d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test amount\n",
    "\n",
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq[0:50].to(device), test_mask[0:50].to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26147cf-03bb-485e-9fa6-4d03c06d8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y[0:50], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90de7375-d118-4ec1-affc-f63c390539cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
