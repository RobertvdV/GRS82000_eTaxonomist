{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b16434b-0b56-4d3e-aed0-f819fe949ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Success\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import random\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import urllib.parse\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.util import filter_spans\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src/models/')\n",
    "sys.path.insert(0, '../src/features/')\n",
    "#sys.path.insert(0, '../src/visualization/')\n",
    "\n",
    "import predict_model\n",
    "#import visualize as vis\n",
    "\n",
    "model = predict_model.loadBERT(\"../models/\", 'saved_weights_inf_FIXED.pt')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "335bc5bc-270f-4eed-9394-066e8c58d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_Duck(query):\n",
    "    \n",
    "    \"\"\"\n",
    "    Queries DuckDuckGo and returns a URL list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get results \n",
    "    page = requests.get('https://duckduckgo.com/html/?q={0}'.format(query), \n",
    "                        headers={'user-agent': 'Descriptor/0.0.1'})\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.find_all('a', attrs={'class':'result__a'}, href=True)\n",
    "    # Init list\n",
    "    links = []\n",
    "    # Clean results\n",
    "    for link in results:\n",
    "        url = link['href']\n",
    "        o = urllib.parse.urlparse(url)\n",
    "        d = urllib.parse.parse_qs(o.query)\n",
    "        links.append(d['uddg'][0])\n",
    "    return links\n",
    "\n",
    "def search_Bing(query):\n",
    "    \n",
    "    \"\"\"\n",
    "    Queries Bing and returns a URL list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get results\n",
    "    page = requests.get('https://www.bing.com/search?form=MOZLBR&pc=MOZI&q={0}'.format(query), \n",
    "                        headers={'user-agent': 'Descriptor/0.0.1'})\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Init list\n",
    "    links = [] \n",
    "    # Clean results\n",
    "    for i in soup.find_all('a', attrs={'h':re.compile('ID=SERP.+')}, href=True):\n",
    "        link = i['href']\n",
    "        if link.startswith('http') and 'microsoft' not in link and 'bing' not in link:\n",
    "            links.append(link)        \n",
    "    return links\n",
    "\n",
    "def SpanPredictor(span, pred_values=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Uses a trained bert classifier to see if a span\n",
    "    belongs to a species description or otherwise.\n",
    "    \"\"\"\n",
    "         \n",
    "    with torch.no_grad():\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer(span, return_tensors=\"pt\", truncation=True)\n",
    "        # Predict class\n",
    "        outputs = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "        # Get prediction values\n",
    "        exps = torch.exp(outputs)\n",
    "        # Get class\n",
    "        span_class = exps.argmax(1).item()\n",
    "\n",
    "        # Print the prediction values\n",
    "        if pred_values:\n",
    "            return span_class, exps[0]\n",
    "        else:\n",
    "            return span_class\n",
    "        \n",
    "def text_cleaner(soup, per_sent=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans the contents of a bs4 object and uses SpaCy to return single sentences.\n",
    "    \"\"\"    \n",
    "    \n",
    "    regexes = [\n",
    "        (r'\\(\\d+.+?Close\\n\\t\\n\\)', ''),\n",
    "        (r'\\(.+?\\)', ''),\n",
    "        (r'\\[.+?\\]', ''),\n",
    "        (r'cm\\.', 'centimeters'),\n",
    "        (r'm\\.', 'meters'),\n",
    "        (r'ft\\.', 'feet'),\n",
    "        (r'\\.\\.\\.', '.'),\n",
    "        (r'\\.\\s*\\.', '.'),\n",
    "    ]\n",
    "\n",
    "    # Get text\n",
    "    dirty_text = soup.get_text(\". \", strip=True)\n",
    "    # Clean text\n",
    "    # Clean text\n",
    "    for regex, replace in regexes:\n",
    "        dirty_text = re.sub(regex, replace, dirty_text)\n",
    "    # Clean stuff\n",
    "    text = dirty_text.replace('\\r', \"\")\\\n",
    "                 .replace('\\n', \"\")\\\n",
    "                 .replace('\\t', \"\")\\\n",
    "                 .strip()\n",
    "                 #.encode(\"ascii\", \"ignore\")\\\n",
    "                 #.decode()\\\n",
    "    \n",
    "    #nlp\n",
    "    doc = nlp(text)\n",
    "    sents = [i for i in doc.sents]\n",
    "    \n",
    "    sents_clean = []\n",
    "    # Clean non English\n",
    "    for sentence in sents:\n",
    "        # Skip short stuff\n",
    "        if len(sentence) <= 5:\n",
    "            continue\n",
    "        # Create ratio\n",
    "        non_eng = [token.is_oov for token in sentence].count(True)\n",
    "        # Continue if the ratio is bad (non English jibberisch)\n",
    "        if non_eng != 0:\n",
    "            if non_eng / len(doc) > .2:\n",
    "                continue\n",
    "        sents_clean.append(sentence)\n",
    "    \n",
    "    sents_clean = list(set(sents_clean))\n",
    "    \n",
    "    if per_sent:\n",
    "        return sents_clean\n",
    "    else:\n",
    "        return doc\n",
    "\n",
    "def VisualizeDoc(text, per_sentence=False, save=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates and HTML file (can be rendered in a notebook) by using the SpaCy \n",
    "    Displacy.\n",
    "    \n",
    "    per_sentence : Returns the visualization per sentence instead of a whole doc.\n",
    "    save         : If True returns the html string to save.\n",
    "    \"\"\"\n",
    "    \n",
    "    # nlp the text\n",
    "    doc = nlp(text)\n",
    "    # Extract the sents\n",
    "    sentences = [i for i in doc.sents]\n",
    "    # Init color map\n",
    "    cmap = cm.get_cmap('Spectral')\n",
    "    # Init color dict\n",
    "    colors = {}\n",
    "    # Init option dict\n",
    "    options = {\"ents\": [],\n",
    "               \"colors\": colors,\n",
    "               \"distance\": 75}\n",
    "    # Init matcher\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    # Loop over the sentences\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        \n",
    "        # Get the prediction values    \n",
    "        prediction = SpanPredictor(str(sentence), pred_values=True)[1][1].numpy().item()\n",
    "        \n",
    "        # String ID            \n",
    "        #text = '#{0} - {1:.2f}'.format(idx, prediction)\n",
    "        text = f'{prediction:.3f}'\n",
    "        # Add the patterns        \n",
    "        pattern = nlp(str(sentence))\n",
    "        matcher.add(text, None, pattern)\n",
    "\n",
    "        # Colorize the strings\n",
    "        if prediction > .5:\n",
    "            colors[text] = matplotlib.colors.rgb2hex(cmap(prediction))\n",
    "        else:\n",
    "            colors[text] = matplotlib.colors.rgb2hex(cmap(prediction)) + '60'\n",
    "        # Add the new ENTS to the doc\n",
    "        options[\"ents\"].append(text)\n",
    "\n",
    "    # Match the enitities in the doc\n",
    "    matches = matcher(doc)\n",
    "    # Reset the current ENTS\n",
    "    doc.ents = ()\n",
    "    # Loop over the matches\n",
    "    for match_id, start, end in matches:\n",
    "        # Add the sentencen as a ENT\n",
    "        span = Span(doc, start, end, label=match_id)\n",
    "        #doc.ents = filter_spans(doc.ents)\n",
    "        try:\n",
    "            doc.ents = list(doc.ents) + [span]\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    # Set title\n",
    "    #doc.user_data[\"title\"] = \"Description Predictor\"\n",
    "    sentence_spans = list(doc.sents)\n",
    "    \n",
    "    if save and per_sentence:\n",
    "        return displacy.render(sentence_spans, style='ent', options=options)\n",
    "    elif save and not per_sentence:\n",
    "        return displacy.render(doc, style='ent', options=options)\n",
    "    elif not save and per_sentence:\n",
    "        displacy.render(sentence_spans, style='ent', options=options)\n",
    "    elif not save and not per_sentence:\n",
    "        displacy.render(doc, style='ent', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6de9f95-b9d8-43cb-bd11-3fbe568f4d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists\n",
    "plants_dict = pickle.load(open('../data/processed/train_dataPOWO.pkl', 'rb'))\n",
    "birds_dict = pickle.load(open('../data/processed/descriptions_web_birds_bow.pkl', 'rb'))\n",
    "\n",
    "plants_list = [keys for keys, values in plants_dict.items()]\n",
    "birds_list = [keys for keys, values in birds_dict.items()]\n",
    "\n",
    "plants_list_r = random.sample(plants_list, len(birds_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e6eb56-80b3-4287-98dd-d6f1f335358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = plants_list_r + birds_list\n",
    "random.shuffle(species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5592e314-5193-43a3-8472-dce7f82c36ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17872"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf881be9-fcd7-49dd-b171-7ecf6c7082f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [02:08<00:00, 64.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Init dict\n",
    "data = collections.defaultdict(list)\n",
    "# Init dict\n",
    "\n",
    "# DEBUGGING\n",
    "data_link = collections.defaultdict(list)\n",
    "data_with_source = collections.defaultdict(list)\n",
    "\n",
    "query = 'description'\n",
    "\n",
    "for count, species in enumerate(tqdm(species_list[0:2])):\n",
    "    \n",
    "    # Empty list\n",
    "    search_links = []\n",
    "    # create q\n",
    "    species_q = species.replace(' ', '+')\n",
    "    species_q = '\"{0}\"+{1}'.format(species_q, query)\n",
    "    # species_q = f'\"{species_q}\"+{query}'\n",
    "    \n",
    "    search_links += search_Duck(species_q)\n",
    "    search_links += search_Bing(species_q)\n",
    "\n",
    "    # Drop duplicates\n",
    "    search_links = list(set(search_links))\n",
    "    # DEBUGGING\n",
    "    data_link[species] += search_links\n",
    "    \n",
    "    # Loop over the URLs\n",
    "    for URL in search_links:\n",
    "        # Skip google archives\n",
    "        if 'google' in URL:\n",
    "            continue\n",
    "        # PDF and TXT\n",
    "        if URL.endswith('txt') or URL.endswith('pdf'):\n",
    "            \n",
    "            \"\"\"\n",
    "            Continue for now, insert the pdf processor here\n",
    "            \"\"\"\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            #print(URL)\n",
    "            page = requests.get(URL, timeout=5)\n",
    "            # Skip PDF files for now\n",
    "            if page.headers['Content-Type'].startswith('application/pdf'):\n",
    "                \n",
    "                \"\"\"\n",
    "                Continue for now, insert the pdf processor here\n",
    "                \"\"\"\n",
    "                continue\n",
    "                \n",
    "            # Soup the result\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            # Skip Embedded PDF's\n",
    "            if 'pdf' in soup.title.text.lower():\n",
    "                continue\n",
    "\n",
    "            # Clean the soup and break into sents\n",
    "            sentences = text_cleaner(soup)\n",
    "            # Loop over the individual sentences\n",
    "            for sentence in sentences:                    \n",
    "                # Create string object\n",
    "                sentence_str = str(sentence)\n",
    "                \n",
    "                if SpanPredictor(sentence_str):\n",
    "                    #print(URL)\n",
    "                    data[species].append(sentence_str)\n",
    "                    data_with_source[species].append(tuple([sentence_str, URL]))\n",
    "        except: \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93e60930-4619-490d-a8ae-85f95881ca82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Oriolus flavocinctus', 'Sicalis citrina'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4e14469-4607-4278-92b3-17a7513da7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Orange fronted Yellow finch Sicalis columbiana regnum =',\n",
       "  'https://es-academic.com/dic.nsf/eswiki/1086796'),\n",
       " ('Animalia phylum = Chordata classis =',\n",
       "  'https://es-academic.com/dic.nsf/eswiki/1086796'),\n",
       " ('Animalia phylum = Chordata classis =',\n",
       "  'https://es-academic.com/dic.nsf/eswiki/1086796'),\n",
       " ('Sicalis. — flaveola ….', 'https://es-academic.com/dic.nsf/eswiki/1086796'),\n",
       " ('– cordés, cordado, chordates.',\n",
       "  'https://itis.gov/servlet/SingleRpt/SingleRpt?search_topic=TSN&search_value=562993'),\n",
       " ('Golden Bellied Sicalis Lemon Sicalis Dwarf Sicalis Saffron sicalis , or saffron finchPatagonian Sicalis Yellow Sicalis Yellow-headed Sicalis Short-billed Sicalis Olive',\n",
       "  'https://www.wikipe.wiki/wiki/ru/Sicalis'),\n",
       " ('yellow, citrine \\xa0< L. citrus.',\n",
       "  'https://birdsoftheworld.org/bow/species/styfin1/cur/introduction'),\n",
       " ('Black-spotted Bare-eye .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Brown-rumped Foliage-gleaner .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('The female has white webbing only near the tips.',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Reddish-winged Bare-eye .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Bright-rumped Yellow-Finch .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Rusty-crowned Tit-Spinetail .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Red-and-white Spinetail .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Chestnut-crowned Foliage-gleaner .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Gray-cowled Wood-Rail .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Red-and-white Antpitta .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Rufous-rumped Foliage-gleaner .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Gray-and-white Tyrannulet .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Many-colored Rush Tyrant .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('The male has a white inner tail webbing on the outer tail feathers.',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('L. citrus, citron= citrinus, yellow, citrine.',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('The upperparts are yellowish with dusky mottles and streaks.',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Bronze-olive Pygmy-Tyrant .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Plain-mantled Tit-Spinetail .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Buff-browed Foliage-gleaner .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('Marble-faced Bristle-Tyrant .',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('The male Stripe-tailed Yellow-finch has yellow head breast and underparts.',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('The female is similar but has dusky streaks on the underparts and head.',\n",
       "  'https://www.peruaves.org/thraupidae/stripe-tailed-yellow-finch-sicalis-citrina/'),\n",
       " ('— Bright-rumped Yellow-Finch.',\n",
       "  'https://slovar-vocab.com/english/ornitho-birds-vocab/sicalis-citrina-6204224.html'),\n",
       " ('— bright-rumped yellow-finch.',\n",
       "  'https://slovar-vocab.com/english/ornitho-birds-vocab/sicalis-citrina-6204224.html'),\n",
       " ('— a wood warbler, Wilsonia citrina, of the U.S., olive-green above, yellow below, and having a black head and throat with ….',\n",
       "  'https://slovar-vocab.com/english/ornitho-birds-vocab/sicalis-citrina-6204224.html'),\n",
       " ('— Greenish Yellow-Finch.',\n",
       "  'https://slovar-vocab.com/english/ornitho-birds-vocab/sicalis-citrina-6204224.html'),\n",
       " ('— greenish yellow-finch.',\n",
       "  'https://slovar-vocab.com/english/ornitho-birds-vocab/sicalis-citrina-6204224.html'),\n",
       " ('Orange fronted Yellow finch Sicalis columbiana regnum =',\n",
       "  'https://translate.academic.ru/Sicalis%20citrina/la/ru/'),\n",
       " ('Sicalis. — flaveola ….',\n",
       "  'https://translate.academic.ru/Sicalis%20citrina/la/ru/'),\n",
       " ('Animalia phylum = Chordata classis =',\n",
       "  'https://translate.academic.ru/Sicalis%20citrina/la/ru/'),\n",
       " ('Animalia phylum = Chordata classis =',\n",
       "  'https://translate.academic.ru/Sicalis%20citrina/la/ru/')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_source['Sicalis citrina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5826c3ef-44cf-4013-817c-370d36a3a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_with_source[species]\n",
    "#data_link[species]\n",
    "print(len(data_with_source['Spatula querquedula']))\n",
    "_ = list(set(data_with_source['Spatula querquedula']))\n",
    "print(len(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a570a79-ad33-45e7-ac6e-3e00ae93550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://db.worldagroforestry.org//species/properties/Enterolobium_cyclocarpum' \n",
    "#URL = 'http://powo.science.kew.org/taxon/757855-1'\n",
    "#URL = 'https://birdsoftheworld.org/bow/species/gargan/cur/introduction'\n",
    "page = requests.get(URL, timeout=5)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "text = str(text_cleaner(soup, per_sent=False))\n",
    "VisualizeDoc(text, per_sentence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b04288-c7ad-4620-8f20-4bdabb3f363e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2b2f8-07de-406c-a8f8-3748026ce58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708de31-0c31-4ca9-bd61-84878bcde8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL]",
   "language": "python",
   "name": "conda-env-DL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
