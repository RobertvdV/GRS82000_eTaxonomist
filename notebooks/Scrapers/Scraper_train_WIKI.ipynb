{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7433918c-9e5b-4055-8d8d-5b7258af2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "from itertools import chain\n",
    "import collections\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d4bbcad-10ff-438b-9dcd-cd5b584972e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "URLs = ['https://en.wikipedia.org/wiki/List_of_animal_names',\n",
    "      'https://en.wikipedia.org/wiki/List_of_fish_common_names',\n",
    "      'https://en.wikipedia.org/wiki/List_of_trees_and_shrubs_by_taxonomic_family',\n",
    "      'https://en.wikipedia.org/wiki/List_of_birds_by_common_name']\n",
    "\n",
    "WikiLinks = []\n",
    "\n",
    "for URL in tqdm(URLs):\n",
    "\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Find all wikiparts\n",
    "    WikiRefs = soup.find_all('a')\n",
    "    # Create links \n",
    "    WikiLinks = ['https://en.wikipedia.org' + pages.get('href') for pages in WikiRefs \n",
    "                           if pages.get('href') != None \n",
    "                           if pages.get('href').startswith('/wiki/')]\n",
    "            \n",
    "# Remove duplicates            \n",
    "WikiLinks = list(set(WikiLinks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a736bd-3891-4b99-81c6-ff049e792172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11005/11005 [1:16:14<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "127985"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiSubLinks = []\n",
    "\n",
    "for WikiLink in tqdm(WikiLinks):\n",
    "\n",
    "    URL = WikiLink\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Find all wikiparts\n",
    "    WikiRefs = soup.find_all('a')\n",
    "    # Create links \n",
    "    WikiSubLinks += ['https://en.wikipedia.org' + pages.get('href') for pages in WikiRefs \n",
    "                           if pages.get('href') != None \n",
    "                           if pages.get('href').startswith('/wiki/')]\n",
    "\n",
    "# Drop doubles\n",
    "WikiSubLinks = list(set(WikiSubLinks))\n",
    "\n",
    "WikiSubLinks += WikiLinks\n",
    "# Remove duplicates            \n",
    "WikiSubLinks = list(set(WikiSubLinks))\n",
    "\n",
    "\n",
    "with open('../data/processed/intermediate_wiki_links.pkl', 'wb') as f:\n",
    "    pickle.dump(WikiLinks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45c46bab-bd9b-4329-ab39-c8927bad2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127985/127985 [11:33:52<00:00,  3.07it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Init Dict\n",
    "Data = collections.defaultdict(list)\n",
    "\n",
    "# Known chapter titles\n",
    "KnownDescriptionList = ['Physical characteristics', 'Description and morphology',\n",
    "                        'Description', 'General description',\n",
    "                        'Appearance',\n",
    "                        'Characteristics']\n",
    "\n",
    "# Lower them\n",
    "KnownDescriptionListLower =[i.lower() for i in KnownDescriptionList]\n",
    "\n",
    "# Removes references in text\n",
    "ReferenceRemover = '\\[\\d*\\]'\n",
    "\n",
    "for WikiLink in tqdm(WikiSubLinks):\n",
    "    \n",
    "    URL = WikiLink\n",
    "\n",
    "    try:\n",
    "        Response = requests.get(URL, timeout=5)\n",
    "        Soup = BeautifulSoup(Response.content, \"html.parser\")\n",
    "\n",
    "        # Check if the link contains description data\n",
    "        Contents = [i.text.replace('[edit]', '') for i in Soup.find_all('h2')]\n",
    "        if all(s not in Contents for s in KnownDescriptionList) == False:\n",
    "\n",
    "            # Find Chapters\n",
    "            for Tag in Soup.find_all('h2')[1:]:\n",
    "\n",
    "\n",
    "                # Get species name\n",
    "                Species = Soup.title.string\\\n",
    "                                    .split(' - ')[0]\\\n",
    "                                    .rstrip(' ')\n",
    "\n",
    "                # Clean Chapter\n",
    "                Chapter = Tag.text.strip().replace('[edit]', '')\n",
    "\n",
    "                # Find all Text\n",
    "                for Item in Tag.find_next_siblings('p'):\n",
    "                    # Check if Chapter is Description or similar\n",
    "                    if Chapter.lower() in KnownDescriptionListLower:\n",
    "                        # Check if text belongs to current chapter\n",
    "                        if Chapter in Item.find_previous_siblings('h2')[0].text.strip():\n",
    "                            # Clean Text\n",
    "                            CleanText = re.sub(ReferenceRemover, '', Item.text)\n",
    "                            # Add to dict\n",
    "                            Data[Species].append(tuple([1, CleanText]))\n",
    "\n",
    "                    else:\n",
    "                        # Check if text belongs to current chapter\n",
    "                        if Chapter in Item.find_previous_siblings('h2')[0].text.strip():\n",
    "                            # Clean Text\n",
    "                            CleanText = re.sub(ReferenceRemover, '', Item.text)\n",
    "                            # Add to dict\n",
    "                            Data[Species].append(tuple([0, CleanText]))\n",
    "        \n",
    "        # Non species part\n",
    "        else:\n",
    "            try:\n",
    "                # Find Chapters\n",
    "                for Tag in Soup.find_all('h2')[1:]:\n",
    "                    # Clean Chapter\n",
    "                    Chapter = Tag.text.strip().replace('[edit]', '')\n",
    "                    # Find all Text\n",
    "                    for Item in Tag.find_next_siblings('p'):\n",
    "                        # Check if text belongs to current chapter\n",
    "                        if Chapter in Item.find_previous_siblings('h2')[0].text.strip():\n",
    "                            #print(Chapter)\n",
    "                            # Clean Text\n",
    "                            CleanText = re.sub(ReferenceRemover, '', Item.text)\n",
    "                            # Add to dict\n",
    "                            Data['no_data'].append(tuple([0, CleanText]))\n",
    "            # Continue on wrong links                \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    except:\n",
    "        # Continue if timeout\n",
    "        continue\n",
    "\n",
    "with open('../data/processed/train_dataWIKI_all.pkl', 'wb') as f:\n",
    "    pickle.dump(Data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1d2315-a199-4888-91b9-12a449601492",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/List_of_animal_names'\n",
    "Response = requests.get(URL, timeout=5)\n",
    "Soup = BeautifulSoup(Response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027fb2cc-3bc0-44b5-b6d1-cc8b3910f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>In the English language, animals have different names depending on whether they are <a href=\"/wiki/Male\" title=\"Male\">male</a>, <a href=\"/wiki/Female\" title=\"Female\">female</a>, young, domesticated, or in groups.\n",
       " </p>,\n",
       " <p>The best-known source of many English words used for collective groupings of animals is <i><a class=\"mw-redirect\" href=\"/wiki/Book_of_St._Albans\" title=\"Book of St. Albans\">The Book of Saint Albans</a></i>, an essay on hunting published in 1486 and attributed to <a href=\"/wiki/Juliana_Berners\" title=\"Juliana Berners\">Juliana Berners</a>.<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup> Most terms used here may be found in common dictionaries and general information web sites.<sup class=\"reference\" id=\"cite_ref-oxfordfaq_2-0\"><a href=\"#cite_note-oxfordfaq-2\">[2]</a></sup><sup class=\"reference\" id=\"cite_ref-dictcom_3-0\"><a href=\"#cite_note-dictcom-3\">[3]</a></sup><sup class=\"reference\" id=\"cite_ref-merriamweb_4-0\"><a href=\"#cite_note-merriamweb-4\">[4]</a></sup>\n",
       " </p>,\n",
       " <p>The terms in this table apply to many or all <a class=\"mw-redirect\" href=\"/wiki/Taxa\" title=\"Taxa\">taxa</a> in a particular <a href=\"/wiki/Family_(biology)\" title=\"Family (biology)\">biological family</a>, <a href=\"/wiki/Class_(biology)\" title=\"Class (biology)\">class</a>, or <a href=\"/wiki/Clade\" title=\"Clade\">clade</a>.\n",
       " </p>,\n",
       " <p>cackle<sup class=\"reference\" id=\"cite_ref-sdzoo_11-68\"><a href=\"#cite_note-sdzoo-11\">[11]</a></sup><sup class=\"reference\" id=\"cite_ref-usgs_14-39\"><a href=\"#cite_note-usgs-14\">[14]</a></sup><br/>clan\n",
       " </p>,\n",
       " <p>yoyo\n",
       " </p>,\n",
       " <p><i><a href=\"/wiki/Merriam-Webster\" title=\"Merriam-Webster\">Merriam-Webster</a></i> writes that most terms of venery fell out of use in the 16th century, including a \"murder\" for crows. It goes on to say that some of the terms in <i><a class=\"mw-redirect\" href=\"/wiki/The_Book_of_Saint_Albans\" title=\"The Book of Saint Albans\">The Book of Saint Albans</a></i> were \"rather fanciful\", explaining that the book extended collective nouns to people of specific professions, such as a \"poverty\" of pipers. It concludes that for <a class=\"mw-redirect\" href=\"/wiki/Lexicographer\" title=\"Lexicographer\">lexicographers</a>, many of these don't satisfy criteria for entry by being \"used consistently in running prose\" without meriting explanation. Some terms that were listed as commonly used were \"herd\", \"flock\", \"school\", and \"swarm\".<sup class=\"reference\" id=\"cite_ref-122\"><a href=\"#cite_note-122\">[113]</a></sup>\n",
       " </p>,\n",
       " <p>Writing for <i><a class=\"mw-redirect\" href=\"/wiki/National_Audubon_Society\" title=\"National Audubon Society\">Audubon</a></i>, Nicholas Lund says that many such terms are not used in actuality. When he interviewed several scientists who specialize in studying specific animals, they had not heard of these terms, such as a \"bask\" of crocodiles or \"wisdom\" of wombats, being applied in their fields. Lund noted that the common plural noun for all kinds of birds was \"flock\" (as opposed to terms such as \"parliament\" of owls or \"murder\" of crows), conceding that a few specialized terms were in current use for certain animals that form groups, such as a \"pod\" of whales or \"gaggle\" of geese.<sup class=\"reference\" id=\"cite_ref-123\"><a href=\"#cite_note-123\">[114]</a></sup>\n",
       " </p>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c180cc-962b-4cc6-9565-de29f1558be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:eTaxonomist]",
   "language": "python",
   "name": "conda-env-eTaxonomist-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
