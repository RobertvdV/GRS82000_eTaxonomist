
@article{reimers_sentence-bert_2019,
	title = {Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks},
	url = {http://arxiv.org/abs/1908.10084},
	shorttitle = {Sentence-{BERT}},
	abstract = {{BERT} (Devlin et al., 2018) and {RoBERTa} (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity ({STS}). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with {BERT}. The construction of {BERT} makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-{BERT} ({SBERT}), a modification of the pretrained {BERT} network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with {BERT} / {RoBERTa} to about 5 seconds with {SBERT}, while maintaining the accuracy from {BERT}. We evaluate {SBERT} and {SRoBERTa} on common {STS} tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
	journaltitle = {{arXiv}:1908.10084 [cs]},
	author = {Reimers, Nils and Gurevych, Iryna},
	urldate = {2021-09-28},
	date = {2019-08-27},
	eprinttype = {arxiv},
	eprint = {1908.10084},
	keywords = {Computer Science - Computation and Language},
}

@article{schmidhuber_deep_2015,
	title = {Deep Learning in Neural Networks: An Overview},
	volume = {61},
	issn = {08936080},
	url = {http://arxiv.org/abs/1404.7828},
	doi = {10.1016/j.neunet.2014.09.003},
	shorttitle = {Deep Learning in Neural Networks},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	pages = {85--117},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Schmidhuber, Juergen},
	urldate = {2021-09-27},
	date = {2015-01},
	eprinttype = {arxiv},
	eprint = {1404.7828},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{marcos_semantically_2019,
	title = {Semantically Interpretable Activation Maps: what-where-how explanations within {CNNs}},
	url = {http://arxiv.org/abs/1909.08442},
	shorttitle = {Semantically Interpretable Activation Maps},
	abstract = {A main issue preventing the use of Convolutional Neural Networks ({CNN}) in end user applications is the low level of transparency in the decision process. Previous work on {CNN} interpretability has mostly focused either on localizing the regions of the image that contribute to the result or on building an external model that generates plausible explanations. However, the former does not provide any semantic information and the latter does not guarantee the faithfulness of the explanation. We propose an intermediate representation composed of multiple Semantically Interpretable Activation Maps ({SIAM}) indicating the presence of predefined attributes at different locations of the image. These attribute maps are then linearly combined to produce the final output. This gives the user insight into what the model has seen, where, and a final output directly linked to this information in a comprehensive and interpretable way. We test the method on the task of landscape scenicness (aesthetic value) estimation, using an intermediate representation of 33 attributes from the {SUN} Attributes database. The results confirm that {SIAM} makes it possible to understand what attributes in the image are contributing to the final score and where they are located. Since it is based on learning from multiple tasks and datasets, {SIAM} improve the explanability of the prediction without additional annotation efforts or computational overhead at inference time, while keeping good performances on both the final and intermediate tasks.},
	journaltitle = {{arXiv}:1909.08442 [cs]},
	author = {Marcos, Diego and Lobry, Sylvain and Tuia, Devis},
	urldate = {2021-09-27},
	date = {2019-09-18},
	eprinttype = {arxiv},
	eprint = {1909.08442},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{hoffer_deep_2015,
	location = {Cham},
	title = {Deep Metric Learning Using Triplet Network},
	isbn = {978-3-319-24261-3},
	doi = {10.1007/978-3-319-24261-3_7},
	series = {Lecture Notes in Computer Science},
	abstract = {Deep learning has proven itself as a successful set of models for learning useful semantic representations of data. These, however, are mostly implicitly learned as part of a classification task. In this paper we propose the triplet network model, which aims to learn useful representations by distance comparisons. A similar model was defined by Wang et al. (2014), tailor made for learning a ranking for image information retrieval. Here we demonstrate using various datasets that our model learns a better representation than that of its immediate competitor, the Siamese network. We also discuss future possible usage as a framework for unsupervised learning.},
	pages = {84--92},
	booktitle = {Similarity-Based Pattern Recognition},
	publisher = {Springer International Publishing},
	author = {Hoffer, Elad and Ailon, Nir},
	editor = {Feragen, Aasa and Pelillo, Marcello and Loog, Marco},
	date = {2015},
	langid = {english},
	keywords = {Deep learning, Metric learning, Representation learning},
}

@software{honnibal_spacy_2020,
	title = {{spaCy}: Industrial-strength Natural Language Processing in Python},
	url = {https://doi.org/10.5281/zenodo.1212303},
	publisher = {Zenodo},
	author = {Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane},
	date = {2020},
	doi = {10.5281/zenodo.1212303},
}

@inproceedings{van_horn_inaturalist_2018,
	location = {Salt Lake City, {UT}},
	title = {The {iNaturalist} Species Classification and Detection Dataset},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8579012/},
	doi = {10.1109/CVPR.2018.00914},
	abstract = {Existing image classiﬁcation datasets used in computer vision tend to have a uniform distribution of images across object categories. In contrast, the natural world is heavily imbalanced, as some species are more abundant and easier to photograph than others. To encourage further progress in challenging real world conditions we present the {iNaturalist} species classiﬁcation and detection dataset, consisting of 859,000 images from over 5,000 different species of plants and animals. It features visually similar species, captured in a wide variety of situations, from all over the world. Images were collected with different camera types, have varying image quality, feature a large class imbalance, and have been veriﬁed by multiple citizen scientists. We discuss the collection of the dataset and present extensive baseline experiments using state-of-the-art computer vision classiﬁcation and detection models. Results show that current nonensemble based methods achieve only 67\% top one classiﬁcation accuracy, illustrating the difﬁculty of the dataset. Speciﬁcally, we observe poor results for classes with small numbers of training examples suggesting more attention is needed in low-shot learning.},
	eventtitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {8769--8778},
	booktitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	publisher = {{IEEE}},
	author = {Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
	urldate = {2021-09-24},
	date = {2018-06},
	langid = {english},
}

@inproceedings{bucher_semantic_2019,
	location = {Cham},
	title = {Semantic Bottleneck for Computer Vision Tasks},
	isbn = {978-3-030-20890-5},
	doi = {10.1007/978-3-030-20890-5_44},
	series = {Lecture Notes in Computer Science},
	abstract = {This paper introduces a novel method for the representation of images that is semantic by nature, addressing the question of computation intelligibility in computer vision tasks. More specifically, our proposition is to introduce what we call a semantic bottleneck in the processing pipeline, which is a crossing point in which the representation of the image is entirely expressed with natural language, while retaining the efficiency of numerical representations. We show that our approach is able to generate semantic representations that give state-of-the-art results on semantic content-based image retrieval and also perform very well on image classification tasks. Intelligibility is evaluated through user centered experiments for failure detection.},
	pages = {695--712},
	booktitle = {Computer Vision – {ACCV} 2018},
	publisher = {Springer International Publishing},
	author = {Bucher, Maxime and Herbin, Stéphane and Jurie, Frédéric},
	editor = {Jawahar, C. V. and Li, Hongdong and Mori, Greg and Schindler, Konrad},
	date = {2019},
	langid = {english},
}

@article{selvaraju_grad-cam_2017,
	title = {Grad-{CAM}: Visual Explanations From Deep Networks via Gradient-Based Localization},
	abstract = {We propose a technique for producing ‘visual explanations’ for decisions from a large class of Convolutional Neural Network ({CNN})-based models, making them more transparent. Our approach – Gradient-weighted Class Activation Mapping (Grad-{CAM}), uses the gradients of any target concept (say logits for ‘dog’ or even a caption), ﬂowing into the ﬁnal convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, {GradCAM} is applicable to a wide variety of {CNN} model-families: (1) {CNNs} with fully-connected layers (e.g. {VGG}), (2) {CNNs} used for structured outputs (e.g. captioning), (3) {CNNs} used in tasks with multi-modal inputs (e.g. visual question answering) or reinforcement learning, without architectural changes or re-training. We combine Grad-{CAM} with existing ﬁne-grained visualizations to create a high-resolution class-discriminative visualization, Guided Grad-{CAM}, and apply it to image classiﬁcation, image captioning, and visual question answering ({VQA}) models, including {ResNet}-based architectures. In the context of image classiﬁcation models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the {ILSVRC}-15 weakly-supervised localization task, (c) are more faithful to the underlying model, and (d) help achieve model generalization by identifying dataset bias. For image captioning and {VQA}, our visualizations show even non-attention based models can localize inputs. Finally, we design and conduct human studies to measure if Grad-{CAM} explanations help users establish appropriate trust in predictions from deep networks and show that Grad-{CAM} helps untrained users successfully discern a ‘stronger’ deep network from a ‘weaker’ one even when both make identical predictions. Our code is available at https: //github.com/ramprs/grad-cam/ along with a demo on {CloudCV} [2]1 and video at youtu.be/{COjUB}9Izk6E.},
	pages = {9},
	author = {Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	date = {2017},
	langid = {english},
}

@incollection{fleet_visualizing_2014,
	location = {Cham},
	title = {Visualizing and Understanding Convolutional Networks},
	volume = {8689},
	isbn = {978-3-319-10589-5 978-3-319-10590-1},
	url = {http://link.springer.com/10.1007/978-3-319-10590-1_53},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classiﬁcation performance on the {ImageNet} benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classiﬁer. Used in a diagnostic role, these visualizations allow us to ﬁnd model architectures that outperform Krizhevsky et al. on the {ImageNet} classiﬁcation benchmark. We also perform an ablation study to discover the performance contribution from diﬀerent model layers. We show our {ImageNet} model generalizes well to other datasets: when the softmax classiﬁer is retrained, it convincingly beats the current state-ofthe-art results on Caltech-101 and Caltech-256 datasets.},
	pages = {818--833},
	booktitle = {Computer Vision – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	urldate = {2021-09-23},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-319-10590-1_53},
	note = {Series Title: Lecture Notes in Computer Science},
}

@article{zintgraf_visualizing_2017,
	title = {Visualizing Deep Neural Network Decisions: Prediction Difference Analysis},
	url = {http://arxiv.org/abs/1702.04595},
	shorttitle = {Visualizing Deep Neural Network Decisions},
	abstract = {This article presents the prediction difference analysis method for visualizing the response of a deep neural network to a speciﬁc input. When classifying images, the method highlights areas in a given input image that provide evidence for or against a certain class. It overcomes several shortcoming of previous methods and provides great additional insight into the decision making process of classiﬁers. Making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black-box classiﬁers in application areas such as medicine. We illustrate the method in experiments on natural images ({ImageNet} data), as well as medical images ({MRI} brain scans).},
	journaltitle = {{arXiv}:1702.04595 [cs]},
	author = {Zintgraf, Luisa M. and Cohen, Taco S. and Adel, Tameem and Welling, Max},
	urldate = {2021-09-23},
	date = {2017-02-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1702.04595},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{smilkov_smoothgrad_2017,
	title = {{SmoothGrad}: removing noise by adding noise},
	url = {http://arxiv.org/abs/1706.03825},
	shorttitle = {{SmoothGrad}},
	abstract = {Explaining the output of a deep network remains a challenge. In the case of an image classiﬁer, one type of explanation is to identify pixels that strongly inﬂuence the ﬁnal decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces {SMOOTHGRAD}, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.},
	journaltitle = {{arXiv}:1706.03825 [cs, stat]},
	author = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Viégas, Fernanda and Wattenberg, Martin},
	urldate = {2021-09-22},
	date = {2017-06-12},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1706.03825},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@incollection{fleet_visualizing_2014-1,
	location = {Cham},
	title = {Visualizing and Understanding Convolutional Networks},
	volume = {8689},
	isbn = {978-3-319-10589-5 978-3-319-10590-1},
	url = {http://link.springer.com/10.1007/978-3-319-10590-1_53},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classiﬁcation performance on the {ImageNet} benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classiﬁer. Used in a diagnostic role, these visualizations allow us to ﬁnd model architectures that outperform Krizhevsky et al. on the {ImageNet} classiﬁcation benchmark. We also perform an ablation study to discover the performance contribution from diﬀerent model layers. We show our {ImageNet} model generalizes well to other datasets: when the softmax classiﬁer is retrained, it convincingly beats the current state-ofthe-art results on Caltech-101 and Caltech-256 datasets.},
	pages = {818--833},
	booktitle = {Computer Vision – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	urldate = {2021-09-22},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-319-10590-1_53},
	note = {Series Title: Lecture Notes in Computer Science},
}

@inproceedings{vig_multiscale_2019,
	location = {Florence, Italy},
	title = {A Multiscale Visualization of Attention in the Transformer Model},
	url = {https://www.aclweb.org/anthology/P19-3007},
	doi = {10.18653/v1/P19-3007},
	abstract = {The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difﬁcult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on {BERT} and {OpenAI} {GPT}-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.},
	eventtitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
	pages = {37--42},
	booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
	publisher = {Association for Computational Linguistics},
	author = {Vig, Jesse},
	urldate = {2021-09-22},
	date = {2019},
	langid = {english},
}

@article{sundararajan_axiomatic_2017,
	title = {Axiomatic Attribution for Deep Networks},
	url = {http://arxiv.org/abs/1703.01365},
	abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisﬁed by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modiﬁcation to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
	journaltitle = {{arXiv}:1703.01365 [cs]},
	author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	urldate = {2021-09-22},
	date = {2017-06-12},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1703.01365},
	keywords = {Computer Science - Machine Learning},
}

@article{lees_species_2015,
	title = {Species, extinct before we know them?},
	volume = {25},
	issn = {0960-9822},
	url = {https://www.sciencedirect.com/science/article/pii/S0960982214016182},
	doi = {10.1016/j.cub.2014.12.017},
	abstract = {Species are going extinct rapidly, while taxonomic catalogues are still incomplete for even the best-known taxa. Intensive fieldwork is finding species so rare and threatened that some become extinct within years of discovery. Recent bird extinctions in Brazil’s coastal forests suggest that some species may have gone extinct before we knew of their existence.},
	pages = {R177--R180},
	number = {5},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Lees, Alexander C. and Pimm, Stuart L.},
	urldate = {2021-09-22},
	date = {2015-03-02},
	langid = {english},
}

@online{birds_of_the_world_birds_nodate,
	title = {Birds of the World - Comprehensive life histories for all bird species and families},
	url = {https://birdsoftheworld.org/bow/home},
	abstract = {Species accounts for all the birds of the world.},
	author = {Birds of the World},
	urldate = {2021-09-16},
	langid = {english},
	note = {S. M. Billerman, B. K. Keeney, P. G. Rodewald, and T. S. Schulenberg, Editors, Cornell Laboratory of Ornithology, Ithaca, {NY}, {USA}.},
}

@article{musgrave_pytorch_2020,
	title = {{PyTorch} Metric Learning},
	url = {http://arxiv.org/abs/2008.09164},
	abstract = {Deep metric learning algorithms have a wide variety of applications, but implementing these algorithms can be tedious and time consuming. {PyTorch} Metric Learning is an open source library that aims to remove this barrier for both researchers and practitioners. The modular and flexible design allows users to easily try out different combinations of algorithms in their existing code. It also comes with complete train/test workflows, for users who want results fast. Code and documentation is available at https://www.github.com/{KevinMusgrave}/pytorch-metric-learning.},
	journaltitle = {{arXiv}:2008.09164 [cs]},
	author = {Musgrave, Kevin and Belongie, Serge and Lim, Ser-Nam},
	urldate = {2021-09-15},
	date = {2020-08-20},
	eprinttype = {arxiv},
	eprint = {2008.09164},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{al-halah_automatic_nodate,
	title = {Automatic Discovery, Association Estimation and Learning of Semantic Attributes for a Thousand Categories},
	abstract = {Attribute-based recognition models, due to their impressive performance and their ability to generalize well on novel categories, have been widely adopted for many computer vision applications. However, usually both the attribute vocabulary and the class-attribute associations have to be provided manually by domain experts or large number of annotators. This is very costly and not necessarily optimal regarding recognition performance, and most importantly, it limits the applicability of attribute-based models to large scale data sets. To tackle this problem, we propose an endto-end unsupervised attribute learning approach. We utilize online text corpora to automatically discover a salient and discriminative vocabulary that correlates well with the human concept of semantic attributes. Moreover, we propose a deep convolutional model to optimize class-attribute associations with a linguistic prior that accounts for noise and missing data in text. In a thorough evaluation on {ImageNet}, we demonstrate that our model is able to efﬁciently discover and learn semantic attributes at a large scale. Furthermore, we demonstrate that our model outperforms the state-ofthe-art in zero-shot learning on three data sets: {ImageNet}, Animals with Attributes and {aPascal}/{aYahoo}. Finally, we enable attribute-based learning on {ImageNet} and will share the attributes and associations for future research.},
	pages = {10},
	author = {Al-Halah, Ziad and Stiefelhagen, Rainer},
	langid = {english},
}

@article{schroff_facenet_2015,
	title = {{FaceNet}: A Unified Embedding for Face Recognition and Clustering},
	url = {http://arxiv.org/abs/1503.03832},
	doi = {10.1109/CVPR.2015.7298682},
	shorttitle = {{FaceNet}},
	abstract = {Despite signiﬁcant recent advances in the ﬁeld of face recognition [10, 14, 15, 17], implementing face veriﬁcation and recognition efﬁciently at scale presents serious challenges to current approaches. In this paper we present a system, called {FaceNet}, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, veriﬁcation and clustering can be easily implemented using standard techniques with {FaceNet} embeddings as feature vectors.},
	pages = {815--823},
	journaltitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
	urldate = {2021-09-13},
	date = {2015-06},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1503.03832},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{ghojogh_fisher_2020,
	title = {Fisher Discriminant Triplet and Contrastive Losses for Training Siamese Networks},
	url = {http://arxiv.org/abs/2004.04674},
	doi = {10.1109/IJCNN48605.2020.9206833},
	abstract = {Siamese neural network is a very powerful architecture for both feature extraction and metric learning. It usually consists of several networks that share weights. The Siamese concept is topology-agnostic and can use any neural network as its backbone. The two most popular loss functions for training these networks are the triplet and contrastive loss functions. In this paper, we propose two novel loss functions, named Fisher Discriminant Triplet ({FDT}) and Fisher Discriminant Contrastive ({FDC}). The former uses anchor-neighbor-distant triplets while the latter utilizes pairs of anchor-neighbor and anchor-distant samples. The {FDT} and {FDC} loss functions are designed based on the statistical formulation of the Fisher Discriminant Analysis ({FDA}), which is a linear subspace learning method. Our experiments on the {MNIST} and two challenging and publicly available histopathology datasets show the effectiveness of the proposed loss functions.},
	pages = {1--7},
	journaltitle = {2020 International Joint Conference on Neural Networks ({IJCNN})},
	author = {Ghojogh, Benyamin and Sikaroudi, Milad and Shafiei, Sobhan and Tizhoosh, H. R. and Karray, Fakhri and Crowley, Mark},
	urldate = {2021-09-13},
	date = {2020-07},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2004.04674},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kaya_deep_2019,
	title = {Deep Metric Learning: A Survey},
	volume = {11},
	issn = {2073-8994},
	url = {https://www.mdpi.com/2073-8994/11/9/1066},
	doi = {10.3390/sym11091066},
	shorttitle = {Deep Metric Learning},
	abstract = {Metric learning aims to measure the similarity among samples while using an optimal distance metric for learning tasks. Metric learning methods, which generally use a linear projection, are limited in solving real-world problems demonstrating non-linear characteristics. Kernel approaches are utilized in metric learning to address this problem. In recent years, deep metric learning, which provides a better solution for nonlinear data through activation functions, has attracted researchers’ attention in many diﬀerent areas. This article aims to reveal the importance of deep metric learning and the problems dealt with in this ﬁeld in the light of recent studies. As far as the research conducted in this ﬁeld are concerned, most existing studies that are inspired by Siamese and Triplet networks are commonly used to correlate among samples while using shared weights in deep metric learning. The success of these networks is based on their capacity to understand the similarity relationship among samples. Moreover, sampling strategy, appropriate distance metric, and the structure of the network are the challenging factors for researchers to improve the performance of the network model. This article is considered to be important, as it is the ﬁrst comprehensive study in which these factors are systematically analyzed and evaluated as a whole and supported by comparing the quantitative results of the methods.},
	pages = {1066},
	number = {9},
	journaltitle = {Symmetry},
	shortjournal = {Symmetry},
	author = {{Kaya} and {Bilge}},
	urldate = {2021-09-13},
	date = {2019-08-21},
	langid = {english},
}

@article{sanh_distilbert_2020,
	title = {{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter},
	url = {http://arxiv.org/abs/1910.01108},
	shorttitle = {{DistilBERT}, a distilled version of {BERT}},
	abstract = {As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing ({NLP}), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called {DistilBERT}, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a {BERT} model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.},
	journaltitle = {{arXiv}:1910.01108 [cs]},
	author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
	urldate = {2021-09-09},
	date = {2020-02-29},
	eprinttype = {arxiv},
	eprint = {1910.01108},
	keywords = {Computer Science - Computation and Language},
}

@online{ontotext_what_2021,
	title = {What is a Knowledge Graph?},
	url = {https://www.ontotext.com/knowledgehub/fundamentals/what-is-a-knowledge-graph/},
	abstract = {Knowledge graphs are a collection of interlinked descriptions of entities that put data into context and enable data integration, analytics \& sharing.},
	titleaddon = {Ontotext},
	author = {Ontotext},
	urldate = {2021-09-09},
	date = {2021},
	langid = {american},
}

@article{van_lent_explainable_2004,
	title = {An Explainable Artificial Intelligence System for Small-unit Tactical Behavior},
	pages = {8},
	author = {van Lent, Michael and Fisher, William and Mancuso, Michael},
	date = {2004},
	langid = {english},
}

@article{doshi-velez_towards_2017,
	title = {Towards A Rigorous Science of Interpretable Machine Learning},
	url = {http://arxiv.org/abs/1702.08608},
	abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
	journaltitle = {{arXiv}:1702.08608 [cs, stat]},
	author = {Doshi-Velez, Finale and Kim, Been},
	urldate = {2021-08-31},
	date = {2017-03-02},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1702.08608},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@incollection{paszke_pytorch_2019,
	title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
	pages = {8024--8035},
	booktitle = {Advances in Neural Information Processing Systems 32},
	publisher = {Curran Associates, Inc.},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and {DeVito}, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	date = {2019},
}

@inproceedings{munappy_data_2019,
	location = {Kallithea-Chalkidiki, Greece},
	title = {Data Management Challenges for Deep Learning},
	isbn = {978-1-72813-421-5},
	url = {https://ieeexplore.ieee.org/document/8906736/},
	doi = {10.1109/SEAA.2019.00030},
	abstract = {Deep learning is one of the most exciting and fastgrowing techniques in Artiﬁcial Intelligence. The unique capacity of deep learning models to automatically learn patterns from the data differentiates it from other machine learning techniques. Deep learning is responsible for a signiﬁcant number of recent breakthroughs in {AI}. However, deep learning models are highly dependent on the underlying data. So, consistency, accuracy, and completeness of data is essential for a deep learning model. Thus, data management principles and practices need to be adopted throughout the development process of deep learning models. The objective of this study is to identify and categorise data management challenges faced by practitioners in different stages of end-to-end development. In this paper, a case study approach is employed to explore the data management issues faced by practitioners across various domains when they use real-world data for training and deploying deep learning models. Our case study is intended to provide valuable insights to the deep learning community as well as for data scientists to guide discussion and future research in applied deep learning with real-world data.},
	eventtitle = {2019 45th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	pages = {140--147},
	booktitle = {2019 45th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	publisher = {{IEEE}},
	author = {Munappy, Aiswarya and Bosch, Jan and Olsson, Helena Holmstrom and Arpteg, Anders and Brinne, Bjorn},
	urldate = {2021-08-29},
	date = {2019-08},
	langid = {english},
}

@article{reed_training_2015,
	title = {Training Deep Neural Networks on Noisy Labels with Bootstrapping},
	url = {http://arxiv.org/abs/1412.6596},
	abstract = {Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overﬁtting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On {MNIST} handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-theart results, and can also beneﬁt from unlabeled face images with no modiﬁcation to our method. On the {ILSVRC}2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.},
	journaltitle = {{arXiv}:1412.6596 [cs]},
	author = {Reed, Scott and Lee, Honglak and Anguelov, Dragomir and Szegedy, Christian and Erhan, Dumitru and Rabinovich, Andrew},
	urldate = {2021-08-23},
	date = {2015-04-15},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1412.6596},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{samek_explainable_2017,
	title = {Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models},
	url = {http://arxiv.org/abs/1708.08296},
	shorttitle = {Explainable Artificial Intelligence},
	abstract = {With the availability of large databases and recent improvements in deep learning methodology, the performance of {AI} systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.},
	journaltitle = {{arXiv}:1708.08296 [cs, stat]},
	author = {Samek, Wojciech and Wiegand, Thomas and Müller, Klaus-Robert},
	urldate = {2021-08-03},
	date = {2017-08-28},
	eprinttype = {arxiv},
	eprint = {1708.08296},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{lei_opening_2018,
	title = {Opening the black box of deep learning},
	url = {http://arxiv.org/abs/1805.08355},
	abstract = {The great success of deep learning shows that its technology contains profound truth, and understanding its internal mechanism not only has important implications for the development of its technology and effective application in various ﬁelds, but also provides meaningful insights into the understanding of human brain mechanism. At present, most of the theoretical research on deep learning is based on mathematics. This dissertation proposes that the neural network of deep learning is a physical system, examines deep learning from three different perspectives: microscopic, macroscopic, and physical world views, answers multiple theoretical puzzles in deep learning by using physics principles. For example, from the perspective of quantum mechanics and statistical physics, this dissertation presents the calculation methods for convolution calculation, pooling, normalization, and Restricted Boltzmann Machine, as well as the selection of cost functions, explains why deep learning must be deep, what characteristics are learned in deep learning, why Convolutional Neural Networks do not have to be trained layer by layer, and the limitations of deep learning, etc., and proposes the theoretical direction and basis for the further development of deep learning now and in the future. The brilliance of physics ﬂashes in deep learning, we try to establish the deep learning technology based on the scientiﬁc theory of physics.},
	journaltitle = {{arXiv}:1805.08355 [cs, stat]},
	author = {Lei, Dian and Chen, Xiaoxiao and Zhao, Jianfei},
	urldate = {2021-08-03},
	date = {2018-05-21},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1805.08355},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{fu_speech--knowledge-graph_2020,
	location = {Yokohama, Japan},
	title = {A Speech-to-Knowledge-Graph Construction System},
	isbn = {978-0-9992411-6-5},
	url = {https://www.ijcai.org/proceedings/2020/777},
	doi = {10.24963/ijcai.2020/777},
	abstract = {This paper presents a {HAO}-Graph system that generates and visualizes knowledge graphs from a speech in real-time. When a user speaks to the system, {HAO}-Graph transforms the voice into knowledge graphs with key phrases from the original speech as nodes and edges. Different from language-to-language systems, such as Chinese-{toEnglish} and English-to-English, {HAO}-Graph converts a speech into graphs, and is the ﬁrst of its kind. The effectiveness of our {HAO}-Graph system is veriﬁed by a two-hour chairman’s talk in front of two thousand participants at an annual meeting in the form of a satisfaction survey.},
	eventtitle = {Twenty-Ninth International Joint Conference on Artificial Intelligence and Seventeenth Pacific Rim International Conference on Artificial Intelligence \{{IJCAI}-{PRICAI}-20\}},
	pages = {5303--5305},
	booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Fu, Xiaoyi and Zhang, Jie and Yu, Hao and Li, Jiachen and Chen, Dong and Yuan, Jie and Wu, Xindong},
	urldate = {2021-08-02},
	date = {2020-07},
	langid = {english},
}

@article{lipton_mythos_2017,
	title = {The Mythos of Model Interpretability},
	url = {http://arxiv.org/abs/1606.03490},
	abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
	journaltitle = {{arXiv}:1606.03490 [cs, stat]},
	author = {Lipton, Zachary C.},
	urldate = {2021-07-30},
	date = {2017-03-06},
	eprinttype = {arxiv},
	eprint = {1606.03490},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@inproceedings{he_delving_2015,
	location = {Santiago, Chile},
	title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {ImageNet} Classification},
	isbn = {978-1-4673-8391-2},
	url = {http://ieeexplore.ieee.org/document/7410480/},
	doi = {10.1109/ICCV.2015.123},
	shorttitle = {Delving Deep into Rectifiers},
	abstract = {Rectiﬁed activation units (rectiﬁers) are essential for state-of-the-art neural networks. In this work, we study rectiﬁer neural networks for image classiﬁcation from two aspects. First, we propose a Parametric Rectiﬁed Linear Unit ({PReLU}) that generalizes the traditional rectiﬁed unit. {PReLU} improves model ﬁtting with nearly zero extra computational cost and little overﬁtting risk. Second, we derive a robust initialization method that particularly considers the rectiﬁer nonlinearities. This method enables us to train extremely deep rectiﬁed models directly from scratch and to investigate deeper or wider network architectures. Based on the learnable activation and advanced initialization, we achieve 4.94\% top-5 test error on the {ImageNet} 2012 classiﬁcation dataset. This is a 26\% relative improvement over the {ILSVRC} 2014 winner ({GoogLeNet}, 6.66\% [33]). To our knowledge, our result is the ﬁrst1 to surpass the reported human-level performance (5.1\%, [26]) on this dataset.},
	eventtitle = {2015 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {1026--1034},
	booktitle = {2015 {IEEE} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2021-07-30},
	date = {2015-12},
	langid = {english},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2021-07-30},
	date = {2015-05-28},
	langid = {english},
}

@inproceedings{chakraborty_interpretability_2017,
	location = {San Francisco, {CA}},
	title = {Interpretability of deep learning models: A survey of results},
	isbn = {978-1-5386-0435-9},
	url = {https://ieeexplore.ieee.org/document/8397411/},
	doi = {10.1109/UIC-ATC.2017.8397411},
	shorttitle = {Interpretability of deep learning models},
	abstract = {Deep neural networks have achieved near-human accuracy levels in various types of classiﬁcation and prediction tasks including images, text, speech, and video data. However, the networks continue to be treated mostly as black-box function approximators, mapping a given input to a classiﬁcation output. The next step in this human-machine evolutionary process –incorporating these networks into mission critical processes such as medical diagnosis, planning and control – requires a level of trust association with the machine output.},
	eventtitle = {2017 {IEEE} {SmartWorld}, Ubiquitous Intelligence \& Computing, Advanced \& Trusted Computed, Scalable Computing \& Communications, Cloud \& Big Data Computing, Internet of People and Smart City Innovation ({SmartWorld}/{SCALCOM}/{UIC}/{ATC}/{CBDCom}/{IOP}/{SCI})},
	pages = {1--6},
	booktitle = {2017 {IEEE} {SmartWorld}, Ubiquitous Intelligence \& Computing, Advanced \& Trusted Computed, Scalable Computing \& Communications, Cloud \& Big Data Computing, Internet of People and Smart City Innovation ({SmartWorld}/{SCALCOM}/{UIC}/{ATC}/{CBDCom}/{IOP}/{SCI})},
	publisher = {{IEEE}},
	author = {Chakraborty, Supriyo and Tomsett, Richard and Raghavendra, Ramya and Harborne, Daniel and Alzantot, Moustafa and Cerutti, Federico and Srivastava, Mani and Preece, Alun and Julier, Simon and Rao, Raghuveer M. and Kelley, Troy D. and Braines, Dave and Sensoy, Murat and Willis, Christopher J. and Gurram, Prudhvi},
	urldate = {2021-07-30},
	date = {2017-08},
	langid = {english},
}

@article{yang_denert-kg_2020,
	title = {{DeNERT}-{KG}: Named Entity and Relation Extraction Model Using {DQN}, Knowledge Graph, and {BERT}},
	volume = {10},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2076-3417/10/18/6429},
	doi = {10.3390/app10186429},
	shorttitle = {{DeNERT}-{KG}},
	abstract = {Along with studies on artificial intelligence technology, research is also being carried out actively in the field of natural language processing to understand and process people\&rsquo;s language, in other words, natural language. For computers to learn on their own, the skill of understanding natural language is very important. There are a wide variety of tasks involved in the field of natural language processing, but we would like to focus on the named entity registration and relation extraction task, which is considered to be the most important in understanding sentences. We propose {DeNERT}-{KG}, a model that can extract subject, object, and relationships, to grasp the meaning inherent in a sentence. Based on the {BERT} language model and Deep Q-Network, the named entity recognition ({NER}) model for extracting subject and object is established, and a knowledge graph is applied for relation extraction. Using the {DeNERT}-{KG} model, it is possible to extract the subject, type of subject, object, type of object, and relationship from a sentence, and verify this model through experiments.},
	pages = {6429},
	number = {18},
	journaltitle = {Applied Sciences},
	author = {Yang, {SungMin} and Yoo, {SoYeop} and Jeong, {OkRan}},
	urldate = {2021-07-28},
	date = {2020-01},
	langid = {english},
	note = {Number: 18
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{BERT}, {DQN}, knowledge graph, named entity recognition, relation extraction},
}

@article{wu_scalable_2020,
	title = {Scalable Zero-shot Entity Linking with Dense Entity Retrieval},
	url = {http://arxiv.org/abs/1911.03814},
	abstract = {This paper introduces a conceptually simple, scalable, and highly effective {BERT}-based entity linking model, along with an extensive evaluation of its accuracy-speed trade-off. We present a two-stage zero-shot linking algorithm, where each entity is deﬁned only by a short textual description. The ﬁrst stage does retrieval in a dense space deﬁned by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then re-ranked with a crossencoder, that concatenates the mention and entity text. Experiments demonstrate that this approach is state of the art on recent zeroshot benchmarks (6 point absolute gains) and also on more established non-zero-shot evaluations (e.g. {TACKBP}-2010), despite its relative simplicity (e.g. no explicit entity embeddings or manually engineered mention tables). We also show that bi-encoder linking is very fast with nearest neighbour search (e.g. linking with 5.9 million candidates in 2 milliseconds), and that much of the accuracy gain from the more expensive crossencoder can be transferred to the bi-encoder via knowledge distillation. Our code and models are available at https://github. com/facebookresearch/{BLINK}.},
	journaltitle = {{arXiv}:1911.03814 [cs]},
	author = {Wu, Ledell and Petroni, Fabio and Josifoski, Martin and Riedel, Sebastian and Zettlemoyer, Luke},
	urldate = {2021-07-27},
	date = {2020-09-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1911.03814},
	keywords = {Computer Science - Computation and Language},
}

@article{stewart_icdm_2019,
	title = {{ICDM} 2019 Knowledge Graph Contest: Team {UWA}},
	url = {http://arxiv.org/abs/1909.01807},
	shorttitle = {{ICDM} 2019 Knowledge Graph Contest},
	abstract = {We present an overview of our triple extraction system for the {ICDM} 2019 Knowledge Graph Contest. Our system uses a pipeline-based approach to extract a set of triples from a given document. It offers a simple and effective solution to the challenge of knowledge graph construction from domain-specific text. It also provides the facility to visualise useful information about each triple such as the degree, betweenness, structured relation type(s), and named entity types.},
	journaltitle = {{arXiv}:1909.01807 [cs]},
	author = {Stewart, Michael and Enkhsaikhan, Majigsuren and Liu, Wei},
	urldate = {2021-07-27},
	date = {2019-09-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1909.01807},
	keywords = {Computer Science - Computation and Language},
}

@article{sergeev_application_2020,
	title = {An Application of Semantic Relation Extraction Models},
	abstract = {Natural language processing ({NLP}) is growing to be one of the largest subfields of computer science, with application to many other fields such as linguistics or information extraction. This large growth has resulted in higher availability and a variety of resources that contributors can work with. Semantic relation datasets as a result have seen an increase in number and many today, including high profile companies at the head of {NLP}, are creating stateof-the-art machine learning models. These models are capable of identifying these relations from sentences by training on this selection of datasets. The number of models applied outside of their datasets, however, is still relatively low. With such a high amount of data being produced daily in our technological world, semantic relation models could potentially be used to help increase the speed at which specific information can be identified and extracted from their collections of data. This project will look at the accuracy of trained semantic models outside of their training datasets to assess the applicability of them as a tool for a general information search.},
	pages = {5},
	author = {Sergeev, Aleksandr},
	date = {2020},
	langid = {english},
}

@article{kim_greg_2020,
	title = {{GREG}: A Global Level Relation Extraction with Knowledge Graph Embedding},
	volume = {10},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/3/1181},
	doi = {10.3390/app10031181},
	shorttitle = {{GREG}},
	abstract = {In an age overﬂowing with information, the task of converting unstructured data into structured data are a vital task of great need. Currently, most relation extraction modules are more focused on the extraction of local mention-level relations—usually from short volumes of text. However, in most cases, the most vital and important relations are those that are described in length and detail. In this research, we propose {GREG}: A Global level Relation Extractor model using knowledge graph embeddings for document-level inputs. The model uses vector representations of mention-level ‘local’ relation’s to construct knowledge graphs that can represent the input document. The knowledge graph is then used to predict global level relations from documents or large bodies of text. The proposed model is largely divided into two modules which are synchronized during their training. Thus, each of the model’s modules is designed to deal with local relations and global relations separately. This allows the model to avoid the problem of struggling against loss of information due to too much information crunched into smaller sized representations when attempting global level relation extraction. Through evaluation, we have shown that the proposed model yields high performances in both predicting global level relations and local level relations consistently.},
	pages = {1181},
	number = {3},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Kim, Kuekyeng and Hur, Yuna and Kim, Gyeongmin and Lim, Heuiseok},
	urldate = {2021-07-20},
	date = {2020-02-10},
	langid = {english},
}

@article{martinez-rodriguez_openie-based_2018,
	title = {{OpenIE}-based approach for Knowledge Graph construction from text},
	volume = {113},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417418304329},
	doi = {10.1016/j.eswa.2018.07.017},
	pages = {339--355},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Martinez-Rodriguez, Jose L. and Lopez-Arevalo, Ivan and Rios-Alvarado, Ana B.},
	urldate = {2021-07-20},
	date = {2018-12},
	langid = {english},
}

@online{noauthor_openie-based_nodate,
	title = {{OpenIE}-based approach for Knowledge Graph construction from text {\textbar} Elsevier Enhanced Reader},
	url = {https://reader.elsevier.com/reader/sd/pii/S0957417418304329?token=2EEAB1A078C9DD135C1E6513ED6CAEA37E228CEB29BAD3B64F5EC0DB23AC90577D2252D7EC5F6BAFA5CB0A5403498D81&originRegion=eu-west-1&originCreation=20210720114836},
	urldate = {2021-07-20},
	langid = {english},
	doi = {10.1016/j.eswa.2018.07.017},
}

@article{martinez-rodriguez_openie-based_2018-1,
	title = {{OpenIE}-based approach for Knowledge Graph construction from text},
	volume = {113},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417418304329},
	doi = {10.1016/j.eswa.2018.07.017},
	abstract = {Transforming unstructured text into a formal representation is an important goal of the Semantic Web in order to facilitate the integration and retrieval of information. The construction of Knowledge Graphs ({KGs}) pursues such an idea, where named entities (real world things) and their relations are extracted from text. In recent years, many approaches for the construction of {KGs} have been proposed by exploiting Discourse Analysis, Semantic Frames, or Machine Learning algorithms with existing Semantic Web data. Although such approaches are useful for processing taxonomies and connecting beliefs, they provide several linguistic descriptions, which lead to semantic data heterogeneity and thus, complicating data consumption. Moreover, Open Information Extraction ({OpenIE}) approaches have been slightly explored for the construction of {KGs}, which provide binary relations representing atomic units of information that could simplify the querying and representation of data. In this paper, we propose an approach to generate {KGs} using binary relations produced by an {OpenIE} approach. For such purpose, we present strategies for favoring the extraction and linking of named entities with {KG} individuals, and additionally, their association with grammatical units that lead to producing more coherent facts. We also provide decisions for selecting the extracted information elements for creating potentially useful {RDF} triples for the {KG}. Our results demonstrate that the integration of information extraction units with grammatical structures provides a better understanding of proposition-based representations provided by {OpenIE} for supporting the construction of {KGs}.},
	pages = {339--355},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Martinez-Rodriguez, Jose L. and Lopez-Arevalo, Ivan and Rios-Alvarado, Ana B.},
	urldate = {2021-07-20},
	date = {2018-12-15},
	langid = {english},
	keywords = {Fact extraction, Knowledge Graph, {RDF} events, Relation Extraction, Semantic Web representation},
}

@article{li_understanding_2017,
	title = {Understanding Neural Networks through Representation Erasure},
	url = {http://arxiv.org/abs/1612.08220},
	abstract = {While neural networks have been successfully applied to many natural language processing tasks, they come at the cost of interpretability. In this paper, we propose a general methodology to analyze and interpret decisions from a neural model by observing the effects on the model of erasing various parts of the representation, such as input word-vector dimensions, intermediate hidden units, or input words. We present several approaches to analyzing the effects of such erasure, from computing the relative difference in evaluation metrics, to using reinforcement learning to erase the minimum set of input words in order to flip a neural model's decision. In a comprehensive analysis of multiple {NLP} tasks, including linguistic feature classification, sentence-level sentiment analysis, and document level sentiment aspect prediction, we show that the proposed methodology not only offers clear explanations about neural model decisions, but also provides a way to conduct error analysis on neural models.},
	journaltitle = {{arXiv}:1612.08220 [cs]},
	author = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
	urldate = {2021-07-19},
	date = {2017-01-09},
	eprinttype = {arxiv},
	eprint = {1612.08220},
	keywords = {Computer Science - Computation and Language},
}

@article{vaswani_attention_nodate,
	title = {Attention is All you Need},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.0 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature.},
	pages = {11},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	langid = {english},
}

@online{billerman_birds_nodate,
	title = {Birds of the World - Comprehensive life histories for all bird species and families},
	url = {https://birdsoftheworld.org/bow/home},
	abstract = {Species accounts for all the birds of the world.},
	titleaddon = {Birds of the World},
	type = {Database},
	author = {Billerman, S.M. and Keeney, B.K. and Rodewald, P.G. and Schulenberg, T.S.},
	urldate = {2021-07-13},
	langid = {english},
}

@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the {ImageNet} {LSVRC}-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of ﬁve convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a ﬁnal 1000-way softmax. To make training faster, we used non-saturating neurons and a very efﬁcient {GPU} implementation of the convolution operation. To reduce overﬁtting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the {ILSVRC}-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	pages = {84--90},
	number = {6},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	urldate = {2021-07-13},
	date = {2017-05-24},
	langid = {english},
}

@article{mikolov_distributed_2013,
	title = {Distributed Representations of Words and Phrases and their Compositionality},
	url = {http://arxiv.org/abs/1310.4546},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	journaltitle = {{arXiv}:1310.4546 [cs, stat]},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2021-07-13},
	date = {2013-10-16},
	eprinttype = {arxiv},
	eprint = {1310.4546},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{sun_how_2020,
	title = {How to Fine-Tune {BERT} for Text Classification?},
	url = {http://arxiv.org/abs/1905.05583},
	abstract = {Language model pre-training has proven to be useful in learning universal language representations. As a state-of-the-art language model pre-training model, {BERT} (Bidirectional Encoder Representations from Transformers) has achieved amazing results in many language understanding tasks. In this paper, we conduct exhaustive experiments to investigate different fine-tuning methods of {BERT} on text classification task and provide a general solution for {BERT} fine-tuning. Finally, the proposed solution obtains new state-of-the-art results on eight widely-studied text classification datasets.},
	journaltitle = {{arXiv}:1905.05583 [cs]},
	author = {Sun, Chi and Qiu, Xipeng and Xu, Yige and Huang, Xuanjing},
	urldate = {2021-07-11},
	date = {2020-02-05},
	eprinttype = {arxiv},
	eprint = {1905.05583},
	keywords = {Computer Science - Computation and Language},
}

@article{minaee_deep_2021,
	title = {Deep Learning Based Text Classification: A Comprehensive Review},
	url = {http://arxiv.org/abs/2004.03705},
	shorttitle = {Deep Learning Based Text Classification},
	abstract = {Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions.},
	journaltitle = {{arXiv}:2004.03705 [cs, stat]},
	author = {Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
	urldate = {2021-07-11},
	date = {2021-01-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2004.03705},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{brown_language_2020,
	title = {Language Models are Few-Shot Learners},
	url = {http://arxiv.org/abs/2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many {NLP} tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current {NLP} systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train {GPT}-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, {GPT}-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. {GPT}-3 achieves strong performance on many {NLP} datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where {GPT}-3's few-shot learning still struggles, as well as some datasets where {GPT}-3 faces methodological issues related to training on large web corpora. Finally, we find that {GPT}-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of {GPT}-3 in general.},
	journaltitle = {{arXiv}:2005.14165 [cs]},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and {McCandlish}, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	urldate = {2021-07-11},
	date = {2020-07-22},
	eprinttype = {arxiv},
	eprint = {2005.14165},
	keywords = {Computer Science - Computation and Language},
}

@incollection{amershi_modeltracker_2015,
	location = {New York, {NY}, {USA}},
	title = {{ModelTracker}: Redesigning Performance Analysis Tools for Machine Learning},
	isbn = {978-1-4503-3145-6},
	url = {https://doi.org/10.1145/2702123.2702509},
	shorttitle = {{ModelTracker}},
	abstract = {Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present {ModelTracker}, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with {ModelTracker} over six months shows {ModelTracker} is used often and throughout model building. A controlled experiment focusing on {ModelTracker}'s debugging capabilities shows participants prefer {ModelTracker} over traditional tools without a loss in model performance.},
	pages = {337--346},
	booktitle = {Proceedings of the 33rd Annual {ACM} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Amershi, Saleema and Chickering, Max and Drucker, Steven M. and Lee, Bongshin and Simard, Patrice and Suh, Jina},
	urldate = {2021-07-11},
	date = {2015-04-18},
	keywords = {debugging, interactive visualization, machine learning, performance analysis},
}

@article{bai_empirical_2018,
	title = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
	url = {http://arxiv.org/abs/1803.01271},
	abstract = {For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as {LSTMs} across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/{TCN} .},
	journaltitle = {{arXiv}:1803.01271 [cs]},
	author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
	urldate = {2021-07-11},
	date = {2018-04-19},
	eprinttype = {arxiv},
	eprint = {1803.01271},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{koh_understanding_2020,
	title = {Understanding Black-box Predictions via Influence Functions},
	url = {http://arxiv.org/abs/1703.04730},
	abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
	journaltitle = {{arXiv}:1703.04730 [cs, stat]},
	author = {Koh, Pang Wei and Liang, Percy},
	urldate = {2021-07-09},
	date = {2020-12-29},
	eprinttype = {arxiv},
	eprint = {1703.04730},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ribeiro_why_2016,
	title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
	url = {http://arxiv.org/abs/1602.04938},
	shorttitle = {"Why Should I Trust You?},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose {LIME}, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	journaltitle = {{arXiv}:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	urldate = {2021-07-09},
	date = {2016-08-09},
	eprinttype = {arxiv},
	eprint = {1602.04938},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{carvalho_machine_2019,
	title = {Machine Learning Interpretability: A Survey on Methods and Metrics},
	volume = {8},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2079-9292/8/8/832},
	doi = {10.3390/electronics8080832},
	shorttitle = {Machine Learning Interpretability},
	abstract = {Machine learning systems are becoming increasingly ubiquitous. These systems\&rsquo;s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.},
	pages = {832},
	number = {8},
	journaltitle = {Electronics},
	author = {Carvalho, Diogo V. and Pereira, Eduardo M. and Cardoso, Jaime S.},
	urldate = {2021-07-09},
	date = {2019-08},
	langid = {english},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{XAI}, explainability, interpretability, machine learning},
}

@article{li_interpretable_2021,
	title = {Interpretable Deep Learning: Interpretation, Interpretability, Trustworthiness, and Beyond},
	url = {http://arxiv.org/abs/2103.10689},
	shorttitle = {Interpretable Deep Learning},
	abstract = {Deep neural networks have been well-known for their superb performance in handling various machine learning and artiﬁcial intelligence tasks. However, due to their over-parameterized black-box nature, it is often diﬃcult to understand the prediction results of deep models. In recent years, many interpretation tools have been proposed to explain or reveal the ways that deep models make decisions. In this paper, we review this line of research and try to make a comprehensive survey. Speciﬁcally, we introduce and clarify two basic concepts—interpretations and interpretability—that people usually get confused. First of all, to address the research eﬀorts in interpretations, we elaborate the design of several recent interpretation algorithms, from diﬀerent perspectives, through proposing a new taxonomy. Then, to understand the results of interpretation, we also survey the performance metrics for evaluating interpretation algorithms. Further, we summarize the existing work in evaluating models’ interpretability using “trustworthy” interpretation algorithms. Finally, we review and discuss the connections between deep models’ interpretations and other factors, such as adversarial robustness and data augmentations, and we introduce several open-source libraries for interpretation algorithms and evaluation approaches.},
	journaltitle = {{arXiv}:2103.10689 [cs]},
	author = {Li, Xuhong and Xiong, Haoyi and Li, Xingjian and Wu, Xuanyu and Zhang, Xiao and Liu, Ji and Bian, Jiang and Dou, Dejing},
	urldate = {2021-07-09},
	date = {2021-05-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2103.10689},
	keywords = {Computer Science - Machine Learning},
}

@article{zhai_scaling_2021,
	title = {Scaling Vision Transformers},
	url = {http://arxiv.org/abs/2106.04560},
	abstract = {Attention-based neural networks such as the Vision Transformer ({ViT}) have recently attained state-of-the-art results on many computer vision benchmarks. Scale is a primary ingredient in attaining excellent results, therefore, understanding a model’s scaling properties is a key to designing future generations effectively. While the laws for scaling Transformer language models have been studied, it is unknown how Vision Transformers scale. To address this, we scale {ViT} models and data, both up and down, and characterize the relationships between error rate, data, and compute. Along the way, we reﬁne the architecture and training of {ViT}, reducing memory consumption and increasing accuracy of the resulting models. As a result, we successfully train a {ViT} model with two billion parameters, which attains a new state-of-the-art on {ImageNet} of 90.45\% top-1 accuracy. The model also performs well on few-shot learning, for example, reaching 84.86\% top-1 accuracy on {ImageNet} with only 10 examples per class.},
	journaltitle = {{arXiv}:2106.04560 [cs]},
	author = {Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
	urldate = {2021-07-09},
	date = {2021-06-08},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2106.04560},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{devlin_bert_2019,
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {http://arxiv.org/abs/1810.04805},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), {BERT} is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.},
	journaltitle = {{arXiv}:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2021-07-04},
	date = {2019-05-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1810.04805},
	keywords = {Computer Science - Computation and Language},
}

@article{losch_interpretability_2019,
	title = {Interpretability Beyond Classification Output: Semantic Bottleneck Networks},
	url = {http://arxiv.org/abs/1907.10882},
	shorttitle = {Interpretability Beyond Classification Output},
	abstract = {Today’s deep learning systems deliver high performance based on end-to-end training. While they deliver strong performance, these systems are hard to interpret. To address this issue, we propose Semantic Bottleneck Networks ({SBN}): deep networks with semantically interpretable intermediate layers that all downstream results are based on. As a consequence, the analysis on what the ﬁnal prediction is based on is transparent to the engineer and failure cases and modes can be analyzed and avoided by high-level reasoning. We present a case study on street scene segmentation to demonstrate the feasibility and power of {SBN}. In particular, we start from a well performing classic deep network which we adapt to house a {SB}-Layer containing task related semantic concepts (such as object-parts and materials). Importantly, we can recover state of the art performance despite a drastic dimensionality reduction from 1000s (non-semantic feature) to 10s (semantic concept) channels. Additionally we show how the activations of the {SB}-Layer can be used for both the interpretation of failure cases of the network as well as for conﬁdence prediction of the resulting output. For the ﬁrst time, e.g., we show interpretable segmentation results for most predictions at over 99\% accuracy.},
	journaltitle = {{arXiv}:1907.10882 [cs]},
	author = {Losch, Max and Fritz, Mario and Schiele, Bernt},
	urldate = {2021-07-04},
	date = {2019-07-28},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.10882},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{wu_visual_2020,
	title = {Visual Transformers: Token-based Image Representation and Processing for Computer Vision},
	url = {http://arxiv.org/abs/2006.03677},
	shorttitle = {Visual Transformers},
	abstract = {Computer vision has achieved remarkable success by (a) representing images as uniformly-arranged pixel arrays and (b) convolving highly-localized features. However, convolutions treat all image pixels equally regardless of importance; explicitly model all concepts across all images, regardless of content; and struggle to relate spatially-distant concepts. In this work, we challenge this paradigm by (a) representing images as semantic visual tokens and (b) running transformers to densely model token relationships. Critically, our Visual Transformer operates in a semantic token space, judiciously attending to different image parts based on context. This is in sharp contrast to pixel-space transformers that require orders-of-magnitude more compute. Using an advanced training recipe, our {VTs} significantly outperform their convolutional counterparts, raising {ResNet} accuracy on {ImageNet} top-1 by 4.6 to 7 points while using fewer {FLOPs} and parameters. For semantic segmentation on {LIP} and {COCO}-stuff, {VT}-based feature pyramid networks ({FPN}) achieve 0.35 points higher {mIoU} while reducing the {FPN} module's {FLOPs} by 6.5x.},
	journaltitle = {{arXiv}:2006.03677 [cs, eess]},
	author = {Wu, Bichen and Xu, Chenfeng and Dai, Xiaoliang and Wan, Alvin and Zhang, Peizhao and Yan, Zhicheng and Tomizuka, Masayoshi and Gonzalez, Joseph and Keutzer, Kurt and Vajda, Peter},
	urldate = {2021-05-12},
	date = {2020-11-19},
	eprinttype = {arxiv},
	eprint = {2006.03677},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{huang_interpretable_2020,
	title = {Interpretable and Accurate Fine-grained Recognition via Region Grouping},
	url = {http://arxiv.org/abs/2005.10411},
	abstract = {We present an interpretable deep model for fine-grained visual recognition. At the core of our method lies the integration of region-based part discovery and attribution within a deep neural network. Our model is trained using image-level object labels, and provides an interpretation of its results via the segmentation of object parts and the identification of their contributions towards classification. To facilitate the learning of object parts without direct supervision, we explore a simple prior of the occurrence of object parts. We demonstrate that this prior, when combined with our region-based part discovery and attribution, leads to an interpretable model that remains highly accurate. Our model is evaluated on major fine-grained recognition datasets, including {CUB}-200, {CelebA} and {iNaturalist}. Our results compare favorably to state-of-the-art methods on classification tasks, and our method outperforms previous approaches on the localization of object parts.},
	journaltitle = {{arXiv}:2005.10411 [cs]},
	author = {Huang, Zixuan and Li, Yin},
	urldate = {2021-05-12},
	date = {2020-05-20},
	eprinttype = {arxiv},
	eprint = {2005.10411},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{radford_learning_2021,
	title = {Learning Transferable Visual Models From Natural Language Supervision},
	url = {http://arxiv.org/abs/2103.00020},
	abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn {SOTA} image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as {OCR}, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original {ResNet}-50 on {ImageNet} zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/{OpenAI}/{CLIP}.},
	journaltitle = {{arXiv}:2103.00020 [cs]},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	urldate = {2021-05-12},
	date = {2021-02-26},
	eprinttype = {arxiv},
	eprint = {2103.00020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@incollection{ishikawa_contextual_2021,
	location = {Cham},
	title = {Contextual Semantic Interpretability},
	volume = {12625},
	isbn = {978-3-030-69537-8 978-3-030-69538-5},
	url = {http://link.springer.com/10.1007/978-3-030-69538-5_22},
	abstract = {Convolutional neural networks ({CNN}) are known to learn an image representation that captures concepts relevant to the task, but do so in an implicit way that hampers model interpretability. However, one could argue that such a representation is hidden in the neurons and can be made explicit by teaching the model to recognize semantically interpretable attributes that are present in the scene. We call such an intermediate layer a semantic bottleneck. Once the attributes are learned, they can be re-combined to reach the ﬁnal decision and provide both an accurate prediction and an explicit reasoning behind the {CNN} decision. In this paper, we look into semantic bottlenecks that capture context: we want attributes to be in groups of a few meaningful elements and participate jointly to the ﬁnal decision. We use a two-layer semantic bottleneck that gathers attributes into interpretable, sparse groups, allowing them contribute diﬀerently to the ﬁnal output depending on the context. We test our contextual semantic interpretable bottleneck ({CSIB}) on the task of landscape scenicness estimation and train the semantic interpretable bottleneck using an auxiliary database ({SUN} Attributes). Our model yields in predictions as accurate as a non-interpretable baseline when applied to a real-world test set of Flickr images, all while providing clear and interpretable explanations for each prediction.},
	pages = {351--368},
	booktitle = {Computer Vision – {ACCV} 2020},
	publisher = {Springer International Publishing},
	author = {Marcos, Diego and Fong, Ruth and Lobry, Sylvain and Flamary, Rémi and Courty, Nicolas and Tuia, Devis},
	editor = {Ishikawa, Hiroshi and Liu, Cheng-Lin and Pajdla, Tomas and Shi, Jianbo},
	urldate = {2021-05-12},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-69538-5_22},
	note = {Series Title: Lecture Notes in Computer Science},
}