
@article{lipton_machine_nodate,
	title = {In machine learning, the concept of interpretability is both important and slippery.},
	pages = {28},
	journaltitle = {machine learning},
	author = {Lipton, Zachary C},
	langid = {english},
}

@inproceedings{chakraborty_interpretability_2017,
	location = {San Francisco, {CA}},
	title = {Interpretability of deep learning models: A survey of results},
	isbn = {978-1-5386-0435-9},
	url = {https://ieeexplore.ieee.org/document/8397411/},
	doi = {10.1109/UIC-ATC.2017.8397411},
	shorttitle = {Interpretability of deep learning models},
	abstract = {Deep neural networks have achieved near-human accuracy levels in various types of classiﬁcation and prediction tasks including images, text, speech, and video data. However, the networks continue to be treated mostly as black-box function approximators, mapping a given input to a classiﬁcation output. The next step in this human-machine evolutionary process –incorporating these networks into mission critical processes such as medical diagnosis, planning and control – requires a level of trust association with the machine output.},
	eventtitle = {2017 {IEEE} {SmartWorld}, Ubiquitous Intelligence \& Computing, Advanced \& Trusted Computed, Scalable Computing \& Communications, Cloud \& Big Data Computing, Internet of People and Smart City Innovation ({SmartWorld}/{SCALCOM}/{UIC}/{ATC}/{CBDCom}/{IOP}/{SCI})},
	pages = {1--6},
	booktitle = {2017 {IEEE} {SmartWorld}, Ubiquitous Intelligence \& Computing, Advanced \& Trusted Computed, Scalable Computing \& Communications, Cloud \& Big Data Computing, Internet of People and Smart City Innovation ({SmartWorld}/{SCALCOM}/{UIC}/{ATC}/{CBDCom}/{IOP}/{SCI})},
	publisher = {{IEEE}},
	author = {Chakraborty, Supriyo and Tomsett, Richard and Raghavendra, Ramya and Harborne, Daniel and Alzantot, Moustafa and Cerutti, Federico and Srivastava, Mani and Preece, Alun and Julier, Simon and Rao, Raghuveer M. and Kelley, Troy D. and Braines, Dave and Sensoy, Murat and Willis, Christopher J. and Gurram, Prudhvi},
	urldate = {2021-07-30},
	date = {2017-08},
	langid = {english},
}

@article{yang_denert-kg_2020,
	title = {{DeNERT}-{KG}: Named Entity and Relation Extraction Model Using {DQN}, Knowledge Graph, and {BERT}},
	volume = {10},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2076-3417/10/18/6429},
	doi = {10.3390/app10186429},
	shorttitle = {{DeNERT}-{KG}},
	abstract = {Along with studies on artificial intelligence technology, research is also being carried out actively in the field of natural language processing to understand and process people\&rsquo;s language, in other words, natural language. For computers to learn on their own, the skill of understanding natural language is very important. There are a wide variety of tasks involved in the field of natural language processing, but we would like to focus on the named entity registration and relation extraction task, which is considered to be the most important in understanding sentences. We propose {DeNERT}-{KG}, a model that can extract subject, object, and relationships, to grasp the meaning inherent in a sentence. Based on the {BERT} language model and Deep Q-Network, the named entity recognition ({NER}) model for extracting subject and object is established, and a knowledge graph is applied for relation extraction. Using the {DeNERT}-{KG} model, it is possible to extract the subject, type of subject, object, type of object, and relationship from a sentence, and verify this model through experiments.},
	pages = {6429},
	number = {18},
	journaltitle = {Applied Sciences},
	author = {Yang, {SungMin} and Yoo, {SoYeop} and Jeong, {OkRan}},
	urldate = {2021-07-28},
	date = {2020-01},
	langid = {english},
	note = {Number: 18
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{BERT}, {DQN}, knowledge graph, named entity recognition, relation extraction},
}

@article{wu_scalable_2020,
	title = {Scalable Zero-shot Entity Linking with Dense Entity Retrieval},
	url = {http://arxiv.org/abs/1911.03814},
	abstract = {This paper introduces a conceptually simple, scalable, and highly effective {BERT}-based entity linking model, along with an extensive evaluation of its accuracy-speed trade-off. We present a two-stage zero-shot linking algorithm, where each entity is deﬁned only by a short textual description. The ﬁrst stage does retrieval in a dense space deﬁned by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then re-ranked with a crossencoder, that concatenates the mention and entity text. Experiments demonstrate that this approach is state of the art on recent zeroshot benchmarks (6 point absolute gains) and also on more established non-zero-shot evaluations (e.g. {TACKBP}-2010), despite its relative simplicity (e.g. no explicit entity embeddings or manually engineered mention tables). We also show that bi-encoder linking is very fast with nearest neighbour search (e.g. linking with 5.9 million candidates in 2 milliseconds), and that much of the accuracy gain from the more expensive crossencoder can be transferred to the bi-encoder via knowledge distillation. Our code and models are available at https://github. com/facebookresearch/{BLINK}.},
	journaltitle = {{arXiv}:1911.03814 [cs]},
	author = {Wu, Ledell and Petroni, Fabio and Josifoski, Martin and Riedel, Sebastian and Zettlemoyer, Luke},
	urldate = {2021-07-27},
	date = {2020-09-29},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1911.03814},
	keywords = {Computer Science - Computation and Language},
}

@article{stewart_icdm_2019,
	title = {{ICDM} 2019 Knowledge Graph Contest: Team {UWA}},
	url = {http://arxiv.org/abs/1909.01807},
	shorttitle = {{ICDM} 2019 Knowledge Graph Contest},
	abstract = {We present an overview of our triple extraction system for the {ICDM} 2019 Knowledge Graph Contest. Our system uses a pipeline-based approach to extract a set of triples from a given document. It offers a simple and effective solution to the challenge of knowledge graph construction from domain-specific text. It also provides the facility to visualise useful information about each triple such as the degree, betweenness, structured relation type(s), and named entity types.},
	journaltitle = {{arXiv}:1909.01807 [cs]},
	author = {Stewart, Michael and Enkhsaikhan, Majigsuren and Liu, Wei},
	urldate = {2021-07-27},
	date = {2019-09-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1909.01807},
	keywords = {Computer Science - Computation and Language},
}

@article{sergeev_application_2020,
	title = {An Application of Semantic Relation Extraction Models},
	abstract = {Natural language processing ({NLP}) is growing to be one of the largest subfields of computer science, with application to many other fields such as linguistics or information extraction. This large growth has resulted in higher availability and a variety of resources that contributors can work with. Semantic relation datasets as a result have seen an increase in number and many today, including high profile companies at the head of {NLP}, are creating stateof-the-art machine learning models. These models are capable of identifying these relations from sentences by training on this selection of datasets. The number of models applied outside of their datasets, however, is still relatively low. With such a high amount of data being produced daily in our technological world, semantic relation models could potentially be used to help increase the speed at which specific information can be identified and extracted from their collections of data. This project will look at the accuracy of trained semantic models outside of their training datasets to assess the applicability of them as a tool for a general information search.},
	pages = {5},
	author = {Sergeev, Aleksandr},
	date = {2020},
	langid = {english},
}

@article{kim_greg_2020,
	title = {{GREG}: A Global Level Relation Extraction with Knowledge Graph Embedding},
	volume = {10},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/3/1181},
	doi = {10.3390/app10031181},
	shorttitle = {{GREG}},
	abstract = {In an age overﬂowing with information, the task of converting unstructured data into structured data are a vital task of great need. Currently, most relation extraction modules are more focused on the extraction of local mention-level relations—usually from short volumes of text. However, in most cases, the most vital and important relations are those that are described in length and detail. In this research, we propose {GREG}: A Global level Relation Extractor model using knowledge graph embeddings for document-level inputs. The model uses vector representations of mention-level ‘local’ relation’s to construct knowledge graphs that can represent the input document. The knowledge graph is then used to predict global level relations from documents or large bodies of text. The proposed model is largely divided into two modules which are synchronized during their training. Thus, each of the model’s modules is designed to deal with local relations and global relations separately. This allows the model to avoid the problem of struggling against loss of information due to too much information crunched into smaller sized representations when attempting global level relation extraction. Through evaluation, we have shown that the proposed model yields high performances in both predicting global level relations and local level relations consistently.},
	pages = {1181},
	number = {3},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Kim, Kuekyeng and Hur, Yuna and Kim, Gyeongmin and Lim, Heuiseok},
	urldate = {2021-07-20},
	date = {2020-02-10},
	langid = {english},
}

@article{martinez-rodriguez_openie-based_2018,
	title = {{OpenIE}-based approach for Knowledge Graph construction from text},
	volume = {113},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417418304329},
	doi = {10.1016/j.eswa.2018.07.017},
	pages = {339--355},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Martinez-Rodriguez, Jose L. and Lopez-Arevalo, Ivan and Rios-Alvarado, Ana B.},
	urldate = {2021-07-20},
	date = {2018-12},
	langid = {english},
}

@online{noauthor_openie-based_nodate,
	title = {{OpenIE}-based approach for Knowledge Graph construction from text {\textbar} Elsevier Enhanced Reader},
	url = {https://reader.elsevier.com/reader/sd/pii/S0957417418304329?token=2EEAB1A078C9DD135C1E6513ED6CAEA37E228CEB29BAD3B64F5EC0DB23AC90577D2252D7EC5F6BAFA5CB0A5403498D81&originRegion=eu-west-1&originCreation=20210720114836},
	urldate = {2021-07-20},
	langid = {english},
	doi = {10.1016/j.eswa.2018.07.017},
}

@article{martinez-rodriguez_openie-based_2018-1,
	title = {{OpenIE}-based approach for Knowledge Graph construction from text},
	volume = {113},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417418304329},
	doi = {10.1016/j.eswa.2018.07.017},
	abstract = {Transforming unstructured text into a formal representation is an important goal of the Semantic Web in order to facilitate the integration and retrieval of information. The construction of Knowledge Graphs ({KGs}) pursues such an idea, where named entities (real world things) and their relations are extracted from text. In recent years, many approaches for the construction of {KGs} have been proposed by exploiting Discourse Analysis, Semantic Frames, or Machine Learning algorithms with existing Semantic Web data. Although such approaches are useful for processing taxonomies and connecting beliefs, they provide several linguistic descriptions, which lead to semantic data heterogeneity and thus, complicating data consumption. Moreover, Open Information Extraction ({OpenIE}) approaches have been slightly explored for the construction of {KGs}, which provide binary relations representing atomic units of information that could simplify the querying and representation of data. In this paper, we propose an approach to generate {KGs} using binary relations produced by an {OpenIE} approach. For such purpose, we present strategies for favoring the extraction and linking of named entities with {KG} individuals, and additionally, their association with grammatical units that lead to producing more coherent facts. We also provide decisions for selecting the extracted information elements for creating potentially useful {RDF} triples for the {KG}. Our results demonstrate that the integration of information extraction units with grammatical structures provides a better understanding of proposition-based representations provided by {OpenIE} for supporting the construction of {KGs}.},
	pages = {339--355},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Martinez-Rodriguez, Jose L. and Lopez-Arevalo, Ivan and Rios-Alvarado, Ana B.},
	urldate = {2021-07-20},
	date = {2018-12-15},
	langid = {english},
	keywords = {Fact extraction, Knowledge Graph, {RDF} events, Relation Extraction, Semantic Web representation},
}

@article{li_understanding_2017,
	title = {Understanding Neural Networks through Representation Erasure},
	url = {http://arxiv.org/abs/1612.08220},
	abstract = {While neural networks have been successfully applied to many natural language processing tasks, they come at the cost of interpretability. In this paper, we propose a general methodology to analyze and interpret decisions from a neural model by observing the effects on the model of erasing various parts of the representation, such as input word-vector dimensions, intermediate hidden units, or input words. We present several approaches to analyzing the effects of such erasure, from computing the relative difference in evaluation metrics, to using reinforcement learning to erase the minimum set of input words in order to flip a neural model's decision. In a comprehensive analysis of multiple {NLP} tasks, including linguistic feature classification, sentence-level sentiment analysis, and document level sentiment aspect prediction, we show that the proposed methodology not only offers clear explanations about neural model decisions, but also provides a way to conduct error analysis on neural models.},
	journaltitle = {{arXiv}:1612.08220 [cs]},
	author = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
	urldate = {2021-07-19},
	date = {2017-01-09},
	eprinttype = {arxiv},
	eprint = {1612.08220},
	keywords = {Computer Science - Computation and Language},
}

@article{vaswani_attention_nodate,
	title = {Attention is All you Need},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.0 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature.},
	pages = {11},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	langid = {english},
}

@online{billerman_birds_nodate,
	title = {Birds of the World - Comprehensive life histories for all bird species and families},
	url = {https://birdsoftheworld.org/bow/home},
	abstract = {Species accounts for all the birds of the world.},
	titleaddon = {Birds of the World},
	type = {Database},
	author = {Billerman, S.M. and Keeney, B.K. and Rodewald, P.G. and Schulenberg, T.S.},
	urldate = {2021-07-13},
	langid = {english},
}

@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3065386},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the {ImageNet} {LSVRC}-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of ﬁve convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a ﬁnal 1000-way softmax. To make training faster, we used non-saturating neurons and a very efﬁcient {GPU} implementation of the convolution operation. To reduce overﬁtting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the {ILSVRC}-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	pages = {84--90},
	number = {6},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	urldate = {2021-07-13},
	date = {2017-05-24},
	langid = {english},
}

@article{mikolov_distributed_2013,
	title = {Distributed Representations of Words and Phrases and their Compositionality},
	url = {http://arxiv.org/abs/1310.4546},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	journaltitle = {{arXiv}:1310.4546 [cs, stat]},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2021-07-13},
	date = {2013-10-16},
	eprinttype = {arxiv},
	eprint = {1310.4546},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{sun_how_2020,
	title = {How to Fine-Tune {BERT} for Text Classification?},
	url = {http://arxiv.org/abs/1905.05583},
	abstract = {Language model pre-training has proven to be useful in learning universal language representations. As a state-of-the-art language model pre-training model, {BERT} (Bidirectional Encoder Representations from Transformers) has achieved amazing results in many language understanding tasks. In this paper, we conduct exhaustive experiments to investigate different fine-tuning methods of {BERT} on text classification task and provide a general solution for {BERT} fine-tuning. Finally, the proposed solution obtains new state-of-the-art results on eight widely-studied text classification datasets.},
	journaltitle = {{arXiv}:1905.05583 [cs]},
	author = {Sun, Chi and Qiu, Xipeng and Xu, Yige and Huang, Xuanjing},
	urldate = {2021-07-11},
	date = {2020-02-05},
	eprinttype = {arxiv},
	eprint = {1905.05583},
	keywords = {Computer Science - Computation and Language},
}

@article{minaee_deep_2021,
	title = {Deep Learning Based Text Classification: A Comprehensive Review},
	url = {http://arxiv.org/abs/2004.03705},
	shorttitle = {Deep Learning Based Text Classification},
	abstract = {Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions.},
	journaltitle = {{arXiv}:2004.03705 [cs, stat]},
	author = {Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
	urldate = {2021-07-11},
	date = {2021-01-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2004.03705},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{brown_language_2020,
	title = {Language Models are Few-Shot Learners},
	url = {http://arxiv.org/abs/2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many {NLP} tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current {NLP} systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train {GPT}-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, {GPT}-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. {GPT}-3 achieves strong performance on many {NLP} datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where {GPT}-3's few-shot learning still struggles, as well as some datasets where {GPT}-3 faces methodological issues related to training on large web corpora. Finally, we find that {GPT}-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of {GPT}-3 in general.},
	journaltitle = {{arXiv}:2005.14165 [cs]},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and {McCandlish}, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	urldate = {2021-07-11},
	date = {2020-07-22},
	eprinttype = {arxiv},
	eprint = {2005.14165},
	keywords = {Computer Science - Computation and Language},
}

@incollection{amershi_modeltracker_2015,
	location = {New York, {NY}, {USA}},
	title = {{ModelTracker}: Redesigning Performance Analysis Tools for Machine Learning},
	isbn = {978-1-4503-3145-6},
	url = {https://doi.org/10.1145/2702123.2702509},
	shorttitle = {{ModelTracker}},
	abstract = {Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present {ModelTracker}, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with {ModelTracker} over six months shows {ModelTracker} is used often and throughout model building. A controlled experiment focusing on {ModelTracker}'s debugging capabilities shows participants prefer {ModelTracker} over traditional tools without a loss in model performance.},
	pages = {337--346},
	booktitle = {Proceedings of the 33rd Annual {ACM} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Amershi, Saleema and Chickering, Max and Drucker, Steven M. and Lee, Bongshin and Simard, Patrice and Suh, Jina},
	urldate = {2021-07-11},
	date = {2015-04-18},
	keywords = {debugging, interactive visualization, machine learning, performance analysis},
}

@article{bai_empirical_2018,
	title = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
	url = {http://arxiv.org/abs/1803.01271},
	abstract = {For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as {LSTMs} across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/{TCN} .},
	journaltitle = {{arXiv}:1803.01271 [cs]},
	author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
	urldate = {2021-07-11},
	date = {2018-04-19},
	eprinttype = {arxiv},
	eprint = {1803.01271},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{koh_understanding_2020,
	title = {Understanding Black-box Predictions via Influence Functions},
	url = {http://arxiv.org/abs/1703.04730},
	abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
	journaltitle = {{arXiv}:1703.04730 [cs, stat]},
	author = {Koh, Pang Wei and Liang, Percy},
	urldate = {2021-07-09},
	date = {2020-12-29},
	eprinttype = {arxiv},
	eprint = {1703.04730},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ribeiro_why_2016,
	title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
	url = {http://arxiv.org/abs/1602.04938},
	shorttitle = {"Why Should I Trust You?},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose {LIME}, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	journaltitle = {{arXiv}:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	urldate = {2021-07-09},
	date = {2016-08-09},
	eprinttype = {arxiv},
	eprint = {1602.04938},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{carvalho_machine_2019,
	title = {Machine Learning Interpretability: A Survey on Methods and Metrics},
	volume = {8},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2079-9292/8/8/832},
	doi = {10.3390/electronics8080832},
	shorttitle = {Machine Learning Interpretability},
	abstract = {Machine learning systems are becoming increasingly ubiquitous. These systems\&rsquo;s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.},
	pages = {832},
	number = {8},
	journaltitle = {Electronics},
	author = {Carvalho, Diogo V. and Pereira, Eduardo M. and Cardoso, Jaime S.},
	urldate = {2021-07-09},
	date = {2019-08},
	langid = {english},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{XAI}, explainability, interpretability, machine learning},
}

@article{li_interpretable_2021,
	title = {Interpretable Deep Learning: Interpretation, Interpretability, Trustworthiness, and Beyond},
	url = {http://arxiv.org/abs/2103.10689},
	shorttitle = {Interpretable Deep Learning},
	abstract = {Deep neural networks have been well-known for their superb performance in handling various machine learning and artiﬁcial intelligence tasks. However, due to their over-parameterized black-box nature, it is often diﬃcult to understand the prediction results of deep models. In recent years, many interpretation tools have been proposed to explain or reveal the ways that deep models make decisions. In this paper, we review this line of research and try to make a comprehensive survey. Speciﬁcally, we introduce and clarify two basic concepts—interpretations and interpretability—that people usually get confused. First of all, to address the research eﬀorts in interpretations, we elaborate the design of several recent interpretation algorithms, from diﬀerent perspectives, through proposing a new taxonomy. Then, to understand the results of interpretation, we also survey the performance metrics for evaluating interpretation algorithms. Further, we summarize the existing work in evaluating models’ interpretability using “trustworthy” interpretation algorithms. Finally, we review and discuss the connections between deep models’ interpretations and other factors, such as adversarial robustness and data augmentations, and we introduce several open-source libraries for interpretation algorithms and evaluation approaches.},
	journaltitle = {{arXiv}:2103.10689 [cs]},
	author = {Li, Xuhong and Xiong, Haoyi and Li, Xingjian and Wu, Xuanyu and Zhang, Xiao and Liu, Ji and Bian, Jiang and Dou, Dejing},
	urldate = {2021-07-09},
	date = {2021-05-11},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2103.10689},
	keywords = {Computer Science - Machine Learning},
}

@article{zhai_scaling_2021,
	title = {Scaling Vision Transformers},
	url = {http://arxiv.org/abs/2106.04560},
	abstract = {Attention-based neural networks such as the Vision Transformer ({ViT}) have recently attained state-of-the-art results on many computer vision benchmarks. Scale is a primary ingredient in attaining excellent results, therefore, understanding a model’s scaling properties is a key to designing future generations effectively. While the laws for scaling Transformer language models have been studied, it is unknown how Vision Transformers scale. To address this, we scale {ViT} models and data, both up and down, and characterize the relationships between error rate, data, and compute. Along the way, we reﬁne the architecture and training of {ViT}, reducing memory consumption and increasing accuracy of the resulting models. As a result, we successfully train a {ViT} model with two billion parameters, which attains a new state-of-the-art on {ImageNet} of 90.45\% top-1 accuracy. The model also performs well on few-shot learning, for example, reaching 84.86\% top-1 accuracy on {ImageNet} with only 10 examples per class.},
	journaltitle = {{arXiv}:2106.04560 [cs]},
	author = {Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
	urldate = {2021-07-09},
	date = {2021-06-08},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2106.04560},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{devlin_bert_2019,
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {http://arxiv.org/abs/1810.04805},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), {BERT} is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.},
	journaltitle = {{arXiv}:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2021-07-04},
	date = {2019-05-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1810.04805},
	keywords = {Computer Science - Computation and Language},
}

@article{losch_interpretability_2019,
	title = {Interpretability Beyond Classification Output: Semantic Bottleneck Networks},
	url = {http://arxiv.org/abs/1907.10882},
	shorttitle = {Interpretability Beyond Classification Output},
	abstract = {Today’s deep learning systems deliver high performance based on end-to-end training. While they deliver strong performance, these systems are hard to interpret. To address this issue, we propose Semantic Bottleneck Networks ({SBN}): deep networks with semantically interpretable intermediate layers that all downstream results are based on. As a consequence, the analysis on what the ﬁnal prediction is based on is transparent to the engineer and failure cases and modes can be analyzed and avoided by high-level reasoning. We present a case study on street scene segmentation to demonstrate the feasibility and power of {SBN}. In particular, we start from a well performing classic deep network which we adapt to house a {SB}-Layer containing task related semantic concepts (such as object-parts and materials). Importantly, we can recover state of the art performance despite a drastic dimensionality reduction from 1000s (non-semantic feature) to 10s (semantic concept) channels. Additionally we show how the activations of the {SB}-Layer can be used for both the interpretation of failure cases of the network as well as for conﬁdence prediction of the resulting output. For the ﬁrst time, e.g., we show interpretable segmentation results for most predictions at over 99\% accuracy.},
	journaltitle = {{arXiv}:1907.10882 [cs]},
	author = {Losch, Max and Fritz, Mario and Schiele, Bernt},
	urldate = {2021-07-04},
	date = {2019-07-28},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1907.10882},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{wu_visual_2020,
	title = {Visual Transformers: Token-based Image Representation and Processing for Computer Vision},
	url = {http://arxiv.org/abs/2006.03677},
	shorttitle = {Visual Transformers},
	abstract = {Computer vision has achieved remarkable success by (a) representing images as uniformly-arranged pixel arrays and (b) convolving highly-localized features. However, convolutions treat all image pixels equally regardless of importance; explicitly model all concepts across all images, regardless of content; and struggle to relate spatially-distant concepts. In this work, we challenge this paradigm by (a) representing images as semantic visual tokens and (b) running transformers to densely model token relationships. Critically, our Visual Transformer operates in a semantic token space, judiciously attending to different image parts based on context. This is in sharp contrast to pixel-space transformers that require orders-of-magnitude more compute. Using an advanced training recipe, our {VTs} significantly outperform their convolutional counterparts, raising {ResNet} accuracy on {ImageNet} top-1 by 4.6 to 7 points while using fewer {FLOPs} and parameters. For semantic segmentation on {LIP} and {COCO}-stuff, {VT}-based feature pyramid networks ({FPN}) achieve 0.35 points higher {mIoU} while reducing the {FPN} module's {FLOPs} by 6.5x.},
	journaltitle = {{arXiv}:2006.03677 [cs, eess]},
	author = {Wu, Bichen and Xu, Chenfeng and Dai, Xiaoliang and Wan, Alvin and Zhang, Peizhao and Yan, Zhicheng and Tomizuka, Masayoshi and Gonzalez, Joseph and Keutzer, Kurt and Vajda, Peter},
	urldate = {2021-05-12},
	date = {2020-11-19},
	eprinttype = {arxiv},
	eprint = {2006.03677},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{huang_interpretable_2020,
	title = {Interpretable and Accurate Fine-grained Recognition via Region Grouping},
	url = {http://arxiv.org/abs/2005.10411},
	abstract = {We present an interpretable deep model for fine-grained visual recognition. At the core of our method lies the integration of region-based part discovery and attribution within a deep neural network. Our model is trained using image-level object labels, and provides an interpretation of its results via the segmentation of object parts and the identification of their contributions towards classification. To facilitate the learning of object parts without direct supervision, we explore a simple prior of the occurrence of object parts. We demonstrate that this prior, when combined with our region-based part discovery and attribution, leads to an interpretable model that remains highly accurate. Our model is evaluated on major fine-grained recognition datasets, including {CUB}-200, {CelebA} and {iNaturalist}. Our results compare favorably to state-of-the-art methods on classification tasks, and our method outperforms previous approaches on the localization of object parts.},
	journaltitle = {{arXiv}:2005.10411 [cs]},
	author = {Huang, Zixuan and Li, Yin},
	urldate = {2021-05-12},
	date = {2020-05-20},
	eprinttype = {arxiv},
	eprint = {2005.10411},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{radford_learning_2021,
	title = {Learning Transferable Visual Models From Natural Language Supervision},
	url = {http://arxiv.org/abs/2103.00020},
	abstract = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn {SOTA} image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as {OCR}, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original {ResNet}-50 on {ImageNet} zero-shot without needing to use any of the 1.28 million training examples it was trained on. We release our code and pre-trained model weights at https://github.com/{OpenAI}/{CLIP}.},
	journaltitle = {{arXiv}:2103.00020 [cs]},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	urldate = {2021-05-12},
	date = {2021-02-26},
	eprinttype = {arxiv},
	eprint = {2103.00020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@incollection{ishikawa_contextual_2021,
	location = {Cham},
	title = {Contextual Semantic Interpretability},
	volume = {12625},
	isbn = {978-3-030-69537-8 978-3-030-69538-5},
	url = {http://link.springer.com/10.1007/978-3-030-69538-5_22},
	abstract = {Convolutional neural networks ({CNN}) are known to learn an image representation that captures concepts relevant to the task, but do so in an implicit way that hampers model interpretability. However, one could argue that such a representation is hidden in the neurons and can be made explicit by teaching the model to recognize semantically interpretable attributes that are present in the scene. We call such an intermediate layer a semantic bottleneck. Once the attributes are learned, they can be re-combined to reach the ﬁnal decision and provide both an accurate prediction and an explicit reasoning behind the {CNN} decision. In this paper, we look into semantic bottlenecks that capture context: we want attributes to be in groups of a few meaningful elements and participate jointly to the ﬁnal decision. We use a two-layer semantic bottleneck that gathers attributes into interpretable, sparse groups, allowing them contribute diﬀerently to the ﬁnal output depending on the context. We test our contextual semantic interpretable bottleneck ({CSIB}) on the task of landscape scenicness estimation and train the semantic interpretable bottleneck using an auxiliary database ({SUN} Attributes). Our model yields in predictions as accurate as a non-interpretable baseline when applied to a real-world test set of Flickr images, all while providing clear and interpretable explanations for each prediction.},
	pages = {351--368},
	booktitle = {Computer Vision – {ACCV} 2020},
	publisher = {Springer International Publishing},
	author = {Marcos, Diego and Fong, Ruth and Lobry, Sylvain and Flamary, Rémi and Courty, Nicolas and Tuia, Devis},
	editor = {Ishikawa, Hiroshi and Liu, Cheng-Lin and Pajdla, Tomas and Shi, Jianbo},
	urldate = {2021-05-12},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-69538-5_22},
	note = {Series Title: Lecture Notes in Computer Science},
}